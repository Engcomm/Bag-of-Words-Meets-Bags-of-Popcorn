{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/.local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/rodrigo/.local/lib/python2.7/site-packages/sklearn/learning_curve.py:23: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import numpy as np\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.learning_curve import learning_curve\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The necessary files can be downloaded from the Data page. The first file that you'll need is unlabeledTrainData.tsv, which contains 25,000 IMDB movie reviews, each with a positive or negative sentiment label.\n",
    "\n",
    "Next, read the tab-delimited file into Python. To do this, we can use the pandas package, introduced in the Titanic tutorial, which provides the read_csv function for easily reading and writing data files. If you haven't used pandas before, you may need to install it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the pandas package, then use the \"read_csv\" function to read\n",
    "# the labeled training data\n",
    "import pandas as pd       \n",
    "data = pd.read_csv(\"data.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, \"header=0\" indicates that the first line of the file contains column names, \"delimiter=\\t\" indicates that the fields are separated by tabs, and quoting=3 tells Python to ignore doubled quotes, otherwise you may encounter errors trying to read the file.\n",
    "\n",
    "We can make sure that we read 25,000 rows and 3 columns as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52108, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['text', 'class'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reenviar indisponivel novamente registro sac</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aproximado mil nobill suspensão corporativo au...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>conte benéficos devidos expirada franquia intr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>exibe conjunta reinscidente venda combinacao m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nba recebemos oct correção informações solicit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  class\n",
       "0       reenviar indisponivel novamente registro sac      1\n",
       "1  aproximado mil nobill suspensão corporativo au...      1\n",
       "2  conte benéficos devidos expirada franquia intr...      1\n",
       "3  exibe conjunta reinscidente venda combinacao m...      1\n",
       "4  nba recebemos oct correção informações solicit...      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The three columns are called \"id\", \"sentiment\", and \"array.\"  Now that you've read the training set, take a look at a few reviews:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a reminder, this will show you the first movie review in the column named \"review.\" You should see a review that starts like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reenviar indisponivel novamente registro sac\n"
     ]
    }
   ],
   "source": [
    "print data[\"text\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing HTML Markup: The BeautifulSoup Package\n",
    "\n",
    "First, we'll remove the HTML tags. For this purpose, we'll use the Beautiful Soup library. If you don't have Beautiful soup installed, do:\n",
    "Then, from within Python, load the package and use it to extract the text from a review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reenviar indisponivel novamente registro sac\n",
      "reenviar indisponivel novamente registro sac\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 174 of the file /usr/lib/python2.7/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "# Import BeautifulSoup into your workspace\n",
    "from bs4 import BeautifulSoup             \n",
    "\n",
    "# Initialize the BeautifulSoup object on a single movie review     \n",
    "example1 = BeautifulSoup(data[\"text\"][0])  \n",
    "\n",
    "# Print the raw review and then the output of get_text(), for \n",
    "# comparison\n",
    "print data[\"text\"][0]\n",
    "print example1.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling get_text() gives you the text of the review, without tags or markup. If you browse the BeautifulSoup documentation, you'll see that it's a very powerful library - more powerful than we need for this dataset. However, it is not considered a reliable practice to remove markup using regular expressions, so even for an application as simple as this, it's usually best to use a package like BeautifulSoup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with Punctuation, Numbers and Stopwords: NLTK and regular expressions\n",
    "\n",
    "When considering how to clean the text, we should think about the data problem we are trying to solve. For many problems, it makes sense to remove punctuation. On the other hand, in this case, we are tackling a sentiment analysis problem, and it is possible that \"!!!\" or \":-(\" could carry sentiment, and should be treated as words. In this tutorial, for simplicity, we remove the punctuation altogether, but it is something you can play with on your own.\n",
    "\n",
    "Similarly, in this tutorial we will remove numbers, but there are other ways of dealing with them that make just as much sense. For example, we could treat them as words, or replace them all with a placeholder string such as \"NUM\".\n",
    "\n",
    "To remove punctuation and numbers, we will use a package for dealing with regular expressions, called re. The package comes built-in with Python; no need to install anything. For a detailed description of how regular expressions work, see the package documentation. Now, try the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reenviar indisponivel novamente registro sac\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# Use regular expressions to do a find-and-replace\n",
    "letters_only = re.sub(\"[^a-zA-Z]\",           # The pattern to search for\n",
    "                      \" \",                   # The pattern to replace it with\n",
    "                      example1.get_text() )  # The text to search\n",
    "print letters_only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A full overview of regular expressions is beyond the scope of this tutorial, but for now it is sufficient to know that [] indicates group membership and ^ means \"not\". In other words, the re.sub() statement above says, \"Find anything that is NOT a lowercase letter (a-z) or an upper case letter (A-Z), and replace it with a space.\"\n",
    "\n",
    "We'll also convert our reviews to lower case and split them into individual words (called \"tokenization\" in NLP lingo):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lower_case = letters_only.lower()        # Convert to lower case\n",
    "words = lower_case.split()               # Split into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'reenviar', u'indisponivel', u'novamente', u'registro', u'sac']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to decide how to deal with frequently occurring words that don't carry much meaning. Such words are called \"stop words\"; in English they include words such as \"a\", \"and\", \"is\", and \"the\". Conveniently, there are Python packages that come with stop word lists built in. Let's import a stop word list from the Python Natural Language Toolkit (NLTK). You'll need to install the library if you don't already have it on your computer; you'll also need to install the data packages that come with it, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'de', u'a', u'o', u'que', u'e', u'do', u'da', u'em', u'um', u'para', u'com', u'n\\xe3o', u'uma', u'os', u'no', u'se', u'na', u'por', u'mais', u'as', u'dos', u'como', u'mas', u'ao', u'ele', u'das', u'\\xe0', u'seu', u'sua', u'ou', u'quando', u'muito', u'nos', u'j\\xe1', u'eu', u'tamb\\xe9m', u's\\xf3', u'pelo', u'pela', u'at\\xe9', u'isso', u'ela', u'entre', u'depois', u'sem', u'mesmo', u'aos', u'seus', u'quem', u'nas', u'me', u'esse', u'eles', u'voc\\xea', u'essa', u'num', u'nem', u'suas', u'meu', u'\\xe0s', u'minha', u'numa', u'pelos', u'elas', u'qual', u'n\\xf3s', u'lhe', u'deles', u'essas', u'esses', u'pelas', u'este', u'dele', u'tu', u'te', u'voc\\xeas', u'vos', u'lhes', u'meus', u'minhas', u'teu', u'tua', u'teus', u'tuas', u'nosso', u'nossa', u'nossos', u'nossas', u'dela', u'delas', u'esta', u'estes', u'estas', u'aquele', u'aquela', u'aqueles', u'aquelas', u'isto', u'aquilo', u'estou', u'est\\xe1', u'estamos', u'est\\xe3o', u'estive', u'esteve', u'estivemos', u'estiveram', u'estava', u'est\\xe1vamos', u'estavam', u'estivera', u'estiv\\xe9ramos', u'esteja', u'estejamos', u'estejam', u'estivesse', u'estiv\\xe9ssemos', u'estivessem', u'estiver', u'estivermos', u'estiverem', u'hei', u'h\\xe1', u'havemos', u'h\\xe3o', u'houve', u'houvemos', u'houveram', u'houvera', u'houv\\xe9ramos', u'haja', u'hajamos', u'hajam', u'houvesse', u'houv\\xe9ssemos', u'houvessem', u'houver', u'houvermos', u'houverem', u'houverei', u'houver\\xe1', u'houveremos', u'houver\\xe3o', u'houveria', u'houver\\xedamos', u'houveriam', u'sou', u'somos', u's\\xe3o', u'era', u'\\xe9ramos', u'eram', u'fui', u'foi', u'fomos', u'foram', u'fora', u'f\\xf4ramos', u'seja', u'sejamos', u'sejam', u'fosse', u'f\\xf4ssemos', u'fossem', u'for', u'formos', u'forem', u'serei', u'ser\\xe1', u'seremos', u'ser\\xe3o', u'seria', u'ser\\xedamos', u'seriam', u'tenho', u'tem', u'temos', u't\\xe9m', u'tinha', u't\\xednhamos', u'tinham', u'tive', u'teve', u'tivemos', u'tiveram', u'tivera', u'tiv\\xe9ramos', u'tenha', u'tenhamos', u'tenham', u'tivesse', u'tiv\\xe9ssemos', u'tivessem', u'tiver', u'tivermos', u'tiverem', u'terei', u'ter\\xe1', u'teremos', u'ter\\xe3o', u'teria', u'ter\\xedamos', u'teriam']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "print stopwords.words(\"portuguese\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will allow you to view the list of English-language stop words. To remove stop words from our movie review, do:\n",
    "This looks at each word in our \"words\" list, and discards anything that is found in the list of stop words. After all of these steps, your review should now begin something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'reenviar', u'indisponivel', u'novamente', u'registro', u'sac']\n"
     ]
    }
   ],
   "source": [
    "# Remove stop words from \"words\"\n",
    "words = [w for w in words if not w in stopwords.words(\"portuguese\")]\n",
    "print words[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't worry about the \"u\" before each word; it just indicates that Python is internally representing each word as a unicode string.\n",
    "\n",
    "There are many other things we could do to the data - For example, Porter Stemming and Lemmatizing (both available in NLTK) would allow us to treat \"messages\", \"message\", and \"messaging\" as the same word, which could certainly be useful. However, for simplicity, the tutorial will stop here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together\n",
    "Now we have code to clean one review - but we need to clean 25,000 training reviews! To make our code reusable, let's create a function that can be called many times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_to_words( raw_review ):\n",
    "    # Function to convert a raw review to a string of words\n",
    "    # The input is a single string (a raw movie review), and \n",
    "    # the output is a single string (a preprocessed movie review)\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(raw_review).get_text() \n",
    "    #\n",
    "    # 2. Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text) \n",
    "    #\n",
    "    # 3. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()                             \n",
    "    #\n",
    "    # 4. In Python, searching a set is much faster than searching\n",
    "    #   a list, so convert the stop words to a set\n",
    "    stops = set(stopwords.words(\"portuguese\"))                  \n",
    "    # \n",
    "    # 5. Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]   \n",
    "    #\n",
    "    # 6. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return( \" \".join( meaningful_words ))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two elements here are new: First, we converted the stop word list to a different data type, a set. This is for speed; since we'll be calling this function tens of thousands of times, it needs to be fast, and searching sets in Python is much faster than searching lists.\n",
    "\n",
    "Second, we joined the words back into one paragraph. This is to make the output easier to use in our Bag of Words, below. After defining the above function, if you call the function for a single review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reenviar indisponivel novamente registro sac\n"
     ]
    }
   ],
   "source": [
    "clean_data = text_to_words( data[\"text\"][0] )\n",
    "print clean_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it should give you exactly the same output as all of the individual steps we did in preceding tutorial sections. Now let's loop through and clean all of the training set at once (this might take a few minutes depending on your computer):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare model for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into a training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41686, 2)\n",
      "(10422, 2)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(data, test_size = 0.2)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41686\n"
     ]
    }
   ],
   "source": [
    "# Get the number of reviews based on the dataframe column size\n",
    "num_text = train[\"text\"].size\n",
    "\n",
    "print num_text\n",
    "\n",
    "# Initialize an empty list to hold the clean reviews\n",
    "clean_train_text = []\n",
    "\n",
    "clean_train_text = train.text.apply(text_to_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41686,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(clean_train_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output the training and test data to csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Copy the results to a pandas dataframe with an \"id\" column and\n",
    "# a \"sentiment\" column\n",
    "output = pd.DataFrame( data=train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>automação travando z logof teclado mouse ctxre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13344</th>\n",
       "      <td>c inadimplência terminais suspenso senhores ve...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30252</th>\n",
       "      <td>tentato cancelamento executada invalido possiv...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36992</th>\n",
       "      <td>enviada clarify ordem</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26548</th>\n",
       "      <td>interoperação wll novas falha devido usuária a...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  class\n",
       "19996  automação travando z logof teclado mouse ctxre...      1\n",
       "13344  c inadimplência terminais suspenso senhores ve...      1\n",
       "30252  tentato cancelamento executada invalido possiv...      2\n",
       "36992                              enviada clarify ordem      2\n",
       "26548  interoperação wll novas falha devido usuária a...      2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use pandas to write the comma-separated output file\n",
    "output.to_csv( \"train.csv\", index=False, quoting=3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Features from a Bag of Words (Using scikit-learn)\n",
    "Now that we have our training reviews tidied up, how do we convert them to some kind of numeric representation for machine learning? One common approach is called a Bag of Words. The Bag of Words model learns a vocabulary from all of the documents, then models each document by counting the number of times each word appears. For example, consider the following two sentences:\n",
    "\n",
    "Sentence 1: \"The cat sat on the hat\"\n",
    "\n",
    "Sentence 2: \"The dog ate the cat and the hat\"\n",
    "\n",
    "From these two sentences, our vocabulary is as follows:\n",
    "\n",
    "{ the, cat, sat, on, hat, dog, ate, and }\n",
    "\n",
    "To get our bags of words, we count the number of times each word occurs in each sentence. In Sentence 1, \"the\" appears twice, and \"cat\", \"sat\", \"on\", and \"hat\" each appear once, so the feature vector for Sentence 1 is:\n",
    "\n",
    "{ the, cat, sat, on, hat, dog, ate, and }\n",
    "\n",
    "Sentence 1: { 2, 1, 1, 1, 1, 0, 0, 0 }\n",
    "\n",
    "Similarly, the features for Sentence 2 are: { 3, 1, 0, 0, 1, 1, 1, 1}\n",
    "\n",
    "In the IMDB data, we have a very large number of reviews, which will give us a large vocabulary. To limit the size of the feature vectors, we should choose some maximum vocabulary size. Below, we use the 5000 most frequent words (remembering that stop words have already been removed).\n",
    "\n",
    "We'll be using the feature_extraction module from scikit-learn to create bag-of-words features. If you did the Random Forest tutorial in the Titanic competition, you should already have scikit-learn installed; otherwise you will need to install it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the bag of words...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"Creating the bag of words...\\n\"\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "# bag of words tool.  \n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 5000) \n",
    "\n",
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocabulary; second, it transforms our training data\n",
    "# into feature vectors. The input to fit_transform should be a list of \n",
    "# strings.\n",
    "train_features = vectorizer.fit_transform(clean_train_text)\n",
    "\n",
    "# Numpy arrays are easy to work with, so convert the result to an \n",
    "# array\n",
    "train_features = train_features.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see what the training data array now looks like, do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41686, 5000)\n"
     ]
    }
   ],
   "source": [
    "print train_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has 25,000 rows and 5,000 features (one for each vocabulary word).\n",
    "\n",
    "Note that CountVectorizer comes with its own options to automatically do preprocessing, tokenization, and stop word removal -- for each of these, instead of specifying \"None\", we could have used a built-in method or specified our own function to use.  See the function documentation for more details. However, we wanted to write our own function for data cleaning in this tutorial to show you how it's done step by step.\n",
    "\n",
    "Now that the Bag of Words model is trained, let's look at the vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'aa', u'aaaammdd', u'aba', u'abaixo', u'abas', u'abend', u'aberta', u'abertas', u'aberto', u'abertos', u'abertura', u'abo', u'abonador', u'abr', u'abra', u'abre', u'abreu', u'abri', u'abril', u'abrimos', u'abrindo', u'abrir', u'abriu', u'abrtelecom', u'ac', u'aca', u'acaa', u'acabou', u'acao', u'acarretando']\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the words in the vocabulary\n",
    "vocab = vectorizer.get_feature_names()\n",
    "print vocab[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're interested, you can also print the counts of each word in\n",
    "the vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "277 aa\n",
      "10 aaaammdd\n",
      "67 aba\n",
      "204 abaixo\n",
      "8 abas\n",
      "19 abend\n",
      "686 aberta\n",
      "179 abertas\n",
      "602 aberto\n",
      "125 abertos\n",
      "417 abertura\n",
      "9 abo\n",
      "26 abonador\n",
      "139 abr\n",
      "13 abra\n",
      "47 abre\n",
      "28 abreu\n",
      "13 abri\n",
      "77 abril\n",
      "21 abrimos\n",
      "24 abrindo\n",
      "235 abrir\n",
      "59 abriu\n",
      "14 abrtelecom\n",
      "106 ac\n",
      "8 aca\n",
      "20 acaa\n",
      "9 acabou\n",
      "17 acao\n",
      "33 acarretando\n",
      "20 acb\n",
      "30 acc\n",
      "23 account\n",
      "20 acct\n",
      "41 aceita\n",
      "8 aceitando\n",
      "30 aceito\n",
      "12 aceitou\n",
      "64 acertar\n",
      "102 acerto\n",
      "12 acess\n",
      "43 acessa\n",
      "112 acessado\n",
      "283 acessar\n",
      "599 acesso\n",
      "7 acessorios\n",
      "276 acessos\n",
      "78 ach\n",
      "203 acima\n",
      "8 acionado\n",
      "36 acionar\n",
      "7 acione\n",
      "398 acl\n",
      "8 acm\n",
      "160 acn\n",
      "8 acoa\n",
      "18 acoes\n",
      "25 acompanhamento\n",
      "12 acompanhamos\n",
      "28 acompanhar\n",
      "49 acontece\n",
      "22 acontecendo\n",
      "17 aconteceu\n",
      "14 acordado\n",
      "146 acordo\n",
      "19 acpa\n",
      "10 acredito\n",
      "14 acrescenta\n",
      "8 acrescentar\n",
      "9 actc\n",
      "44 acumulo\n",
      "57 acusa\n",
      "7 acusando\n",
      "69 ad\n",
      "31 ada\n",
      "8 adalberto\n",
      "10 adao\n",
      "11 adcional\n",
      "23 add\n",
      "7 ademar\n",
      "22 aderir\n",
      "25 aderiu\n",
      "57 ades\n",
      "9 adesao\n",
      "9 adi\n",
      "144 adicionado\n",
      "118 adicionais\n",
      "167 adicional\n",
      "109 adicionar\n",
      "22 adilson\n",
      "8 adimplente\n",
      "9 adm\n",
      "17 administracao\n",
      "43 administrador\n",
      "12 administradora\n",
      "10 adnc\n",
      "105 ado\n",
      "14 ados\n",
      "63 adriana\n",
      "45 adriano\n",
      "205 adsl\n",
      "15 ae\n",
      "14 aef\n",
      "15 aei\n",
      "10 aelac\n",
      "29 aelba\n",
      "22 aelbe\n",
      "8 aenxo\n",
      "20 aesc\n",
      "10 aesd\n",
      "12 aeta\n",
      "16 aez\n",
      "66 afeta\n",
      "21 afetada\n",
      "26 afetadas\n",
      "234 afetado\n",
      "68 afetados\n",
      "1200 afetando\n",
      "9 afim\n",
      "71 afirma\n",
      "8 afirmou\n",
      "17 afonso\n",
      "74 ag\n",
      "34 agencia\n",
      "9 agenda\n",
      "21 agendada\n",
      "17 agendado\n",
      "320 agendamento\n",
      "13 agendamentos\n",
      "10 agendamos\n",
      "83 agendar\n",
      "38 agente\n",
      "20 agentes\n",
      "13 agilizar\n",
      "39 agilize\n",
      "28 aglutina\n",
      "19 aglutinado\n",
      "13 aglutinador\n",
      "17 ago\n",
      "7 agostinho\n",
      "72 agosto\n",
      "123 agr\n",
      "247 agrade\n",
      "39 agradecemos\n",
      "9 agrgy\n",
      "7 agrhk\n",
      "16 agrif\n",
      "29 agrig\n",
      "69 agrih\n",
      "9 agrii\n",
      "16 agrupada\n",
      "8 agrupadas\n",
      "23 agrupado\n",
      "155 agrupador\n",
      "48 agrupamento\n",
      "7 agrupar\n",
      "21 agrx\n",
      "13 agry\n",
      "113 aguard\n",
      "31 aguarda\n",
      "363 aguardando\n",
      "27 aguardar\n",
      "8 aguarde\n",
      "53 aguardo\n",
      "34 aguiar\n",
      "16 ai\n",
      "30 aice\n",
      "7 ailton\n",
      "9 aires\n",
      "9 aja\n",
      "17 aju\n",
      "42 ajuda\n",
      "122 ajudar\n",
      "14 ajustada\n",
      "16 ajustado\n",
      "210 ajustar\n",
      "74 ajuste\n",
      "12 ajustes\n",
      "85 al\n",
      "7 alan\n",
      "47 alarme\n",
      "54 alberto\n",
      "27 albuquerque\n",
      "13 alcantara\n",
      "10 aldo\n",
      "62 alega\n",
      "16 alegando\n",
      "8 alegre\n",
      "12 alem\n",
      "18 alencar\n",
      "382 alerta\n",
      "23 alessandra\n",
      "9 alessandro\n",
      "29 alex\n",
      "8 alexander\n",
      "8 alexandra\n",
      "77 alexandre\n",
      "10 alexia\n",
      "13 alfredo\n",
      "8 alho\n",
      "44 alice\n",
      "15 alimentos\n",
      "60 aline\n",
      "29 alinhado\n",
      "12 alinhamento\n",
      "8 allan\n",
      "13 allitems\n",
      "16 allnet\n",
      "144 almeida\n",
      "8 almir\n",
      "50 alone\n",
      "11 alt\n",
      "16 alta\n",
      "8 altccob\n",
      "79 altctec\n",
      "15 altenda\n",
      "10 altendb\n",
      "413 altera\n",
      "33 alteracao\n",
      "20 alterada\n",
      "64 alteradas\n",
      "310 alterado\n",
      "50 alterados\n",
      "14 alterando\n",
      "281 alterar\n",
      "25 altere\n",
      "28 alterou\n",
      "17 altmeio\n",
      "75 alto\n",
      "52 altpdem\n",
      "17 altperc\n",
      "37 alttcir\n",
      "13 aluguel\n",
      "14 alvaro\n",
      "216 alves\n",
      "45 am\n",
      "13 amanda\n",
      "43 amaral\n",
      "11 amaro\n",
      "38 amb\n",
      "27 ambas\n",
      "76 ambiente\n",
      "7 ambientes\n",
      "419 ambos\n",
      "10 amea\n",
      "10 amelia\n",
      "10 amento\n",
      "7 americo\n",
      "44 amorim\n",
      "22 amos\n",
      "13 amostra\n",
      "8 ams\n",
      "180 an\n",
      "156 ana\n",
      "19 analisa\n",
      "19 analisado\n",
      "9 analisados\n",
      "9 analisando\n",
      "217 analisar\n",
      "256 analise\n",
      "22 analises\n",
      "15 analista\n",
      "339 anatel\n",
      "7 anc\n",
      "7 and\n",
      "64 andamento\n",
      "7 andamentos\n",
      "7 andar\n",
      "54 anderson\n",
      "9 andr\n",
      "127 andrade\n",
      "77 andre\n",
      "25 andrea\n",
      "26 andreia\n",
      "9 andressa\n",
      "11 andreza\n",
      "69 anexa\n",
      "34 anexada\n",
      "21 anexadas\n",
      "68 anexado\n",
      "61 anexados\n",
      "110 anexar\n",
      "13 anexas\n",
      "1379 anexo\n",
      "100 anexos\n",
      "37 angela\n",
      "9 angelica\n",
      "8 angelika\n",
      "10 angelita\n",
      "25 angelo\n",
      "23 anjos\n",
      "8 anna\n",
      "28 ano\n",
      "13 anos\n",
      "13 anote\n",
      "16 ans\n",
      "8 ant\n",
      "94 anterior\n",
      "20 anteriores\n",
      "24 anteriormente\n",
      "33 antiga\n",
      "7 antigas\n",
      "142 antigo\n",
      "11 antigos\n",
      "20 antivirus\n",
      "26 antonia\n",
      "170 antonio\n",
      "27 antunes\n",
      "20 aonde\n",
      "50 ap\n",
      "10 apaa\n",
      "19 apaga\n",
      "59 apagada\n",
      "25 apagado\n",
      "305 apagar\n",
      "12 apagou\n",
      "8 aparace\n",
      "9 apare\n",
      "427 aparece\n",
      "71 aparecem\n",
      "137 aparecendo\n",
      "42 aparecer\n",
      "29 apareceu\n",
      "139 aparecida\n",
      "49 aparecido\n",
      "19 aparelho\n",
      "13 aparelhos\n",
      "23 aparente\n",
      "8 apartamento\n",
      "155 apenas\n",
      "44 apesar\n",
      "91 aplic\n",
      "272 aplica\n",
      "27 aplicacao\n",
      "14 aplicacoes\n",
      "28 aplicada\n",
      "49 aplicado\n",
      "13 aplicados\n",
      "167 aplicar\n",
      "23 aplicativo\n",
      "65 apn\n",
      "58 apoio\n",
      "7 aponta\n",
      "7 apontado\n",
      "8 apontando\n",
      "97 apos\n",
      "21 app\n",
      "1003 application\n",
      "49 aprazada\n",
      "12 aprece\n",
      "25 aprensenta\n",
      "608 apresenta\n",
      "162 apresentada\n",
      "173 apresentado\n",
      "9 apresentados\n",
      "69 apresentam\n",
      "580 apresentando\n",
      "23 apresentar\n",
      "88 apresentaram\n",
      "13 apresente\n",
      "131 apresentou\n",
      "12 apresta\n",
      "26 aprisionamento\n",
      "41 aprov\n",
      "46 aprova\n",
      "27 aprovada\n",
      "60 aprovado\n",
      "8 aprovisionado\n",
      "198 aprovisionamento\n",
      "11 aproximado\n",
      "96 apura\n",
      "80 apurado\n",
      "57 apurar\n",
      "10 aq\n",
      "8 aqui\n",
      "25 aquino\n",
      "10 aquisi\n",
      "45 ar\n",
      "8 ara\n",
      "7 aracaju\n",
      "12 aragao\n",
      "8 arantes\n",
      "8 arapongas\n",
      "163 araujo\n",
      "228 arb\n",
      "10 arbo\n",
      "629 arbor\n",
      "148 arbpc\n",
      "60 arbpd\n",
      "33 arbpe\n",
      "18 arbrc\n",
      "8 arbre\n",
      "8 arbsourcetargetprodpcs\n",
      "7 arbtd\n",
      "15 arbtm\n",
      "73 area\n",
      "9 ariane\n",
      "62 arm\n",
      "14 armando\n",
      "41 armario\n",
      "10 arnaldo\n",
      "27 arq\n",
      "7 arqs\n",
      "210 arquivo\n",
      "113 arquivos\n",
      "12 arrecadacao\n",
      "14 arruda\n",
      "600 ars\n",
      "14 arthur\n",
      "7 artur\n",
      "15 asap\n",
      "80 asg\n",
      "13 aspx\n",
      "16 ass\n",
      "13 assessoria\n",
      "7 asset\n",
      "126 assim\n",
      "99 assinante\n",
      "174 assinatura\n",
      "35 assinaturas\n",
      "44 assis\n",
      "7 assistencia\n",
      "47 associa\n",
      "28 associacao\n",
      "61 associada\n",
      "27 associadas\n",
      "222 associado\n",
      "37 associados\n",
      "12 associando\n",
      "64 associar\n",
      "7 assumindo\n",
      "39 assumir\n",
      "29 assumiu\n",
      "13 assuncao\n",
      "16 assunto\n",
      "124 at\n",
      "7 ataide\n",
      "70 ate\n",
      "51 atem\n",
      "24 atemb\n",
      "56 aten\n",
      "23 atenciosamente\n",
      "106 atende\n",
      "233 atendente\n",
      "56 atender\n",
      "11 atendida\n",
      "19 atendido\n",
      "123 atendimento\n",
      "7 atf\n",
      "31 ativ\n",
      "691 ativa\n",
      "38 ativacao\n",
      "56 ativada\n",
      "60 ativado\n",
      "13 ativados\n",
      "22 ativando\n",
      "166 ativar\n",
      "74 ativas\n",
      "342 atividade\n",
      "157 atividades\n",
      "391 ativo\n",
      "143 ativos\n",
      "32 ativou\n",
      "48 ato\n",
      "102 atraso\n",
      "40 atraves\n",
      "22 atrelada\n",
      "46 atrelado\n",
      "7 atrelados\n",
      "44 atribu\n",
      "21 atribui\n",
      "14 atribuido\n",
      "8 atribuir\n",
      "17 atributo\n",
      "77 att\n",
      "21 atu\n",
      "13 atua\n",
      "11 atuais\n",
      "160 atual\n",
      "214 atualiza\n",
      "123 atualizacao\n",
      "30 atualizada\n",
      "10 atualizadas\n",
      "93 atualizado\n",
      "25 atualizados\n",
      "18 atualizando\n",
      "582 atualizar\n",
      "8 atualizarem\n",
      "118 atualizou\n",
      "19 atualizr\n",
      "24 atualmente\n",
      "20 atuar\n",
      "24 atv\n",
      "28 auditoria\n",
      "66 augusto\n",
      "58 aumento\n",
      "19 aurelio\n",
      "9 aurora\n",
      "33 autd\n",
      "220 autentica\n",
      "327 autenticar\n",
      "30 auto\n",
      "340 autom\n",
      "42 automatica\n",
      "78 automaticamente\n",
      "7 automaticas\n",
      "75 automatico\n",
      "117 autor\n",
      "50 autora\n",
      "14 autoridade\n",
      "94 autoriza\n",
      "10 autorizada\n",
      "42 autorizado\n",
      "17 autorizador\n",
      "11 autorizados\n",
      "23 autorizar\n",
      "16 aux\n",
      "10 auxiliadora\n",
      "7 auxiliamos\n",
      "41 auxiliar\n",
      "18 auxilio\n",
      "26 av\n",
      "24 ava\n",
      "32 avaliar\n",
      "92 avan\n",
      "10 avancado\n",
      "37 avaya\n",
      "14 averiguar\n",
      "22 avila\n",
      "12 avisar\n",
      "13 avise\n",
      "10 aviso\n",
      "13 avulsa\n",
      "93 avulso\n",
      "34 avulsos\n",
      "9 axa\n",
      "7 azambuja\n",
      "58 azevedo\n",
      "1976 ba\n",
      "36 back\n",
      "208 backlog\n",
      "103 backoffice\n",
      "20 backup\n",
      "40 bahia\n",
      "25 bairro\n",
      "381 baixa\n",
      "47 baixada\n",
      "71 baixadas\n",
      "17 baixado\n",
      "46 baixar\n",
      "9 baixas\n",
      "27 baixo\n",
      "9 baixou\n",
      "13 banc\n",
      "111 banco\n",
      "251 banda\n",
      "12 bandeira\n",
      "11 baptista\n",
      "17 barbara\n",
      "110 barbosa\n",
      "11 barboza\n",
      "9 barcelos\n",
      "25 barra\n",
      "57 barramento\n",
      "24 barras\n",
      "29 barreto\n",
      "72 barros\n",
      "11 barroso\n",
      "22 bartoline\n",
      "132 bas\n",
      "319 base\n",
      "57 basico\n",
      "9 bastante\n",
      "27 bastos\n",
      "11 bat\n",
      "12 batana\n",
      "15 batch\n",
      "32 bate\n",
      "115 batimento\n",
      "86 batista\n",
      "37 bauer\n",
      "55 bb\n",
      "22 bbiprd\n",
      "83 bc\n",
      "56 bcb\n",
      "249 bd\n",
      "13 bdea\n",
      "11 bded\n",
      "72 bdo\n",
      "12 bds\n",
      "25 beatriz\n",
      "33 belo\n",
      "29 bem\n",
      "15 ben\n",
      "8 benedita\n",
      "20 benedito\n",
      "261 benef\n",
      "80 beneficio\n",
      "15 beneficios\n",
      "19 bento\n",
      "14 bernadete\n",
      "7 bernardes\n",
      "28 bernardo\n",
      "11 bet\n",
      "52 bezerra\n",
      "7 bh\n",
      "93 bhe\n",
      "10 bhya\n",
      "8 bhyd\n",
      "12 bianca\n",
      "16 bib\n",
      "42 biblioteca\n",
      "166 bif\n",
      "7 bilhetagem\n",
      "117 bilhete\n",
      "27 bilhetes\n",
      "271 bill\n",
      "14 billing\n",
      "81 bin\n",
      "14 binado\n",
      "19 bip\n",
      "15 bispo\n",
      "10 bitencourt\n",
      "175 bito\n",
      "144 bitos\n",
      "15 bko\n",
      "669 bl\n",
      "17 bla\n",
      "11 black\n",
      "10 blackberry\n",
      "7 blica\n",
      "15 blico\n",
      "16 blindado\n",
      "33 blindagem\n",
      "16 bll\n",
      "22 blm\n",
      "10 bloco\n",
      "15 bloddc\n",
      "8 blomov\n",
      "8 bloq\n",
      "102 bloqueada\n",
      "8 bloqueadas\n",
      "172 bloqueado\n",
      "25 bloqueados\n",
      "8 bloqueando\n",
      "42 bloquear\n",
      "492 bloqueio\n",
      "21 bloqueios\n",
      "7 bloquieo\n",
      "150 bmc\n",
      "163 bo\n",
      "250 boa\n",
      "10 boas\n",
      "19 bol\n",
      "25 boleto\n",
      "275 bom\n",
      "18 bonifica\n",
      "71 bonus\n",
      "12 borba\n",
      "66 borges\n",
      "100 bot\n",
      "12 botao\n",
      "33 bov\n",
      "508 bp\n",
      "31 bpr\n",
      "30 bps\n",
      "10 bqe\n",
      "124 br\n",
      "8 bracp\n",
      "15 bradesco\n",
      "39 braga\n",
      "12 braile\n",
      "179 branco\n",
      "18 brandao\n",
      "98 brasil\n",
      "7 brasileira\n",
      "13 braz\n",
      "7 breno\n",
      "8 brf\n",
      "8 bri\n",
      "7 brica\n",
      "53 brito\n",
      "214 brt\n",
      "47 bruna\n",
      "56 bruno\n",
      "14 bs\n",
      "223 bsa\n",
      "16 bsim\n",
      "12 bt\n",
      "9 btcc\n",
      "23 btdf\n",
      "18 bueno\n",
      "453 bundle\n",
      "21 bundles\n",
      "122 busca\n",
      "9 business\n",
      "20 bva\n",
      "12 by\n",
      "103 ca\n",
      "53 cabo\n",
      "23 cabral\n",
      "20 cache\n",
      "17 cad\n",
      "32 cadastra\n",
      "176 cadastrada\n",
      "44 cadastradas\n",
      "240 cadastrado\n",
      "86 cadastrados\n",
      "66 cadastrais\n",
      "58 cadastral\n",
      "45 cadastramento\n",
      "210 cadastrar\n",
      "11 cadastre\n",
      "483 cadastro\n",
      "9 cadastrocliente\n",
      "8 cadastros\n",
      "17 cadastrou\n",
      "14 cadeia\n",
      "7 cadop\n",
      "15 caetano\n",
      "19 cai\n",
      "58 caindo\n",
      "10 caio\n",
      "53 caiu\n",
      "131 caixa\n",
      "9 calcados\n",
      "12 caldas\n",
      "51 call\n",
      "13 camapanha\n",
      "13 camara\n",
      "31 camargo\n",
      "34 camila\n",
      "10 camile\n",
      "7 camilla\n",
      "7 camilo\n",
      "29 caminho\n",
      "9 camp\n",
      "361 campanha\n",
      "85 campanhas\n",
      "272 campo\n",
      "132 campos\n",
      "8 can\n",
      "20 canais\n",
      "125 canal\n",
      "28 canc\n",
      "33 cancel\n",
      "59 cancela\n",
      "410 cancelada\n",
      "64 canceladas\n",
      "438 cancelado\n",
      "56 cancelados\n",
      "1494 cancelamento\n",
      "50 cancelamentos\n",
      "24 cancelando\n",
      "576 cancelar\n",
      "10 cancele\n",
      "39 cancelou\n",
      "10 candida\n",
      "21 candido\n",
      "7 car\n",
      "97 caracter\n",
      "8 caracteres\n",
      "40 caracteristicas\n",
      "23 card\n",
      "83 cardoso\n",
      "9 cardozo\n",
      "77 carga\n",
      "8 cargas\n",
      "16 cargo\n",
      "7 cargos\n",
      "11 carina\n",
      "8 carine\n",
      "52 carla\n",
      "171 carlos\n",
      "68 carmo\n",
      "40 carneiro\n",
      "42 carolina\n",
      "34 caroline\n",
      "215 caros\n",
      "41 carrega\n",
      "8 carregado\n",
      "21 carregados\n",
      "15 carregando\n",
      "14 carregar\n",
      "89 cart\n",
      "11 cartao\n",
      "79 carte\n",
      "148 carvalho\n",
      "58 casa\n",
      "23 cascavel\n",
      "34 case\n",
      "73 casella\n",
      "151 caso\n",
      "236 casos\n",
      "22 cassia\n",
      "8 cassio\n",
      "70 castro\n",
      "163 cat\n",
      "43 catarina\n",
      "10 categ\n",
      "534 categoria\n",
      "34 categoriza\n",
      "7 catfra\n",
      "8 catia\n",
      "7 catonx\n",
      "171 causa\n",
      "36 causando\n",
      "19 cavalcante\n",
      "17 cb\n",
      "114 cba\n",
      "30 cbb\n",
      "55 cbc\n",
      "169 cc\n",
      "11 cca\n",
      "1262 cco\n",
      "37 ccto\n",
      "57 cd\n",
      "114 cdi\n",
      "7 cdigatprdd\n",
      "7 cdipw\n",
      "73 cdr\n",
      "111 cdrs\n",
      "106 ce\n",
      "7 ceara\n",
      "7 ceasing\n",
      "19 cecilia\n",
      "79 cel\n",
      "30 celia\n",
      "7 celio\n",
      "22 celso\n",
      "94 celular\n",
      "23 celulares\n",
      "76 cen\n",
      "13 cenario\n",
      "9 cennario\n",
      "47 center\n",
      "22 centrais\n",
      "106 central\n",
      "43 centro\n",
      "49 cep\n",
      "15 cerca\n",
      "11 cerqueira\n",
      "7 certa\n",
      "23 certo\n",
      "77 cesar\n",
      "17 cesta\n",
      "20 cezar\n",
      "82 cf\n",
      "82 cfg\n",
      "14 cg\n",
      "51 cga\n",
      "17 cgb\n",
      "177 cgc\n",
      "11 cgd\n",
      "11 cgds\n",
      "44 cge\n",
      "21 cgf\n",
      "16 cgo\n",
      "17 cgocs\n",
      "104 cgs\n",
      "7 cgslibte\n",
      "82 ch\n",
      "26 cha\n",
      "51 chagas\n",
      "103 cham\n",
      "21 chama\n",
      "49 chamada\n",
      "98 chamadas\n",
      "404 chamado\n",
      "175 chamador\n",
      "26 chamados\n",
      "13 charlene\n",
      "23 charles\n",
      "93 chave\n",
      "37 chaves\n",
      "31 chega\n",
      "18 chegando\n",
      "46 chegar\n",
      "19 chegaram\n",
      "56 chegou\n",
      "13 chido\n",
      "72 chip\n",
      "18 chips\n",
      "9 chmd\n",
      "7 christiane\n",
      "55 chrome\n",
      "59 cia\n",
      "16 cicero\n",
      "224 ciclo\n",
      "32 ciclos\n",
      "35 cidade\n",
      "30 cielo\n",
      "104 ciente\n",
      "8 cim\n",
      "11 cima\n",
      "10 cinco\n",
      "20 cinema\n",
      "9 cintia\n",
      "245 cio\n",
      "146 cios\n",
      "7 cir\n",
      "7 circ\n",
      "759 circuito\n",
      "179 circuitos\n",
      "10 circula\n",
      "7 citada\n",
      "14 citado\n",
      "15 citados\n",
      "20 citrix\n",
      "22 city\n",
      "37 cj\n",
      "14 cka\n",
      "8 ckz\n",
      "12 cl\n",
      "10 clara\n",
      "599 clarify\n",
      "77 claro\n",
      "130 classe\n",
      "11 classificados\n",
      "8 claudete\n",
      "52 claudia\n",
      "7 claudinei\n",
      "10 claudino\n",
      "58 claudio\n",
      "9 clck\n",
      "52 cld\n",
      "24 clean\n",
      "8 cleanup\n",
      "21 cleber\n",
      "13 cleide\n",
      "25 cleinte\n",
      "12 cleonice\n",
      "98 cli\n",
      "57 clica\n",
      "13 clicado\n",
      "13 clicamos\n",
      "8 clicando\n",
      "133 clicar\n",
      "1122 click\n",
      "60 clie\n",
      "23 client\n",
      "1043 cliente\n",
      "10 clienteoperacao\n",
      "661 clientes\n",
      "8 cliete\n",
      "10 clietne\n",
      "18 clinica\n",
      "12 clinte\n",
      "17 clka\n",
      "46 clkb\n",
      "102 clke\n",
      "7 clkp\n",
      "7 cloud\n",
      "126 clt\n",
      "25 cly\n",
      "22 cm\n",
      "57 cmd\n",
      "11 cmf\n",
      "237 cmr\n",
      "105 cms\n",
      "34 cn\n",
      "9 cnf\n",
      "53 cnica\n",
      "126 cnico\n",
      "28 cnicos\n",
      "17 cnl\n",
      "563 cnpj\n",
      "9 cns\n",
      "137 co\n",
      "27 cob\n",
      "11 cober\n",
      "8 cobertura\n",
      "15 cobilling\n",
      "167 cobprd\n",
      "11 cobra\n",
      "49 cobrada\n",
      "27 cobradas\n",
      "251 cobrado\n",
      "19 cobrados\n",
      "347 cobran\n",
      "163 cobranca\n",
      "74 cobrando\n",
      "21 cobrar\n",
      "37 cobre\n",
      "7 cocncluir\n",
      "168 cod\n",
      "10 code\n",
      "135 codigo\n",
      "8 codigos\n",
      "11 coelba\n",
      "67 coelho\n",
      "12 coimbra\n",
      "94 colaborador\n",
      "61 colaboradora\n",
      "39 colaboradores\n",
      "9 coleta\n",
      "7 coletar\n",
      "53 coloca\n",
      "34 colocada\n",
      "21 colocado\n",
      "19 colocamos\n",
      "29 colocando\n",
      "136 colocar\n",
      "8 coloco\n",
      "12 colocou\n",
      "34 coluna\n",
      "8 coma\n",
      "375 comando\n",
      "34 comandos\n",
      "14 combate\n",
      "30 combinado\n",
      "87 combo\n",
      "63 combos\n",
      "28 comcampoferta\n",
      "24 come\n",
      "38 coment\n",
      "96 comercial\n",
      "118 comercio\n",
      "16 comfra\n",
      "17 comissionadas\n",
      "52 comp\n",
      "15 companhia\n",
      "9 compartilhada\n",
      "11 compartilhado\n",
      "23 compartilhamento\n",
      "19 compat\n",
      "7 compativel\n",
      "12 complementar\n",
      "34 complemento\n",
      "9 complementos\n",
      "95 completa\n",
      "19 completada\n",
      "10 completado\n",
      "11 completar\n",
      "128 completo\n",
      "7 complexa\n",
      "31 component\n",
      "59 componente\n",
      "105 componentes\n",
      "10 comportamento\n",
      "27 composi\n",
      "30 comprobat\n",
      "22 comprova\n",
      "7 comprovam\n",
      "13 comprovando\n",
      "18 comprovante\n",
      "7 comprovantes\n",
      "16 comtemplados\n",
      "15 comum\n",
      "82 comunica\n",
      "17 comunicacao\n",
      "11 comunique\n",
      "10 comuta\n",
      "17 comverse\n",
      "25 con\n",
      "26 concede\n",
      "9 conceder\n",
      "14 concedida\n",
      "59 concedido\n",
      "24 concei\n",
      "61 conceicao\n",
      "8 concentrador\n",
      "23 concess\n",
      "513 conclu\n",
      "21 concluam\n",
      "73 conclui\n",
      "66 concluida\n",
      "15 concluidas\n",
      "202 concluido\n",
      "14 concluidos\n",
      "13 concluindo\n",
      "535 concluir\n",
      "17 concluiu\n",
      "317 conclus\n",
      "22 conclusao\n",
      "12 cond\n",
      "101 condi\n",
      "71 condicao\n",
      "7 condicionada\n",
      "25 condominio\n",
      "13 cone\n",
      "35 conec\n",
      "11 conect\n",
      "375 conectado\n",
      "9 conector\n",
      "10 conex\n",
      "28 conf\n",
      "22 confeccoes\n",
      "8 confederacao\n",
      "33 confer\n",
      "9 conferem\n",
      "85 confian\n",
      "11 config\n",
      "193 configura\n",
      "8 configuracao\n",
      "13 configurada\n",
      "48 configurado\n",
      "141 configurador\n",
      "26 configurados\n",
      "212 configurar\n",
      "78 confira\n",
      "91 confirma\n",
      "25 confirmado\n",
      "12 confirmados\n",
      "39 confirmamos\n",
      "16 confirmando\n",
      "73 confirmar\n",
      "7 confirmou\n",
      "95 conflito\n",
      "514 conforme\n",
      "7 congela\n",
      "120 conjunta\n",
      "10 conjunto\n",
      "81 connect\n",
      "29 conosco\n",
      "7 cons\n",
      "505 consegue\n",
      "121 conseguem\n",
      "58 consegui\n",
      "7 conseguia\n",
      "10 conseguido\n",
      "169 conseguimos\n",
      "327 conseguindo\n",
      "62 conseguir\n",
      "11 conseguiram\n",
      "16 conseguirmos\n",
      "52 conseguiu\n",
      "46 conseq\n",
      "36 consequ\n",
      "36 consequentemente\n",
      "8 considerando\n",
      "7 considerar\n",
      "18 consiga\n",
      "74 consigo\n",
      "17 consolidado\n",
      "475 consta\n",
      "147 constam\n",
      "53 constando\n",
      "19 constar\n",
      "16 constatado\n",
      "12 constatamos\n",
      "15 construcao\n",
      "11 construcoes\n",
      "15 construtora\n",
      "302 consulta\n",
      "17 consultado\n",
      "21 consultamos\n",
      "58 consultando\n",
      "199 consultar\n",
      "13 consultas\n",
      "54 consultor\n",
      "7 consultora\n",
      "20 consultoria\n",
      "14 consumida\n",
      "12 consumido\n",
      "50 consumidor\n",
      "10 consumidora\n",
      "117 consumo\n",
      "209 cont\n",
      "702 conta\n",
      "32 contabilidade\n",
      "17 contactar\n",
      "339 contas\n",
      "24 contatar\n",
      "1197 contato\n",
      "80 contatos\n",
      "22 contax\n",
      "9 conte\n",
      "7 contem\n",
      "14 contempla\n",
      "19 contemplado\n",
      "28 contendo\n",
      "9 contest\n",
      "229 contesta\n",
      "8 contestacoes\n",
      "54 contestada\n",
      "11 contestadas\n",
      "19 contestado\n",
      "13 contestar\n",
      "13 contidas\n",
      "52 conting\n",
      "13 contingencia\n",
      "15 contingencial\n",
      "379 continua\n",
      "58 continuam\n",
      "58 continuar\n",
      "90 continuidade\n",
      "18 continuou\n",
      "25 contr\n",
      "32 contrata\n",
      "16 contratada\n",
      "15 contratado\n",
      "7 contratadooi\n",
      "7 contratados\n",
      "18 contratar\n",
      "694 contrato\n",
      "84 contratos\n",
      "56 contratou\n",
      "8 contratual\n",
      "14 contro\n",
      "34 control\n",
      "20 controlado\n",
      "505 controle\n",
      "792 controlm\n",
      "12 controlr\n",
      "10 conv\n",
      "93 convergente\n",
      "55 convergentes\n",
      "9 convers\n",
      "23 cooperativa\n",
      "12 cooperativas\n",
      "9 coordenador\n",
      "8 coordenadora\n",
      "8 cor\n",
      "33 cordeiro\n",
      "10 core\n",
      "19 corp\n",
      "33 corpo\n",
      "13 corporativa\n",
      "68 corporativo\n",
      "7 corrde\n",
      "331 corre\n",
      "50 correa\n",
      "13 correcao\n",
      "49 correia\n",
      "18 correios\n",
      "37 corrente\n",
      "12 correspond\n",
      "14 corresponde\n",
      "8 correspondencia\n",
      "20 correspondente\n",
      "60 correspondentes\n",
      "87 correta\n",
      "146 corretamente\n",
      "16 corretas\n",
      "156 correto\n",
      "20 corretora\n",
      "95 corretos\n",
      "15 corridos\n",
      "17 corrigi\n",
      "8 corrigida\n",
      "36 corrigido\n",
      "7 corrigidos\n",
      "296 corrigir\n",
      "60 corte\n",
      "7 cortes\n",
      "14 cortip\n",
      "180 costa\n",
      "21 coutinho\n",
      "12 couto\n",
      "14 cp\n",
      "20 cpa\n",
      "10 cpct\n",
      "200 cpe\n",
      "8 cpecom\n",
      "535 cpf\n",
      "36 cpfcnpj\n",
      "12 cpfs\n",
      "11 cps\n",
      "856 cr\n",
      "11 cracp\n",
      "76 credito\n",
      "31 creditos\n",
      "29 crescente\n",
      "330 cria\n",
      "21 criacao\n",
      "27 criada\n",
      "49 criado\n",
      "14 criados\n",
      "74 criar\n",
      "21 criem\n",
      "13 criou\n",
      "48 cristiane\n",
      "23 cristiano\n",
      "116 cristina\n",
      "8 cristine\n",
      "9 crit\n",
      "907 critica\n",
      "50 criticada\n",
      "10 criticadas\n",
      "16 criticado\n",
      "27 criticados\n",
      "14 criticando\n",
      "13 criticas\n",
      "8 crjd\n",
      "838 crm\n",
      "17 crmbat\n",
      "9 crmcriatabela\n",
      "23 crmextrator\n",
      "12 crmmktgtwd\n",
      "56 crmoibatd\n",
      "20 crmoiftp\n",
      "24 crmpubsp\n",
      "20 crmshl\n",
      "7 crmshlinadeim\n",
      "77 crmshlsp\n",
      "7 crmshpsp\n",
      "18 crmsp\n",
      "29 cronol\n",
      "29 crtd\n",
      "69 cruz\n",
      "52 crv\n",
      "7 cs\n",
      "18 csp\n",
      "13 ct\n",
      "157 cta\n",
      "1577 ctm\n",
      "306 cto\n",
      "14 ctr\n",
      "82 ctrl\n",
      "128 ctt\n",
      "16 ctxsalpb\n",
      "7 cuidados\n",
      "8 cuja\n",
      "38 cujo\n",
      "26 cula\n",
      "35 culas\n",
      "11 cumprimento\n",
      "67 cunha\n",
      "20 curitiba\n",
      "13 cust\n",
      "26 customer\n",
      "9 cvp\n",
      "19 cx\n",
      "71 dacc\n",
      "33 dad\n",
      "21 dada\n",
      "57 dado\n",
      "483 dados\n",
      "7 daiana\n",
      "19 daiane\n",
      "131 daily\n",
      "9 dal\n",
      "13 dalva\n",
      "16 damasceno\n",
      "97 dando\n",
      "24 dani\n",
      "62 daniel\n",
      "143 daniela\n",
      "26 daniele\n",
      "11 danielle\n",
      "23 danilo\n",
      "21 dantas\n",
      "12 danubia\n",
      "173 dar\n",
      "7 darem\n",
      "26 darmos\n",
      "278 data\n",
      "24 dataquality\n",
      "22 datas\n",
      "13 date\n",
      "49 david\n",
      "10 dayane\n",
      "19 dd\n",
      "197 ddd\n",
      "9 ddmmaaaa\n",
      "87 ddr\n",
      "8 debitando\n",
      "123 debito\n",
      "50 debitos\n",
      "23 debora\n",
      "13 dec\n",
      "22 decurso\n",
      "39 dedicado\n",
      "14 defeito\n",
      "18 defini\n",
      "11 definido\n",
      "32 definitiva\n",
      "7 definitivamente\n",
      "8 definitivo\n",
      "7 degrada\n",
      "13 deise\n",
      "99 deixa\n",
      "34 deixam\n",
      "106 deixando\n",
      "47 deixar\n",
      "11 deixou\n",
      "9 delgado\n",
      "154 demais\n",
      "70 demanda\n",
      "13 demandante\n",
      "22 demandas\n",
      "14 demilson\n",
      "12 demonstrado\n",
      "20 demora\n",
      "14 demorando\n",
      "9 denilson\n",
      "26 denise\n",
      "176 dentro\n",
      "9 dep\n",
      "201 dependente\n",
      "44 dependentes\n",
      "9 deposito\n",
      "31 der\n",
      "19 deriva\n",
      "9 des\n",
      "72 desab\n",
      "12 desabilita\n",
      "15 desabilitada\n",
      "75 desabilitado\n",
      "16 desassocia\n",
      "18 desassociado\n",
      "7 desassociados\n",
      "66 desassociar\n",
      "105 desativa\n",
      "10 desativaacesso\n",
      "48 desativada\n",
      "105 desativado\n",
      "107 desativar\n",
      "23 desatualizado\n",
      "8 desatualizados\n",
      "8 desbloqueada\n",
      "16 desbloqueado\n",
      "27 desbloqueados\n",
      "61 desbloquear\n",
      "12 desbloqueiem\n",
      "275 desbloqueio\n",
      "14 desbloqueou\n",
      "112 desc\n",
      "10 desconectada\n",
      "7 desconectado\n",
      "87 desconex\n",
      "19 desconfigurar\n",
      "23 desconhece\n",
      "177 desconto\n",
      "33 descontos\n",
      "10 descreve\n",
      "237 descrever\n",
      "188 descri\n",
      "14 descric\n",
      "32 descricao\n",
      "8 descrita\n",
      "22 descrito\n",
      "585 desde\n",
      "277 deseja\n",
      "85 desejada\n",
      "15 desejado\n",
      "7 desejo\n",
      "18 desenvolvimento\n",
      "16 desfazer\n",
      "84 designa\n",
      "10 designacao\n",
      "28 designada\n",
      "43 designado\n",
      "176 designar\n",
      "16 desinstalar\n",
      "8 desist\n",
      "72 desistente\n",
      "48 desistiu\n",
      "57 desk\n",
      "11 desmembrada\n",
      "20 desmembrado\n",
      "172 desmembramento\n",
      "135 desmembrar\n",
      "17 desmembrou\n",
      "7 desmenbrar\n",
      "12 desmigra\n",
      "58 desmigrar\n",
      "40 desnecess\n",
      "15 despacho\n",
      "13 destaque\n",
      "9 destinat\n",
      "21 destino\n",
      "7 desvincula\n",
      "11 desvinculada\n",
      "31 desvinculado\n",
      "53 desvincular\n",
      "17 det\n",
      "21 detalha\n",
      "122 detalhada\n",
      "273 detalhadamente\n",
      "13 detalhadas\n",
      "14 detalhado\n",
      "112 detalhamento\n",
      "45 detalhar\n",
      "67 detalhe\n",
      "52 detalhes\n",
      "86 detectados\n",
      "27 determina\n",
      "16 determinado\n",
      "78 deu\n",
      "9 deus\n",
      "18 deve\n",
      "12 dever\n",
      "30 devida\n",
      "69 devidamente\n",
      "33 devidas\n",
      "259 devido\n",
      "7 devidos\n",
      "16 devolu\n",
      "50 devolvida\n",
      "10 devolvido\n",
      "16 dez\n",
      "43 dezembro\n",
      "307 df\n",
      "38 dg\n",
      "103 di\n",
      "559 dia\n",
      "10 diana\n",
      "55 diante\n",
      "145 diaria\n",
      "16 diariamente\n",
      "47 diario\n",
      "273 dias\n",
      "14 diasnatarefa\n",
      "7 dica\n",
      "11 dico\n",
      "37 diego\n",
      "13 diferen\n",
      "137 diferente\n",
      "51 diferentes\n",
      "258 dificuldade\n",
      "62 dificuldades\n",
      "10 dig\n",
      "27 digita\n",
      "23 digitado\n",
      "20 digitais\n",
      "276 digital\n",
      "69 digitar\n",
      "17 digito\n",
      "9 digitos\n",
      "24 digitronco\n",
      "209 digo\n",
      "27 digos\n",
      "19 diniz\n",
      "10 dio\n",
      "15 diogo\n",
      "27 dir\n",
      "25 direcionada\n",
      "45 direcionado\n",
      "8 direcionamento\n",
      "16 direcionar\n",
      "39 direito\n",
      "18 diret\n",
      "20 diretamente\n",
      "39 direto\n",
      "10 diretoria\n",
      "10 diretorio\n",
      "185 dispon\n",
      "90 disponibilidade\n",
      "106 disponibiliza\n",
      "23 disponibilizada\n",
      "25 disponibilizadas\n",
      "65 disponibilizado\n",
      "25 disponibilizados\n",
      "15 disponibilizando\n",
      "40 disponibilizar\n",
      "17 disponiveis\n",
      "111 disponivel\n",
      "19 disputa\n",
      "40 dissocia\n",
      "11 dissociar\n",
      "14 dist\n",
      "11 distancia\n",
      "13 distribuicao\n",
      "26 distribuidora\n",
      "7 distrito\n",
      "93 dito\n",
      "29 ditos\n",
      "165 diverg\n",
      "89 divergencia\n",
      "8 divergencias\n",
      "74 divergente\n",
      "37 divergentes\n",
      "20 diversas\n",
      "64 diversos\n",
      "11 divina\n",
      "7 divis\n",
      "26 dizendo\n",
      "202 dk\n",
      "19 dm\n",
      "134 dn\n",
      "82 dnc\n",
      "22 doa\n",
      "33 doado\n",
      "306 doadora\n",
      "9 dobro\n",
      "232 doc\n",
      "40 documento\n",
      "8 documentoassociado\n",
      "8 documentos\n",
      "7 docx\n",
      "135 dois\n",
      "58 dom\n",
      "7 domic\n",
      "28 domingos\n",
      "16 domingues\n",
      "31 dominio\n",
      "15 dores\n",
      "29 douglas\n",
      "9 dourado\n",
      "7 dowell\n",
      "72 downgrade\n",
      "105 dp\n",
      "16 dqx\n",
      "7 ds\n",
      "52 dsa\n",
      "8 dslam\n",
      "64 dsnames\n",
      "112 dt\n",
      "15 dta\n",
      "113 dth\n",
      "44 duarte\n",
      "132 duas\n",
      "8 due\n",
      "7 dulce\n",
      "11 dulo\n",
      "22 dup\n",
      "24 dupl\n",
      "13 duplicada\n",
      "8 duplicadas\n",
      "30 duplicado\n",
      "67 duplicados\n",
      "127 duplicidade\n",
      "7 dura\n",
      "76 durante\n",
      "19 dutra\n",
      "41 duvidas\n",
      "29 dvr\n",
      "30 dw\n",
      "24 ea\n",
      "572 eai\n",
      "22 ebilling\n",
      "9 economica\n",
      "14 ed\n",
      "19 eder\n",
      "8 edgar\n",
      "22 edificio\n",
      "12 edilson\n",
      "8 editar\n",
      "7 editora\n",
      "8 edmar\n",
      "10 edmilson\n",
      "16 edna\n",
      "17 edson\n",
      "95 eduardo\n",
      "16 educa\n",
      "12 educacao\n",
      "14 efetiva\n",
      "13 efetivar\n",
      "28 efetivo\n",
      "17 efetua\n",
      "51 efetuada\n",
      "11 efetuadas\n",
      "51 efetuado\n",
      "20 efetuamos\n",
      "43 efetuando\n",
      "304 efetuar\n",
      "40 efetuem\n",
      "120 efetuou\n",
      "11 eh\n",
      "17 eild\n",
      "29 eireli\n",
      "17 el\n",
      "21 elaine\n",
      "58 eleg\n",
      "78 elemento\n",
      "110 elementos\n",
      "9 eletronica\n",
      "9 eliana\n",
      "28 eliane\n",
      "26 elias\n",
      "7 elisabeth\n",
      "7 elisangela\n",
      "13 elizabete\n",
      "22 elizabeth\n",
      "9 ellen\n",
      "7 elton\n",
      "7 elvira\n",
      "14 elza\n",
      "12 ema\n",
      "302 email\n",
      "8 embalagens\n",
      "18 embora\n",
      "85 embratel\n",
      "15 emerson\n",
      "7 emilia\n",
      "7 emilio\n",
      "43 emiss\n",
      "32 emissao\n",
      "7 emite\n",
      "10 emitida\n",
      "7 emitidas\n",
      "7 emitindo\n",
      "49 emitir\n",
      "27 emp\n",
      "12 empacotamento\n",
      "12 empreendimentos\n",
      "198 empresa\n",
      "7 empresariais\n",
      "73 empresarial\n",
      "11 empresas\n",
      "9 en\n",
      "19 enc\n",
      "15 encaminhada\n",
      "8 encaminhadas\n",
      "37 encaminhado\n",
      "17 encaminhados\n",
      "19 encaminhamento\n",
      "45 encaminhar\n",
      "10 encaminhou\n",
      "44 encerra\n",
      "318 encerrada\n",
      "50 encerradas\n",
      "466 encerrado\n",
      "77 encerrados\n",
      "43 encerram\n",
      "490 encerramento\n",
      "11 encerrando\n",
      "616 encerrar\n",
      "15 encerre\n",
      "23 encerrou\n",
      "549 encontra\n",
      "90 encontrada\n",
      "9 encontradas\n",
      "206 encontrado\n",
      "21 encontrados\n",
      "279 encontram\n",
      "34 encontramos\n",
      "24 encontrar\n",
      "9 encontrasse\n",
      "10 encontravam\n",
      "92 end\n",
      "480 endere\n",
      "13 endereco\n",
      "10 energia\n",
      "7 energisa\n",
      "7 eng\n",
      "40 engenharia\n",
      "11 engenheiros\n",
      "25 enriquecendo\n",
      "45 enriquecer\n",
      "8 enriquecidas\n",
      "14 enriquecido\n",
      "57 enriquecidos\n",
      "16 enriquecimento\n",
      "41 ent\n",
      "87 entanto\n",
      "37 entemente\n",
      "36 entender\n",
      "124 enter\n",
      "98 entra\n",
      "97 entrada\n",
      "9 entrando\n",
      "227 entrar\n",
      "12 entraram\n",
      "16 entrega\n",
      "478 entregue\n",
      "127 entretanto\n",
      "445 entrou\n",
      "19 entry\n",
      "8 env\n",
      "34 envia\n",
      "323 enviada\n",
      "22 enviadas\n",
      "94 enviado\n",
      "29 enviados\n",
      "52 enviamos\n",
      "43 enviando\n",
      "216 enviar\n",
      "7 enviarmos\n",
      "206 envio\n",
      "18 enviou\n",
      "13 envolvido\n",
      "18 envolvidos\n",
      "7 eo\n",
      "69 eot\n",
      "98 epp\n",
      "7 eq\n",
      "115 eqn\n",
      "8 equip\n",
      "14 equipamento\n",
      "36 equipamentos\n",
      "86 equipe\n",
      "7 er\n",
      "12 erica\n",
      "7 erick\n",
      "11 erika\n",
      "12 ero\n",
      "89 err\n",
      "33 errada\n",
      "47 errado\n",
      "12 errados\n",
      "826 erro\n",
      "7 errocriandoosoms\n",
      "18 erroneamente\n",
      "20 error\n",
      "146 erros\n",
      "1283 es\n",
      "10 esb\n",
      "40 escolha\n",
      "14 escolher\n",
      "7 escolhida\n",
      "7 escopo\n",
      "8 escrito\n",
      "8 esmeralda\n",
      "25 esp\n",
      "10 espa\n",
      "26 espec\n",
      "28 especiais\n",
      "80 especial\n",
      "10 especialista\n",
      "12 especificada\n",
      "19 especificado\n",
      "22 especifico\n",
      "10 espelhamento\n",
      "12 espelhar\n",
      "314 espelho\n",
      "39 espera\n",
      "16 esperado\n",
      "11 espirito\n",
      "27 esqueceu\n",
      "8 esqueci\n",
      "42 est\n",
      "68 estacao\n",
      "7 estacoes\n",
      "158 estado\n",
      "8 estados\n",
      "39 estadual\n",
      "1190 estah\n",
      "70 estando\n",
      "96 estao\n",
      "170 estar\n",
      "18 estarem\n",
      "8 estela\n",
      "7 ester\n",
      "7 esteves\n",
      "26 estimado\n",
      "11 estornado\n",
      "43 estorno\n",
      "21 estourado\n",
      "16 estudo\n",
      "38 etapa\n",
      "10 etapas\n",
      "54 etc\n",
      "9 eth\n",
      "10 etiquetas\n",
      "7 etx\n",
      "11 eunice\n",
      "13 eustaquio\n",
      "15 ev\n",
      "17 eva\n",
      "13 evandro\n",
      "16 evangelista\n",
      "160 evento\n",
      "185 eventos\n",
      "11 eventual\n",
      "9 everton\n",
      "1254 evid\n",
      "399 evidencia\n",
      "18 evidenciada\n",
      "208 evidenciado\n",
      "481 evidencias\n",
      "7 evitadas\n",
      "55 evitar\n",
      "9 evolu\n",
      "46 ex\n",
      "17 exce\n",
      "10 excedente\n",
      "19 excedentes\n",
      "13 excel\n",
      "25 exceto\n",
      "55 exclu\n",
      "13 excluido\n",
      "72 excluir\n",
      "48 exclus\n",
      "18 exclusao\n",
      "209 exclusiva\n",
      "48 exec\n",
      "238 execu\n",
      "205 execucao\n",
      "29 executa\n",
      "139 executada\n",
      "23 executadas\n",
      "92 executado\n",
      "12 executados\n",
      "219 executando\n",
      "244 executar\n",
      "7 executou\n",
      "105 exemplo\n",
      "85 exemplos\n",
      "30 exibe\n",
      "12 exibida\n",
      "29 exibido\n",
      "8 exibir\n",
      "9 exigida\n",
      "32 exist\n",
      "328 existe\n",
      "129 existem\n",
      "75 existente\n",
      "14 existentes\n",
      "7 exists\n",
      "8 exito\n",
      "226 expediter\n",
      "110 expert\n",
      "8 expira\n",
      "9 expirada\n",
      "29 expirado\n",
      "7 expirados\n",
      "15 expirou\n",
      "18 explica\n",
      "9 explicar\n",
      "58 explorer\n",
      "34 exposta\n",
      "40 exposto\n",
      "127 ext\n",
      "26 externa\n",
      "32 external\n",
      "22 externo\n",
      "57 extra\n",
      "38 extracao\n",
      "21 extrai\n",
      "8 extrair\n",
      "37 extrator\n",
      "7 extratos\n",
      "27 fa\n",
      "30 fabiana\n",
      "9 fabiane\n",
      "23 fabiano\n",
      "66 fabio\n",
      "17 fabrica\n",
      "22 fabricio\n",
      "23 fac\n",
      "31 fachada\n",
      "232 facilidade\n",
      "113 facilidades\n",
      "14 fagundes\n",
      "66 faixa\n",
      "15 fala\n",
      "8 falamos\n",
      "27 falar\n",
      "39 fale\n",
      "441 falha\n",
      "26 falhas\n",
      "73 falta\n",
      "23 faltando\n",
      "10 faltantes\n",
      "172 fam\n",
      "175 familia\n",
      "42 faria\n",
      "36 farias\n",
      "7 fase\n",
      "41 fast\n",
      "11 fastfu\n",
      "9 fastvb\n",
      "50 fastve\n",
      "94 fat\n",
      "73 fatima\n",
      "28 fato\n",
      "437 fatura\n",
      "11 faturadas\n",
      "52 faturado\n",
      "18 faturados\n",
      "315 faturamento\n",
      "13 faturamentos\n",
      "80 faturando\n",
      "23 faturar\n",
      "359 faturas\n",
      "11 faturou\n",
      "16 favo\n",
      "1256 favor\n",
      "88 faz\n",
      "20 fazem\n",
      "37 fazemos\n",
      "7 fazia\n",
      "9 fbb\n",
      "19 fbltv\n",
      "8 fc\n",
      "40 fd\n",
      "9 feb\n",
      "14 febraban\n",
      "28 fecha\n",
      "194 fechada\n",
      "70 fechadas\n",
      "562 fechado\n",
      "146 fechados\n",
      "742 fechamento\n",
      "11 fechamos\n",
      "8 fechando\n",
      "282 fechar\n",
      "20 fechou\n",
      "8 federacao\n",
      "58 federal\n",
      "40 fego\n",
      "13 feira\n",
      "9 feitosa\n",
      "70 felipe\n",
      "20 felix\n",
      "27 fen\n",
      "64 fernanda\n",
      "99 fernandes\n",
      "120 fernando\n",
      "218 ferramenta\n",
      "9 ferramentas\n",
      "10 ferrari\n",
      "10 ferraz\n",
      "202 ferreira\n",
      "17 fev\n",
      "94 fevereiro\n",
      "128 fez\n",
      "11 ff\n",
      "9 fhynbeen\n",
      "11 fi\n",
      "1251 fibra\n",
      "195 fica\n",
      "8 ficado\n",
      "25 ficam\n",
      "87 ficando\n",
      "45 ficar\n",
      "22 ficaram\n",
      "71 ficha\n",
      "63 fico\n",
      "15 ficos\n",
      "236 ficou\n",
      "84 fict\n",
      "7 ficticia\n",
      "44 ficticio\n",
      "427 fid\n",
      "12 fidel\n",
      "11 fidelidade\n",
      "18 fideliza\n",
      "9 figueira\n",
      "48 figueiredo\n",
      "361 fila\n",
      "26 filas\n",
      "27 file\n",
      "93 filho\n",
      "23 filiais\n",
      "140 filial\n",
      "71 fim\n",
      "19 finais\n",
      "134 final\n",
      "127 finaliza\n",
      "50 finalizada\n",
      "12 finalizadas\n",
      "157 finalizado\n",
      "165 finalizar\n",
      "41 financeira\n",
      "112 financeiro\n",
      "47 fique\n",
      "18 fiquem\n",
      "15 firefox\n",
      "14 fiscais\n",
      "39 fiscal\n",
      "19 fisica\n",
      "8 fisicamente\n",
      "80 fisico\n",
      "20 fix\n",
      "277 fixa\n",
      "15 fixas\n",
      "2346 fixo\n",
      "15 fixos\n",
      "20 fiz\n",
      "23 fizemos\n",
      "11 fizeram\n",
      "9 fj\n",
      "47 fla\n",
      "155 flag\n",
      "64 flat\n",
      "28 flavia\n",
      "35 flavio\n",
      "13 fleg\n",
      "8 flegue\n",
      "19 flex\n",
      "17 flg\n",
      "24 flores\n",
      "74 fluxo\n",
      "16 fm\n",
      "14 fnb\n",
      "166 fns\n",
      "9 focal\n",
      "131 fone\n",
      "56 fonseca\n",
      "14 fontes\n",
      "204 forma\n",
      "13 forms\n",
      "22 fortaleza\n",
      "9 fortuna\n",
      "8 foto\n",
      "13 found\n",
      "7 foz\n",
      "58 fr\n",
      "29 fraga\n",
      "14 frame\n",
      "21 franca\n",
      "45 francisca\n",
      "102 francisco\n",
      "28 franco\n",
      "374 franquia\n",
      "21 franquias\n",
      "110 fraude\n",
      "11 frederico\n",
      "18 freire\n",
      "86 freitas\n",
      "8 from\n",
      "38 frqvc\n",
      "8 fs\n",
      "7 fsa\n",
      "34 ft\n",
      "22 ftp\n",
      "22 ftv\n",
      "20 full\n",
      "17 fun\n",
      "20 funciona\n",
      "39 funcional\n",
      "39 funcionalidade\n",
      "8 funcionalidades\n",
      "14 funcionamento\n",
      "45 funcionando\n",
      "18 funcionar\n",
      "14 funcionou\n",
      "12 fundacao\n",
      "12 fundo\n",
      "16 furtado\n",
      "12 futuras\n",
      "9 futuro\n",
      "17 fv\n",
      "32 fvr\n",
      "7 fw\n",
      "8 fx\n",
      "36 ga\n",
      "786 gaap\n",
      "29 gabriel\n",
      "21 gabriela\n",
      "7 gabrielle\n",
      "8 galdino\n",
      "9 galera\n",
      "11 galvao\n",
      "13 gama\n",
      "7 gantt\n",
      "82 garantir\n",
      "42 garcia\n",
      "9 gas\n",
      "322 gb\n",
      "62 gcob\n",
      "7 gd\n",
      "351 gde\n",
      "28 gdes\n",
      "15 ge\n",
      "39 geco\n",
      "20 ged\n",
      "28 gen\n",
      "9 generico\n",
      "21 geneva\n",
      "317 gentileza\n",
      "7 gentiliza\n",
      "41 ger\n",
      "363 gera\n",
      "18 geracao\n",
      "174 gerada\n",
      "68 geradas\n",
      "255 gerado\n",
      "41 gerados\n",
      "19 gerais\n",
      "29 geral\n",
      "39 geraldo\n",
      "9 geralmente\n",
      "7 geramos\n",
      "249 gerando\n",
      "450 gerar\n",
      "21 geraram\n",
      "10 gere\n",
      "32 gerei\n",
      "17 gerencia\n",
      "16 gerenciamento\n",
      "31 gerenciar\n",
      "31 gerente\n",
      "9 gero\n",
      "396 gerou\n",
      "10 gerson\n",
      "20 gest\n",
      "84 gestor\n",
      "9 gestores\n",
      "8 get\n",
      "13 getnet\n",
      "11 gf\n",
      "135 gfr\n",
      "11 gi\n",
      "31 gica\n",
      "7 gid\n",
      "24 gilberto\n",
      "13 gilmar\n",
      "16 gilson\n",
      "38 gina\n",
      "7 gio\n",
      "10 gisele\n",
      "23 gl\n",
      "16 global\n",
      "13 globalweb\n",
      "11 globo\n",
      "16 gloria\n",
      "156 gmail\n",
      "15 gmud\n",
      "211 gna\n",
      "366 go\n",
      "14 goes\n",
      "8 goi\n",
      "12 goias\n",
      "151 gomes\n",
      "29 gon\n",
      "132 goncalves\n",
      "10 gonzaga\n",
      "8 gonzalez\n",
      "30 google\n",
      "47 gostaria\n",
      "9 goulart\n",
      "8 gouveia\n",
      "10 governo\n",
      "99 gpon\n",
      "8 gpp\n",
      "38 gprs\n",
      "38 gr\n",
      "53 gra\n",
      "27 gracas\n",
      "21 grade\n",
      "12 grafico\n",
      "53 granite\n",
      "186 grata\n",
      "166 grato\n",
      "12 gratuito\n",
      "14 grava\n",
      "16 graziela\n",
      "32 grosso\n",
      "799 group\n",
      "7 grta\n",
      "48 grupo\n",
      "15 gse\n",
      "36 gsm\n",
      "22 gt\n",
      "11 gua\n",
      "17 guedes\n",
      "10 guerra\n",
      "32 guia\n",
      "49 guilherme\n",
      "54 guimaraes\n",
      "39 gustavo\n",
      "43 gvt\n",
      "1224 ha\n",
      "7 habf\n",
      "138 habilita\n",
      "18 habilitada\n",
      "66 habilitado\n",
      "69 habilitar\n",
      "20 havendo\n",
      "44 haver\n",
      "27 havia\n",
      "16 hb\n",
      "7 hbo\n",
      "84 hd\n",
      "87 hdca\n",
      "12 hdcbj\n",
      "13 hdck\n",
      "58 helena\n",
      "12 helio\n",
      "31 help\n",
      "104 henrique\n",
      "14 hibrido\n",
      "22 hierarquia\n",
      "184 hist\n",
      "18 histo\n",
      "47 historico\n",
      "7 hl\n",
      "75 hlr\n",
      "12 hlrbsi\n",
      "11 hoa\n",
      "20 hob\n",
      "65 hoje\n",
      "9 holanda\n",
      "16 home\n",
      "49 hor\n",
      "152 hora\n",
      "13 horario\n",
      "389 horas\n",
      "14 horasnatarefa\n",
      "35 horizonte\n",
      "30 hot\n",
      "7 hotel\n",
      "93 hotline\n",
      "129 hotmail\n",
      "51 hrs\n",
      "101 hs\n",
      "63 htcd\n",
      "11 htce\n",
      "444 http\n",
      "8 hugo\n",
      "9 humberto\n",
      "90 ia\n",
      "8 ias\n",
      "26 ib\n",
      "220 ic\n",
      "18 iccid\n",
      "9 icms\n",
      "481 ics\n",
      "8 icseiminad\n",
      "8 icsldrparc\n",
      "384 id\n",
      "8 ida\n",
      "54 iddaordem\n",
      "45 ident\n",
      "17 identifica\n",
      "14 identificada\n",
      "169 identificado\n",
      "63 identificador\n",
      "14 identificados\n",
      "72 identificamos\n",
      "12 identificando\n",
      "141 identificar\n",
      "11 identificou\n",
      "11 identifiquei\n",
      "7 idigtro\n",
      "13 idpositivo\n",
      "14 ids\n",
      "72 ie\n",
      "11 if\n",
      "9 iffd\n",
      "10 ig\n",
      "7 igi\n",
      "13 igor\n",
      "75 igual\n",
      "9 ih\n",
      "8 iig\n",
      "30 ijb\n",
      "16 il\n",
      "14 ilha\n",
      "8 ilim\n",
      "14 ilimitada\n",
      "15 ilimitadas\n",
      "55 ilimitado\n",
      "18 ilimitados\n",
      "18 imagem\n",
      "49 imagens\n",
      "34 imediatamente\n",
      "13 imediato\n",
      "8 imei\n",
      "7 imeis\n",
      "9 imobiliaria\n",
      "8 imobiliarios\n",
      "7 imoveis\n",
      "53 imp\n",
      "19 impacta\n",
      "15 impactada\n",
      "9 impactadas\n",
      "9 impactado\n",
      "21 impactados\n",
      "115 impactando\n",
      "46 impacto\n",
      "14 impe\n",
      "110 impede\n",
      "12 impedi\n",
      "64 impedida\n",
      "11 impedidas\n",
      "34 impedido\n",
      "89 impedimento\n",
      "291 impedindo\n",
      "8 impedir\n",
      "20 impeditivo\n",
      "10 impendindo\n",
      "13 implanta\n",
      "74 implantar\n",
      "11 importacao\n",
      "8 importante\n",
      "16 impossibilidade\n",
      "46 impossibilita\n",
      "27 impossibilitado\n",
      "245 impossibilitando\n",
      "8 imposto\n",
      "14 impress\n",
      "24 imprimir\n",
      "12 improcedente\n",
      "18 imput\n",
      "8 imputar\n",
      "50 imsi\n",
      "106 in\n",
      "15 inacio\n",
      "119 inadimpl\n",
      "38 inadimplencia\n",
      "28 inadimplente\n",
      "8 inadimplentes\n",
      "17 inadiplencia\n",
      "129 inativa\n",
      "12 inativacao\n",
      "26 inativado\n",
      "21 inativados\n",
      "9 inativando\n",
      "90 inativar\n",
      "34 inativas\n",
      "193 inativo\n",
      "53 inativos\n",
      "32 inativou\n",
      "167 incentiva\n",
      "97 incidente\n",
      "7 incidentes\n",
      "51 inclu\n",
      "10 inclua\n",
      "14 inclui\n",
      "12 incluindo\n",
      "197 incluir\n",
      "157 inclus\n",
      "18 inclusa\n",
      "14 inclusao\n",
      "10 inclusas\n",
      "17 inclusive\n",
      "39 incluso\n",
      "31 inclusos\n",
      "81 incompat\n",
      "26 incompatibilidade\n",
      "60 incompativel\n",
      "7 incompleto\n",
      "84 inconsist\n",
      "11 inconsistencia\n",
      "32 inconsistente\n",
      "21 inconsistentes\n",
      "39 incorreta\n",
      "19 incorretamente\n",
      "85 incorreto\n",
      "102 incorretos\n",
      "35 ind\n",
      "13 independente\n",
      "12 indeterminado\n",
      "130 indevida\n",
      "199 indevidamente\n",
      "52 indevidas\n",
      "124 indevido\n",
      "19 indevidos\n",
      "28 indica\n",
      "19 indicador\n",
      "9 indicadores\n",
      "7 indicando\n",
      "7 indicativo\n",
      "126 indispon\n",
      "23 indisponibilidade\n",
      "89 indisponivel\n",
      "11 individual\n",
      "23 indo\n",
      "57 industria\n",
      "13 ines\n",
      "8 inesistente\n",
      "17 inesperado\n",
      "229 inexistente\n",
      "30 inexistentes\n",
      "17 inf\n",
      "29 inferior\n",
      "13 infnc\n",
      "17 info\n",
      "7 inform\n",
      "2163 informa\n",
      "37 informacoes\n",
      "90 informada\n",
      "12 informadas\n",
      "405 informado\n",
      "44 informados\n",
      "9 informam\n",
      "7 informamos\n",
      "458 informando\n",
      "177 informar\n",
      "13 informaram\n",
      "53 informatica\n",
      "103 informe\n",
      "14 informo\n",
      "261 informou\n",
      "8 ingl\n",
      "9 ingrid\n",
      "14 inibi\n",
      "8 inibidas\n",
      "64 inibidos\n",
      "12 inibir\n",
      "23 iniciada\n",
      "10 iniciais\n",
      "133 inicial\n",
      "22 iniciar\n",
      "42 inicio\n",
      "14 iniciodatarefa\n",
      "8 iniciou\n",
      "15 input\n",
      "81 ins\n",
      "156 insadsl\n",
      "7 insagrrw\n",
      "17 insantvir\n",
      "7 insapoint\n",
      "8 insapoio\n",
      "11 insatisfeito\n",
      "7 insblo\n",
      "10 inscirc\n",
      "18 inscomod\n",
      "11 inscorins\n",
      "31 inscpe\n",
      "7 inscpecom\n",
      "39 inser\n",
      "12 insere\n",
      "18 inserida\n",
      "100 inserido\n",
      "14 inseridos\n",
      "7 inserindo\n",
      "168 inserir\n",
      "18 insfastfu\n",
      "332 insfastve\n",
      "10 insinet\n",
      "18 insmodcli\n",
      "16 insnfilim\n",
      "16 insnfm\n",
      "71 insoitot\n",
      "17 inspcte\n",
      "78 insplano\n",
      "17 inspor\n",
      "420 inst\n",
      "19 insta\n",
      "18 instal\n",
      "580 instala\n",
      "207 instalacao\n",
      "113 instalada\n",
      "14 instaladas\n",
      "293 instalado\n",
      "59 instalados\n",
      "7 instalando\n",
      "297 instalar\n",
      "8 instalou\n",
      "28 instance\n",
      "65 instancia\n",
      "127 instancias\n",
      "13 instituto\n",
      "83 int\n",
      "7 intala\n",
      "43 intcel\n",
      "562 integra\n",
      "7 integradas\n",
      "13 integrado\n",
      "10 integral\n",
      "20 intelig\n",
      "38 inter\n",
      "15 intera\n",
      "12 intercepta\n",
      "12 interesse\n",
      "562 interface\n",
      "24 interfaces\n",
      "17 interfacesbcv\n",
      "15 interm\n",
      "45 intermedi\n",
      "57 intermediario\n",
      "9 intermitente\n",
      "33 interna\n",
      "29 internacionais\n",
      "25 internacional\n",
      "7 internaliza\n",
      "8 internalizados\n",
      "251 internet\n",
      "43 interno\n",
      "22 interopera\n",
      "8 interoperacao\n",
      "15 interrompida\n",
      "24 interven\n",
      "8 intra\n",
      "7 intrag\n",
      "18 intragrupo\n",
      "9 intranet\n",
      "23 intrarrede\n",
      "277 inv\n",
      "21 inva\n",
      "9 inval\n",
      "84 invalida\n",
      "189 invalido\n",
      "67 invalidos\n",
      "88 investiga\n",
      "39 investigado\n",
      "183 investigar\n",
      "128 investigativa\n",
      "7 investigue\n",
      "19 inviabilidade\n",
      "8 ione\n",
      "101 ip\n",
      "14 ipc\n",
      "97 iptv\n",
      "68 ir\n",
      "13 ira\n",
      "13 iracema\n",
      "7 iremos\n",
      "7 irene\n",
      "10 iria\n",
      "10 irla\n",
      "39 is\n",
      "23 isabel\n",
      "42 isen\n",
      "19 isentar\n",
      "15 isento\n",
      "8 ismael\n",
      "12 israel\n",
      "26 it\n",
      "7 ita\n",
      "14 itau\n",
      "53 item\n",
      "43 itens\n",
      "20 ivan\n",
      "10 ivo\n",
      "16 ivone\n",
      "8 ivonete\n",
      "17 izabel\n",
      "7 izaias\n",
      "318 ja\n",
      "14 jacarepagua\n",
      "9 jackson\n",
      "12 jair\n",
      "8 jairo\n",
      "7 jamc\n",
      "17 jan\n",
      "16 janaina\n",
      "9 jane\n",
      "99 janeiro\n",
      "144 janela\n",
      "8 janete\n",
      "29 jaqueline\n",
      "23 jardim\n",
      "7 jb\n",
      "7 jbo\n",
      "7 jd\n",
      "21 jean\n",
      "15 jec\n",
      "17 jeferson\n",
      "18 jefferson\n",
      "38 jessica\n",
      "113 jesus\n",
      "27 jfa\n",
      "9 jffd\n",
      "34 jo\n",
      "19 joana\n",
      "111 joao\n",
      "17 joaquim\n",
      "861 job\n",
      "519 jobid\n",
      "9 jobs\n",
      "17 joel\n",
      "8 jogar\n",
      "15 joice\n",
      "7 jonas\n",
      "8 jonathan\n",
      "7 jordao\n",
      "42 jorge\n",
      "32 jos\n",
      "168 jose\n",
      "11 josefa\n",
      "10 josiane\n",
      "8 joyce\n",
      "17 jpa\n",
      "7 jt\n",
      "7 jti\n",
      "179 judicial\n",
      "10 jul\n",
      "86 julho\n",
      "13 julia\n",
      "42 juliana\n",
      "13 juliano\n",
      "32 julio\n",
      "48 jumper\n",
      "45 jumpers\n",
      "61 junho\n",
      "17 junio\n",
      "130 junior\n",
      "37 juntamente\n",
      "84 junto\n",
      "18 jur\n",
      "35 juros\n",
      "38 justica\n",
      "16 jve\n",
      "12 karina\n",
      "11 karine\n",
      "15 karla\n",
      "49 katia\n",
      "10 kb\n",
      "21 kbps\n",
      "43 keller\n",
      "37 kelly\n",
      "12 ken\n",
      "201 kenpx\n",
      "9 key\n",
      "130 kit\n",
      "9 kleber\n",
      "64 la\n",
      "17 lacerda\n",
      "158 lado\n",
      "56 lais\n",
      "82 lan\n",
      "17 lara\n",
      "142 larga\n",
      "18 larissa\n",
      "21 las\n",
      "21 laura\n",
      "9 layout\n",
      "9 lazaro\n",
      "10 lculo\n",
      "358 ld\n",
      "17 ldi\n",
      "12 lditotal\n",
      "54 ldn\n",
      "9 ldntotal\n",
      "7 le\n",
      "26 leal\n",
      "67 leandro\n",
      "8 legada\n",
      "118 legado\n",
      "112 legados\n",
      "7 leidiane\n",
      "10 leitao\n",
      "54 leite\n",
      "14 leitura\n",
      "16 lembra\n",
      "64 lembramos\n",
      "18 lembrando\n",
      "9 lemes\n",
      "15 lemos\n",
      "28 lentid\n",
      "62 leonardo\n",
      "17 leticia\n",
      "59 levantamento\n",
      "17 levantamentos\n",
      "26 levantar\n",
      "12 lfe\n",
      "23 lg\n",
      "75 li\n",
      "183 lia\n",
      "26 lib\n",
      "382 libera\n",
      "14 liberacao\n",
      "235 liberada\n",
      "45 liberadas\n",
      "65 liberado\n",
      "16 liberados\n",
      "16 liberamos\n",
      "12 liberando\n",
      "307 liberar\n",
      "193 lico\n",
      "57 lida\n",
      "14 lidas\n",
      "7 lider\n",
      "7 lidia\n",
      "8 lidiane\n",
      "116 lido\n",
      "120 lidos\n",
      "7 liente\n",
      "244 liga\n",
      "7 ligado\n",
      "7 ligados\n",
      "22 ligar\n",
      "202 light\n",
      "9 ligou\n",
      "13 lilian\n",
      "10 liliane\n",
      "196 lima\n",
      "76 limbo\n",
      "11 limitada\n",
      "36 limite\n",
      "54 limpar\n",
      "37 limpeza\n",
      "23 line\n",
      "38 linh\n",
      "734 linha\n",
      "7 linhares\n",
      "422 linhas\n",
      "41 link\n",
      "7 lino\n",
      "10 lins\n",
      "51 lio\n",
      "8 lira\n",
      "14 lisboa\n",
      "141 lise\n",
      "20 lises\n",
      "7 list\n",
      "79 lista\n",
      "10 listada\n",
      "11 listadas\n",
      "92 listados\n",
      "31 listagem\n",
      "12 listando\n",
      "18 listar\n",
      "8 literal\n",
      "12 live\n",
      "12 livia\n",
      "15 livre\n",
      "11 lobo\n",
      "62 loc\n",
      "8 loca\n",
      "30 locais\n",
      "209 local\n",
      "307 localidade\n",
      "19 localidades\n",
      "26 localiza\n",
      "33 localizada\n",
      "57 localizado\n",
      "7 localizamos\n",
      "33 localizar\n",
      "10 loctotal\n",
      "68 log\n",
      "10 logadas\n",
      "43 logar\n",
      "57 logi\n",
      "364 login\n",
      "45 logins\n",
      "11 logistica\n",
      "58 logo\n",
      "63 logradouro\n",
      "18 logradouros\n",
      "28 logs\n",
      "7 loguin\n",
      "118 loja\n",
      "17 lojas\n",
      "110 lojista\n",
      "23 longa\n",
      "118 lopes\n",
      "10 lorena\n",
      "45 los\n",
      "23 lote\n",
      "7 lotes\n",
      "9 louise\n",
      "42 lourdes\n",
      "16 lourenco\n",
      "7 lourival\n",
      "12 lpa\n",
      "20 lt\n",
      "9 ltd\n",
      "163 ltda\n",
      "18 ltiplo\n",
      "14 luan\n",
      "25 luana\n",
      "55 lucas\n",
      "8 lucelia\n",
      "97 lucia\n",
      "43 luciana\n",
      "10 luciane\n",
      "28 luciano\n",
      "12 luciene\n",
      "7 lucilene\n",
      "18 lucio\n",
      "12 lugar\n",
      "75 luis\n",
      "159 luiz\n",
      "31 luiza\n",
      "22 lula\n",
      "8 lurdes\n",
      "38 luz\n",
      "16 luzia\n",
      "9 lw\n",
      "12 lyra\n",
      "50 ma\n",
      "7 mac\n",
      "37 macedo\n",
      "93 machado\n",
      "30 maciel\n",
      "125 macro\n",
      "16 macros\n",
      "16 madalena\n",
      "67 mae\n",
      "31 magalhaes\n",
      "8 magno\n",
      "20 mahi\n",
      "34 maia\n",
      "136 mail\n",
      "51 mailing\n",
      "10 mails\n",
      "71 maio\n",
      "37 maior\n",
      "73 maiores\n",
      "7 maioria\n",
      "11 maira\n",
      "7 man\n",
      "9 manda\n",
      "10 mandar\n",
      "15 maneira\n",
      "9 manh\n",
      "12 manobra\n",
      "49 manoel\n",
      "10 mantendo\n",
      "24 manter\n",
      "9 manteve\n",
      "135 manual\n",
      "258 manualmente\n",
      "10 manuel\n",
      "18 manuten\n",
      "7 map\n",
      "13 maquina\n",
      "9 maquinas\n",
      "271 mar\n",
      "28 mara\n",
      "7 maranhao\n",
      "50 marca\n",
      "43 marcado\n",
      "9 marcados\n",
      "58 marcar\n",
      "9 marcel\n",
      "12 marcelino\n",
      "95 marcelo\n",
      "82 marcia\n",
      "57 marcio\n",
      "65 marco\n",
      "7 marcondes\n",
      "96 marcos\n",
      "17 marcus\n",
      "7 margarete\n",
      "10 margarida\n",
      "211 maria\n",
      "27 mariana\n",
      "19 mariane\n",
      "19 mariano\n",
      "13 marilene\n",
      "11 marilia\n",
      "8 marilucia\n",
      "8 marina\n",
      "22 marinho\n",
      "8 marint\n",
      "22 mario\n",
      "7 marisa\n",
      "7 mariza\n",
      "22 marketing\n",
      "21 marlene\n",
      "18 marli\n",
      "112 marques\n",
      "23 marta\n",
      "7 martinez\n",
      "147 martins\n",
      "9 mary\n",
      "19 masc\n",
      "8 mascara\n",
      "59 massa\n",
      "56 massivo\n",
      "23 master\n",
      "11 mat\n",
      "41 materiais\n",
      "22 mateus\n",
      "23 matheus\n",
      "11 matias\n",
      "34 mato\n",
      "31 matos\n",
      "61 matr\n",
      "54 matricula\n",
      "62 matriculas\n",
      "16 mattos\n",
      "37 mauricio\n",
      "19 mauro\n",
      "13 max\n",
      "11 maximo\n",
      "8 mayara\n",
      "277 mb\n",
      "21 mbps\n",
      "7 mc\n",
      "8 mce\n",
      "8 mcl\n",
      "25 mco\n",
      "12 md\n",
      "7 mecanica\n",
      "45 medeiros\n",
      "26 media\n",
      "11 mediante\n",
      "8 medicamentos\n",
      "12 medina\n",
      "92 medio\n",
      "52 mega\n",
      "55 megas\n",
      "281 meio\n",
      "76 meios\n",
      "10 meira\n",
      "31 melhor\n",
      "37 mello\n",
      "83 melo\n",
      "8 memso\n",
      "15 mencionado\n",
      "86 mendes\n",
      "23 mendonca\n",
      "41 menezes\n",
      "51 menor\n",
      "35 menos\n",
      "402 mensagem\n",
      "30 mensagens\n",
      "13 mensais\n",
      "44 mensal\n",
      "8 mensalmente\n",
      "98 menu\n",
      "25 mercado\n",
      "19 merge\n",
      "715 mero\n",
      "92 meros\n",
      "45 mes\n",
      "7 mesagem\n",
      "62 meses\n",
      "26 mesquita\n",
      "9 messias\n",
      "197 met\n",
      "9 metalico\n",
      "9 metalurgica\n",
      "15 metro\n",
      "18 metroeth\n",
      "7 metros\n",
      "473 mg\n",
      "23 mgid\n",
      "83 mi\n",
      "99 mica\n",
      "7 micas\n",
      "9 michael\n",
      "9 michel\n",
      "16 michele\n",
      "11 michelle\n",
      "124 mico\n",
      "101 micro\n",
      "14 micros\n",
      "7 microservi\n",
      "32 mig\n",
      "7 migr\n",
      "535 migra\n",
      "14 migracao\n",
      "34 migrada\n",
      "14 migradas\n",
      "120 migrado\n",
      "16 migrador\n",
      "28 migrados\n",
      "13 migrando\n",
      "234 migrar\n",
      "19 migraram\n",
      "116 migrou\n",
      "31 miguel\n",
      "19 mil\n",
      "8 militar\n",
      "10 milton\n",
      "7 mim\n",
      "58 min\n",
      "17 minas\n",
      "13 minhaoi\n",
      "78 mini\n",
      "84 miniciclo\n",
      "11 ministerio\n",
      "140 minutos\n",
      "68 miranda\n",
      "10 miriam\n",
      "18 mirian\n",
      "12 miscelaneous\n",
      "28 mite\n",
      "115 mix\n",
      "32 mkt\n",
      "9 mktrel\n",
      "16 mm\n",
      "28 mms\n",
      "19 mns\n",
      "19 mobile\n",
      "15 mobilidade\n",
      "25 modalidade\n",
      "30 modelo\n",
      "168 modem\n",
      "7 modens\n",
      "108 modifica\n",
      "10 modificado\n",
      "28 modificar\n",
      "20 modo\n",
      "103 modulo\n",
      "8 moises\n",
      "197 momento\n",
      "137 mon\n",
      "8 monet\n",
      "22 monica\n",
      "12 monit\n",
      "48 monitor\n",
      "10 monitoracao\n",
      "15 monitorar\n",
      "8 monte\n",
      "59 monteiro\n",
      "8 monthly\n",
      "83 moraes\n",
      "51 morais\n",
      "100 moreira\n",
      "10 moreno\n",
      "34 mos\n",
      "160 mostra\n",
      "10 mostrado\n",
      "17 mostrando\n",
      "18 mota\n",
      "253 motivo\n",
      "10 motivos\n",
      "7 motos\n",
      "16 motta\n",
      "72 moura\n",
      "11 mov\n",
      "71 moveis\n",
      "408 movel\n",
      "13 mover\n",
      "7 movimenta\n",
      "19 movimento\n",
      "8 mozila\n",
      "56 mozilla\n",
      "7 mp\n",
      "11 mpa\n",
      "58 mpn\n",
      "428 ms\n",
      "44 msg\n",
      "288 msisdn\n",
      "36 msisdns\n",
      "18 mssisdn\n",
      "15 msz\n",
      "29 mszc\n",
      "217 mt\n",
      "8 mu\n",
      "94 mud\n",
      "41 muda\n",
      "408 mudan\n",
      "14 mudanca\n",
      "8 mudando\n",
      "77 mudar\n",
      "11 mudarea\n",
      "70 mudend\n",
      "45 mudext\n",
      "148 mudinho\n",
      "30 mudla\n",
      "8 mudloc\n",
      "7 mudo\n",
      "34 mudou\n",
      "33 mudporta\n",
      "25 mudqlinha\n",
      "15 muller\n",
      "169 multa\n",
      "30 multas\n",
      "13 multi\n",
      "27 multiplicidade\n",
      "8 multiproduto\n",
      "55 multiprodutos\n",
      "8 mundo\n",
      "15 munic\n",
      "54 municipal\n",
      "47 municipio\n",
      "15 muniz\n",
      "8 murilo\n",
      "40 nacional\n",
      "59 nada\n",
      "15 nadia\n",
      "9 nadir\n",
      "7 nair\n",
      "112 name\n",
      "555 nao\n",
      "17 nara\n",
      "158 nasc\n",
      "253 nascimento\n",
      "64 nat\n",
      "10 natal\n",
      "39 natalia\n",
      "8 natbetx\n",
      "15 nathalia\n",
      "33 navegador\n",
      "65 navegadores\n",
      "8 nayara\n",
      "9 nazare\n",
      "19 nba\n",
      "32 nc\n",
      "2073 ncia\n",
      "8 nciado\n",
      "7 ncial\n",
      "1049 ncias\n",
      "8 nculo\n",
      "7 ne\n",
      "248 necess\n",
      "72 necessario\n",
      "22 necessidade\n",
      "34 necessita\n",
      "34 necessitam\n",
      "15 necessitamos\n",
      "22 necessito\n",
      "22 neg\n",
      "7 negadas\n",
      "31 negado\n",
      "7 negando\n",
      "11 negocia\n",
      "9 negocio\n",
      "11 negocios\n",
      "7 neide\n",
      "8 neli\n",
      "25 nelson\n",
      "182 nenhuma\n",
      "7 neogrid\n",
      "47 nesse\n",
      "12 nesses\n",
      "81 neste\n",
      "89 net\n",
      "14 netiwn\n",
      "64 neto\n",
      "8 netprd\n",
      "34 netwin\n",
      "7 neusa\n",
      "21 neuza\n",
      "48 neves\n",
      "32 nextel\n",
      "19 nf\n",
      "8 nfid\n",
      "10 nia\n",
      "119 nica\n",
      "13 nicas\n",
      "19 nico\n",
      "8 nilson\n",
      "9 nilton\n",
      "11 nilza\n",
      "72 nimo\n",
      "57 nio\n",
      "17 niter\n",
      "12 niteroi\n",
      "15 niu\n",
      "170 nivel\n",
      "14 nm\n",
      "25 nnf\n",
      "56 nobill\n",
      "7 nobre\n",
      "81 noc\n",
      "21 node\n",
      "787 nodeid\n",
      "46 nogueira\n",
      "91 noite\n",
      "40 nok\n",
      "684 nome\n",
      "14 nomenclatura\n",
      "15 nonato\n",
      "10 noncat\n",
      "103 norm\n",
      "9 norma\n",
      "166 normal\n",
      "107 normalmente\n",
      "18 not\n",
      "83 nota\n",
      "31 notas\n",
      "15 notifica\n",
      "10 nov\n",
      "200 nova\n",
      "9 novaes\n",
      "101 novamente\n",
      "33 novas\n",
      "15 novembro\n",
      "332 novo\n",
      "67 novos\n",
      "19 np\n",
      "46 npac\n",
      "45 nr\n",
      "224 nrc\n",
      "21 nrcs\n",
      "34 nres\n",
      "33 nri\n",
      "15 nro\n",
      "12 nrs\n",
      "14 ns\n",
      "7 nsc\n",
      "23 nt\n",
      "62 ntcd\n",
      "18 ntce\n",
      "8 ntcm\n",
      "26 ntl\n",
      "10 nu\n",
      "48 null\n",
      "11 nulo\n",
      "7 number\n",
      "8 numera\n",
      "13 numeracao\n",
      "13 numerador\n",
      "480 numero\n",
      "34 numeros\n",
      "78 nunes\n",
      "270 nus\n",
      "8 oa\n",
      "10 obj\n",
      "33 objectel\n",
      "9 obriga\n",
      "154 obrigada\n",
      "157 obrigado\n",
      "122 obrigat\n",
      "9 obrigatorio\n",
      "398 obs\n",
      "53 observa\n",
      "8 observar\n",
      "12 obteve\n",
      "12 ocasionando\n",
      "9 occurred\n",
      "13 ocm\n",
      "359 oco\n",
      "63 ocorr\n",
      "30 ocorra\n",
      "258 ocorre\n",
      "8 ocorrencia\n",
      "126 ocorrendo\n",
      "32 ocorrer\n",
      "342 ocorreu\n",
      "7 ocorrida\n",
      "30 ocorrido\n",
      "31 ocos\n",
      "134 ocs\n",
      "313 oct\n",
      "10 octlight\n",
      "39 ocupado\n",
      "7 od\n",
      "520 odate\n",
      "180 odo\n",
      "49 odos\n",
      "9 oe\n",
      "54 oes\n",
      "12 oeste\n",
      "10 of\n",
      "37 ofc\n",
      "323 oferta\n",
      "12 ofertado\n",
      "51 ofertas\n",
      "19 off\n",
      "14 office\n",
      "23 offline\n",
      "59 ogs\n",
      "4479 oi\n",
      "15 oidigital\n",
      "7 oigalera\n",
      "26 oiofc\n",
      "7 oipaggo\n",
      "8 oipontos\n",
      "34 oit\n",
      "33 oitot\n",
      "82 oitotal\n",
      "73 oitv\n",
      "30 oivende\n",
      "224 ok\n",
      "7 ol\n",
      "8 old\n",
      "271 oliveira\n",
      "230 om\n",
      "172 omr\n",
      "784 oms\n",
      "8 omvelox\n",
      "30 on\n",
      "205 onde\n",
      "32 online\n",
      "24 ontem\n",
      "380 op\n",
      "52 opcao\n",
      "42 opcional\n",
      "22 open\n",
      "510 opera\n",
      "147 operacao\n",
      "8 operacional\n",
      "36 operador\n",
      "381 operadora\n",
      "33 operadoras\n",
      "40 operadores\n",
      "26 optica\n",
      "10 opvprd\n",
      "17 or\n",
      "9 oracle\n",
      "700 ordem\n",
      "204 ordens\n",
      "66 order\n",
      "1306 orderid\n",
      "8 organiza\n",
      "10 orgao\n",
      "56 orienta\n",
      "34 orientada\n",
      "41 orientado\n",
      "7 orientados\n",
      "275 origem\n",
      "11 originadas\n",
      "14 originado\n",
      "83 original\n",
      "7 ortega\n",
      "7 osc\n",
      "20 oscrm\n",
      "186 oss\n",
      "19 ossac\n",
      "13 osvaldo\n",
      "20 osvc\n",
      "646 ot\n",
      "24 out\n",
      "11 outlook\n",
      "57 outubro\n",
      "14 ouve\n",
      "97 ouvidoria\n",
      "7 ov\n",
      "118 pa\n",
      "9 pablo\n",
      "34 pabx\n",
      "9 pac\n",
      "24 pacheco\n",
      "36 pack\n",
      "17 package\n",
      "339 pacote\n",
      "211 pacotes\n",
      "12 padr\n",
      "141 pae\n",
      "16 paes\n",
      "126 paga\n",
      "248 pagamento\n",
      "9 pagando\n",
      "13 pagar\n",
      "269 pagas\n",
      "14 paggo\n",
      "52 pagina\n",
      "572 pago\n",
      "16 pagos\n",
      "47 pagou\n",
      "9 pagseguro\n",
      "154 pai\n",
      "13 painel\n",
      "9 pais\n",
      "33 paiva\n",
      "8 paixao\n",
      "11 palno\n",
      "7 paludo\n",
      "7 pamela\n",
      "21 paola\n",
      "46 pap\n",
      "14 papel\n",
      "46 papo\n",
      "267 par\n",
      "714 parada\n",
      "209 paradas\n",
      "174 parado\n",
      "98 parados\n",
      "20 parametriza\n",
      "23 parametrizada\n",
      "10 parametro\n",
      "7 parana\n",
      "8 parc\n",
      "120 parceiro\n",
      "75 parcelamento\n",
      "7 parcelar\n",
      "59 parcial\n",
      "8 parcialmente\n",
      "17 parece\n",
      "18 parecer\n",
      "9 parm\n",
      "18 parou\n",
      "122 parte\n",
      "51 participante\n",
      "29 partir\n",
      "21 pas\n",
      "12 pass\n",
      "30 passa\n",
      "27 passada\n",
      "26 passado\n",
      "9 passando\n",
      "25 passar\n",
      "9 passaram\n",
      "143 passo\n",
      "20 passos\n",
      "64 passou\n",
      "16 pasta\n",
      "10 patr\n",
      "72 patricia\n",
      "133 paula\n",
      "13 paulino\n",
      "147 paulo\n",
      "13 paz\n",
      "50 pb\n",
      "10 pbat\n",
      "109 pbi\n",
      "174 pc\n",
      "19 pcd\n",
      "15 pcdi\n",
      "17 pcen\n",
      "9 pcp\n",
      "37 pcpprd\n",
      "236 pcrm\n",
      "90 pcs\n",
      "13 pct\n",
      "9 pcte\n",
      "66 pdf\n",
      "1083 pdv\n",
      "10 pdvs\n",
      "440 pe\n",
      "35 pecas\n",
      "94 pede\n",
      "9 pedencia\n",
      "20 pedente\n",
      "1864 pedido\n",
      "123 pedidos\n",
      "14 pedimos\n",
      "31 pedindo\n",
      "12 pedir\n",
      "43 pediu\n",
      "86 pedro\n",
      "8 pef\n",
      "7 pegar\n",
      "17 pegasus\n",
      "30 peixoto\n",
      "9 pelican\n",
      "708 pend\n",
      "9 pendecia\n",
      "449 pendencia\n",
      "36 pendenciada\n",
      "52 pendenciado\n",
      "15 pendenciar\n",
      "64 pendencias\n",
      "556 pendente\n",
      "102 pendentes\n",
      "12 penha\n",
      "228 per\n",
      "50 percentual\n",
      "59 perda\n",
      "19 perdeu\n",
      "10 perdido\n",
      "203 pereira\n",
      "17 peres\n",
      "127 perfil\n",
      "9 perfis\n",
      "19 periodo\n",
      "8 permance\n",
      "283 permanece\n",
      "174 permanecem\n",
      "25 permanecendo\n",
      "80 permanecer\n",
      "32 permaneceram\n",
      "73 permaneceu\n",
      "16 permiss\n",
      "301 permite\n",
      "11 permitem\n",
      "7 permiti\n",
      "95 permitida\n",
      "119 permitido\n",
      "141 permitindo\n",
      "33 permitir\n",
      "42 permitiu\n",
      "8 pernambuco\n",
      "112 persiste\n",
      "90 pertence\n",
      "15 pertencem\n",
      "7 pertencentes\n",
      "7 pertencia\n",
      "81 pesquisa\n",
      "14 pesquisar\n",
      "25 pesquisas\n",
      "52 pessoa\n",
      "14 pessoal\n",
      "66 pessoas\n",
      "98 pf\n",
      "22 pfat\n",
      "11 pfc\n",
      "298 pfx\n",
      "17 pg\n",
      "535 pgm\n",
      "788 php\n",
      "40 pi\n",
      "155 pics\n",
      "28 pida\n",
      "9 pido\n",
      "15 piloto\n",
      "12 pimenta\n",
      "11 pimentel\n",
      "23 pinf\n",
      "42 pinheiro\n",
      "11 pinho\n",
      "56 pinto\n",
      "11 pio\n",
      "40 pip\n",
      "11 pipeline\n",
      "50 pires\n",
      "10 pj\n",
      "64 pke\n",
      "8 pkg\n",
      "23 pl\n",
      "38 plabil\n",
      "12 plaf\n",
      "9 plan\n",
      "15 planas\n",
      "106 planilha\n",
      "639 plano\n",
      "141 planos\n",
      "41 planta\n",
      "8 plat\n",
      "67 plataforma\n",
      "23 plataformas\n",
      "9 playboy\n",
      "10 plsql\n",
      "8 plt\n",
      "36 plus\n",
      "13 pmj\n",
      "24 pmkt\n",
      "121 pms\n",
      "74 pnet\n",
      "9 pneus\n",
      "37 po\n",
      "110 podem\n",
      "34 podemos\n",
      "64 poder\n",
      "41 podera\n",
      "15 podermos\n",
      "10 policia\n",
      "45 ponta\n",
      "18 pontes\n",
      "179 ponto\n",
      "127 pontos\n",
      "9 pontual\n",
      "24 pop\n",
      "15 popular\n",
      "15 porcentagem\n",
      "397 porem\n",
      "9 porqu\n",
      "11 port\n",
      "102 porta\n",
      "12 portab\n",
      "568 portabilidade\n",
      "12 portabilidades\n",
      "35 portada\n",
      "11 portadas\n",
      "258 portado\n",
      "51 portador\n",
      "22 portadora\n",
      "17 portados\n",
      "651 portal\n",
      "60 portanto\n",
      "24 portar\n",
      "24 portas\n",
      "18 portf\n",
      "15 portfolio\n",
      "17 portif\n",
      "17 portifolio\n",
      "24 porto\n",
      "22 portou\n",
      "395 pos\n",
      "7 posbif\n",
      "17 posconec\n",
      "21 posi\n",
      "10 positiva\n",
      "334 poss\n",
      "114 possa\n",
      "19 possam\n",
      "144 possamos\n",
      "75 possibilidade\n",
      "11 possibilita\n",
      "243 possivel\n",
      "89 possu\n",
      "18 possue\n",
      "82 possuem\n",
      "439 possui\n",
      "25 possuia\n",
      "8 possuimos\n",
      "23 possuir\n",
      "8 possuo\n",
      "46 postal\n",
      "23 posterior\n",
      "21 posteriormente\n",
      "853 posto\n",
      "20 postos\n",
      "12 pp\n",
      "13 ppi\n",
      "19 pprt\n",
      "11 pq\n",
      "1070 pr\n",
      "125 pra\n",
      "31 prado\n",
      "8 prates\n",
      "260 prazo\n",
      "11 prazos\n",
      "519 prc\n",
      "9 prd\n",
      "257 pre\n",
      "112 precisa\n",
      "50 precisam\n",
      "280 precisamos\n",
      "7 precisando\n",
      "7 precisar\n",
      "169 preciso\n",
      "12 preco\n",
      "10 predio\n",
      "13 preechemos\n",
      "14 preen\n",
      "7 preencha\n",
      "7 preenche\n",
      "125 preencher\n",
      "17 preenchida\n",
      "8 preenchidas\n",
      "67 preenchido\n",
      "18 preenchidos\n",
      "32 preenchimento\n",
      "67 prefeitura\n",
      "11 prefixo\n",
      "13 premiere\n",
      "157 prep\n",
      "22 prepago\n",
      "22 preq\n",
      "232 presa\n",
      "30 presas\n",
      "50 presente\n",
      "11 presentes\n",
      "232 preso\n",
      "18 presos\n",
      "15 prestada\n",
      "9 prestes\n",
      "9 preven\n",
      "10 prevista\n",
      "9 previsto\n",
      "8 preza\n",
      "126 prezado\n",
      "348 prezados\n",
      "18 prezadx\n",
      "7 prezo\n",
      "1577 pri\n",
      "54 prim\n",
      "7 primario\n",
      "35 primeira\n",
      "28 prin\n",
      "48 principal\n",
      "551 print\n",
      "151 prints\n",
      "39 prioridade\n",
      "9 prioriza\n",
      "26 priorizar\n",
      "27 priscila\n",
      "7 priv\n",
      "8 prive\n",
      "63 prj\n",
      "141 pro\n",
      "299 problema\n",
      "123 problemas\n",
      "44 proc\n",
      "10 procede\n",
      "15 procedente\n",
      "157 proceder\n",
      "214 procedimento\n",
      "27 procedimentos\n",
      "15 procedure\n",
      "11 proceguir\n",
      "11 process\n",
      "8 processa\n",
      "14 processada\n",
      "20 processado\n",
      "132 processamento\n",
      "10 processar\n",
      "248 processo\n",
      "11 processos\n",
      "99 procon\n",
      "8 procsim\n",
      "8 procuradoria\n",
      "10 procurar\n",
      "105 prod\n",
      "84 prodtrap\n",
      "19 produ\n",
      "395 produto\n",
      "9 produtor\n",
      "213 produtos\n",
      "52 profissional\n",
      "56 proforma\n",
      "8 prog\n",
      "311 programa\n",
      "7 programada\n",
      "17 progressao\n",
      "7 proje\n",
      "8 projetada\n",
      "47 projetado\n",
      "44 projeto\n",
      "39 projetos\n",
      "112 promessa\n",
      "72 promo\n",
      "17 promocional\n",
      "23 pronta\n",
      "23 pronto\n",
      "48 propensos\n",
      "14 proporcional\n",
      "36 proposta\n",
      "9 propriedade\n",
      "10 proprio\n",
      "27 prorroga\n",
      "10 prorrogadas\n",
      "29 prorrogar\n",
      "13 proseguindo\n",
      "16 proseguir\n",
      "41 prossegue\n",
      "7 prosseguida\n",
      "15 prosseguimento\n",
      "309 prosseguir\n",
      "18 prosseguirmos\n",
      "9 prosseguiu\n",
      "336 protocolo\n",
      "30 protocolos\n",
      "12 provavelmente\n",
      "20 provedor\n",
      "41 prover\n",
      "376 providenciar\n",
      "7 provider\n",
      "58 provis\n",
      "12 provisionado\n",
      "303 provisionamento\n",
      "20 provisionar\n",
      "17 provisorio\n",
      "162 prvnosb\n",
      "28 ps\n",
      "8 psa\n",
      "29 psbl\n",
      "18 psul\n",
      "10 ptica\n",
      "32 pts\n",
      "17 ptvs\n",
      "14 publica\n",
      "41 publico\n",
      "7 puxa\n",
      "7 puxar\n",
      "8 pv\n",
      "69 pvo\n",
      "10 pvw\n",
      "10 pzlv\n",
      "7 qabr\n",
      "8 qdez\n",
      "8 qfev\n",
      "7 qjan\n",
      "7 qjul\n",
      "7 qjun\n",
      "9 qmai\n",
      "9 qmar\n",
      "8 qnov\n",
      "109 qr\n",
      "35 qtd\n",
      "29 qtde\n",
      "10 qu\n",
      "7 quadros\n",
      "19 qualifica\n",
      "13 qualificada\n",
      "110 qualificar\n",
      "10 quality\n",
      "91 qualquer\n",
      "110 quantidade\n",
      "34 quarentena\n",
      "7 quase\n",
      "13 quatro\n",
      "7 queda\n",
      "30 queiroz\n",
      "64 queixa\n",
      "101 quer\n",
      "98 quest\n",
      "15 questionamentos\n",
      "11 questionando\n",
      "33 quina\n",
      "7 quinas\n",
      "7 quita\n",
      "91 quitado\n",
      "30 quot\n",
      "13 qy\n",
      "111 ra\n",
      "7 rabelo\n",
      "7 rachel\n",
      "95 rafael\n",
      "21 rafaela\n",
      "7 raid\n",
      "13 raimunda\n",
      "36 raimundo\n",
      "200 raiz\n",
      "8 ram\n",
      "63 ramais\n",
      "76 ramal\n",
      "13 ramalho\n",
      "8 ramon\n",
      "76 ramos\n",
      "18 rangel\n",
      "15 raphael\n",
      "29 raquel\n",
      "9 rata\n",
      "139 raz\n",
      "9 raza\n",
      "34 razao\n",
      "112 rb\n",
      "8 rbce\n",
      "29 rbo\n",
      "11 rbt\n",
      "529 rc\n",
      "35 rce\n",
      "20 rcs\n",
      "19 re\n",
      "100 rea\n",
      "22 reagendamento\n",
      "75 reagendar\n",
      "43 reais\n",
      "21 real\n",
      "103 realiza\n",
      "154 realizada\n",
      "35 realizadas\n",
      "207 realizado\n",
      "16 realizados\n",
      "14 realizam\n",
      "44 realizamos\n",
      "36 realizando\n",
      "569 realizar\n",
      "47 realizarmos\n",
      "9 realize\n",
      "7 realizei\n",
      "119 realizou\n",
      "64 realmente\n",
      "14 reas\n",
      "10 reason\n",
      "108 reativa\n",
      "42 reativada\n",
      "45 reativar\n",
      "24 rec\n",
      "22 recado\n",
      "169 recarga\n",
      "32 recargas\n",
      "8 receba\n",
      "82 recebe\n",
      "11 recebem\n",
      "40 recebemos\n",
      "188 recebendo\n",
      "122 receber\n",
      "45 receberam\n",
      "11 receberretornosolicitbilheteportab\n",
      "12 receberretornosolicitportab\n",
      "251 recebeu\n",
      "75 recebido\n",
      "74 recebimento\n",
      "67 receita\n",
      "10 recente\n",
      "67 recentes\n",
      "285 recep\n",
      "46 receptiva\n",
      "38 receptivo\n",
      "115 receptor\n",
      "65 receptora\n",
      "11 receptores\n",
      "12 reciclagem\n",
      "10 reciclo\n",
      "9 recife\n",
      "66 recl\n",
      "285 reclama\n",
      "92 reclamada\n",
      "21 reclamadas\n",
      "212 reclamado\n",
      "18 reclamados\n",
      "11 reclamando\n",
      "61 reclamante\n",
      "19 recomandar\n",
      "8 reconhe\n",
      "174 reconhece\n",
      "12 reconhecendo\n",
      "8 reconheceu\n",
      "14 reconhecido\n",
      "10 recorre\n",
      "43 recorrente\n",
      "11 recupera\n",
      "75 recuperar\n",
      "11 recusa\n",
      "249 recusada\n",
      "9 recusadas\n",
      "13 recusado\n",
      "93 rede\n",
      "17 redecard\n",
      "11 redes\n",
      "12 redirect\n",
      "29 redu\n",
      "8 reduzir\n",
      "49 reenviar\n",
      "23 reenvio\n",
      "272 ref\n",
      "32 refazer\n",
      "81 refer\n",
      "16 refere\n",
      "48 referencia\n",
      "273 referente\n",
      "110 referentes\n",
      "13 referido\n",
      "8 referidos\n",
      "7 reflete\n",
      "16 refletido\n",
      "7 refletidos\n",
      "12 refletindo\n",
      "7 refletir\n",
      "97 refletiu\n",
      "23 reflita\n",
      "95 reg\n",
      "81 regi\n",
      "8 regiane\n",
      "15 regiao\n",
      "81 regina\n",
      "16 reginaldo\n",
      "17 regionais\n",
      "176 regional\n",
      "8 registra\n",
      "36 registrado\n",
      "31 registrar\n",
      "8 registration\n",
      "200 registro\n",
      "58 registros\n",
      "12 rego\n",
      "63 regra\n",
      "10 regras\n",
      "16 regularizar\n",
      "14 reinaldo\n",
      "10 reincid\n",
      "10 reincidente\n",
      "14 reiniciou\n",
      "72 reinstala\n",
      "27 reinstalar\n",
      "106 reis\n",
      "15 rej\n",
      "12 rejane\n",
      "51 rejei\n",
      "26 rejeitado\n",
      "22 rejeitados\n",
      "105 rel\n",
      "67 rela\n",
      "10 relacionadas\n",
      "14 relacionado\n",
      "8 relacionados\n",
      "7 relacionamento\n",
      "93 relat\n",
      "46 relata\n",
      "16 relatorio\n",
      "91 relatorios\n",
      "9 relay\n",
      "7 release\n",
      "34 relfat\n",
      "9 remedy\n",
      "17 remessa\n",
      "8 remessas\n",
      "44 remo\n",
      "58 remover\n",
      "20 removeu\n",
      "16 removido\n",
      "12 renan\n",
      "59 renata\n",
      "37 renato\n",
      "10 renova\n",
      "10 rentabiliza\n",
      "8 rep\n",
      "211 reparo\n",
      "40 reparos\n",
      "9 repassado\n",
      "28 repasse\n",
      "14 replica\n",
      "11 replicacao\n",
      "11 reporta\n",
      "7 reportado\n",
      "17 reppx\n",
      "22 representacoes\n",
      "13 reproc\n",
      "13 reprocessados\n",
      "29 reprocessamento\n",
      "30 reprocessar\n",
      "21 req\n",
      "12 requer\n",
      "20 request\n",
      "44 requisi\n",
      "139 res\n",
      "12 resende\n",
      "87 reserva\n",
      "71 reservada\n",
      "29 reservado\n",
      "8 reservar\n",
      "229 reset\n",
      "54 resetar\n",
      "24 resgatar\n",
      "57 resgate\n",
      "30 resid\n",
      "15 residencia\n",
      "173 residencial\n",
      "7 residual\n",
      "20 resolu\n",
      "29 resolver\n",
      "7 resolveu\n",
      "17 resolvida\n",
      "33 resolvido\n",
      "18 resolvo\n",
      "10 respectiva\n",
      "13 respectivamente\n",
      "9 respectivas\n",
      "68 respectivos\n",
      "14 respeitando\n",
      "15 responda\n",
      "18 responde\n",
      "92 respons\n",
      "10 responsabilidade\n",
      "23 responsavel\n",
      "9 response\n",
      "44 resposta\n",
      "12 ressaltar\n",
      "32 ressalto\n",
      "8 ressubmeter\n",
      "11 ressubmiss\n",
      "18 rest\n",
      "13 restante\n",
      "8 restaurar\n",
      "32 restri\n",
      "11 resubmeter\n",
      "49 resultado\n",
      "9 resumindo\n",
      "109 resumo\n",
      "358 ret\n",
      "21 retadsl\n",
      "19 retblo\n",
      "8 retbusca\n",
      "8 retcirc\n",
      "7 retdef\n",
      "7 retdial\n",
      "16 reteild\n",
      "275 reten\n",
      "12 retencao\n",
      "15 retida\n",
      "12 retidas\n",
      "10 retido\n",
      "10 retificada\n",
      "54 retinsmud\n",
      "55 retinsmudnum\n",
      "12 retir\n",
      "49 retira\n",
      "596 retirada\n",
      "12 retiradas\n",
      "168 retirado\n",
      "45 retirados\n",
      "19 retirando\n",
      "322 retirar\n",
      "13 retire\n",
      "9 retirem\n",
      "13 retirou\n",
      "11 retitar\n",
      "17 retoitot\n",
      "168 retorna\n",
      "21 retornada\n",
      "40 retornado\n",
      "9 retornam\n",
      "64 retornando\n",
      "56 retornar\n",
      "9 retornaram\n",
      "14 retorne\n",
      "214 retorno\n",
      "306 retornou\n",
      "45 retplano\n",
      "66 retransmitir\n",
      "7 retroativas\n",
      "56 rev\n",
      "76 revenda\n",
      "18 revers\n",
      "7 review\n",
      "9 revis\n",
      "19 rezende\n",
      "23 rf\n",
      "10 rffd\n",
      "9 rffps\n",
      "9 rffpsel\n",
      "272 rg\n",
      "7 rgio\n",
      "22 ri\n",
      "599 ria\n",
      "126 rias\n",
      "10 ribas\n",
      "158 ribeiro\n",
      "86 ricardo\n",
      "198 rico\n",
      "20 rie\n",
      "16 rii\n",
      "1565 rio\n",
      "264 rios\n",
      "9 risco\n",
      "49 rita\n",
      "413 rj\n",
      "228 rjo\n",
      "32 rmino\n",
      "7 rms\n",
      "38 rn\n",
      "168 ro\n",
      "28 roaming\n",
      "22 roberta\n",
      "155 roberto\n",
      "48 robo\n",
      "42 robson\n",
      "97 rocha\n",
      "13 rodando\n",
      "44 rodar\n",
      "10 rodolfo\n",
      "99 rodrigo\n",
      "177 rodrigues\n",
      "85 rogerio\n",
      "14 rogero\n",
      "8 rolagem\n",
      "8 rollback\n",
      "31 ronaldo\n",
      "12 rondonia\n",
      "104 rosa\n",
      "12 rosana\n",
      "20 rosangela\n",
      "11 rosario\n",
      "10 rose\n",
      "9 roseli\n",
      "8 rosilene\n",
      "8 rot\n",
      "16 rota\n",
      "8 roteador\n",
      "8 roteamento\n",
      "35 rotina\n",
      "9 rotinas\n",
      "10 roubo\n",
      "62 row\n",
      "35 rp\n",
      "9 rpc\n",
      "22 rr\n",
      "7 rro\n",
      "130 rs\n",
      "120 rt\n",
      "105 rtcd\n",
      "11 rtcm\n",
      "33 rua\n",
      "18 rubens\n",
      "10 rufino\n",
      "25 rural\n",
      "7 rute\n",
      "20 rv\n",
      "11 rvd\n",
      "85 sa\n",
      "12 sabe\n",
      "12 sabemos\n",
      "37 saber\n",
      "7 sabrina\n",
      "1654 sac\n",
      "94 saf\n",
      "13 sag\n",
      "18 sai\n",
      "14 sair\n",
      "18 saiu\n",
      "8 saldanha\n",
      "88 saldo\n",
      "45 sales\n",
      "9 salete\n",
      "7 salgado\n",
      "9 salles\n",
      "7 salomao\n",
      "23 salvador\n",
      "15 salvar\n",
      "46 sampaio\n",
      "66 sample\n",
      "16 samuel\n",
      "10 sanches\n",
      "30 sandra\n",
      "23 sandro\n",
      "8 sant\n",
      "45 santa\n",
      "70 santana\n",
      "39 santander\n",
      "20 santiago\n",
      "23 santo\n",
      "234 santos\n",
      "33 sao\n",
      "84 sap\n",
      "9 saraiva\n",
      "9 satus\n",
      "27 saude\n",
      "13 saulo\n",
      "27 sav\n",
      "79 sbl\n",
      "9 sbloitotal\n",
      "8 sblpx\n",
      "408 sc\n",
      "9 scacp\n",
      "10 scb\n",
      "20 schedule\n",
      "17 scom\n",
      "11 scp\n",
      "10 sd\n",
      "12 sdcorp\n",
      "51 sdr\n",
      "8 sebastiana\n",
      "23 sebastiao\n",
      "50 sec\n",
      "48 secretaria\n",
      "49 secund\n",
      "78 segmenta\n",
      "83 segmento\n",
      "1413 segue\n",
      "155 seguem\n",
      "27 seguida\n",
      "20 seguindo\n",
      "196 seguinte\n",
      "35 seguintes\n",
      "343 seguir\n",
      "43 segunda\n",
      "51 segundo\n",
      "10 segundos\n",
      "29 seguran\n",
      "23 seguranca\n",
      "21 seguros\n",
      "7 seis\n",
      "7 seixas\n",
      "25 sele\n",
      "8 seleciona\n",
      "12 selecionada\n",
      "57 selecionado\n",
      "55 selecionar\n",
      "8 select\n",
      "8 selma\n",
      "96 semana\n",
      "9 semanas\n",
      "17 sena\n",
      "396 senha\n",
      "10 senhora\n",
      "58 senhores\n",
      "12 separada\n",
      "24 separadamente\n",
      "21 separadas\n",
      "16 separado\n",
      "14 sequ\n",
      "16 sequencia\n",
      "74 sequencial\n",
      "271 ser\n",
      "37 sera\n",
      "17 serede\n",
      "57 serem\n",
      "11 sereno\n",
      "74 sergio\n",
      "24 serpa\n",
      "33 serra\n",
      "51 serv\n",
      "12 server\n",
      "859 servi\n",
      "49 service\n",
      "10 services\n",
      "179 servico\n",
      "96 servicos\n",
      "20 servidor\n",
      "8 sess\n",
      "18 set\n",
      "60 setembro\n",
      "50 setor\n",
      "9 setores\n",
      "18 sev\n",
      "8 severidade\n",
      "15 severino\n",
      "24 sexy\n",
      "7 sf\n",
      "296 sfa\n",
      "412 sge\n",
      "7 sgeb\n",
      "21 sgef\n",
      "7 sgep\n",
      "7 sgex\n",
      "32 sgft\n",
      "19 sgo\n",
      "10 sh\n",
      "10 sharepoint\n",
      "17 sheila\n",
      "277 siac\n",
      "109 sibel\n",
      "48 sica\n",
      "277 sico\n",
      "7 sicoob\n",
      "13 sicos\n",
      "18 sidara\n",
      "11 sidnei\n",
      "1991 siebel\n",
      "10 siebelbatimento\n",
      "12 siebelcdi\n",
      "12 siebeldataguard\n",
      "22 siebelmkt\n",
      "145 siebelreport\n",
      "30 siga\n",
      "163 sigla\n",
      "11 siin\n",
      "280 silva\n",
      "42 silvana\n",
      "70 silveira\n",
      "7 silvestre\n",
      "22 silvia\n",
      "8 silvio\n",
      "285 sim\n",
      "8 simao\n",
      "13 simcard\n",
      "8 simcards\n",
      "7 similar\n",
      "7 simm\n",
      "16 simoes\n",
      "45 simone\n",
      "18 simples\n",
      "17 simproc\n",
      "94 simula\n",
      "7 simulada\n",
      "35 simular\n",
      "14 sin\n",
      "141 sinal\n",
      "27 sincronismo\n",
      "8 sindicato\n",
      "319 sinn\n",
      "7 sinndth\n",
      "16 sinnweb\n",
      "45 siqueira\n",
      "14 sirlene\n",
      "91 sis\n",
      "7 sisbel\n",
      "227 sisjur\n",
      "273 sisraf\n",
      "228 sist\n",
      "608 sistema\n",
      "203 sistemas\n",
      "18 sistemica\n",
      "73 sistemico\n",
      "26 sit\n",
      "871 site\n",
      "22 sitema\n",
      "7 sites\n",
      "49 sitescope\n",
      "16 sito\n",
      "30 sittel\n",
      "164 situa\n",
      "21 situacao\n",
      "12 sla\n",
      "7 sldd\n",
      "7 sle\n",
      "16 slot\n",
      "24 sls\n",
      "11 smi\n",
      "10 smkprd\n",
      "8 smpe\n",
      "134 sms\n",
      "80 so\n",
      "44 soa\n",
      "10 soapenv\n",
      "8 soapx\n",
      "123 soares\n",
      "14 soasync\n",
      "7 sobreposi\n",
      "7 sobrinho\n",
      "1122 soc\n",
      "172 social\n",
      "8 sociedade\n",
      "18 socorro\n",
      "27 sofreram\n",
      "35 sofreu\n",
      "8 sol\n",
      "21 solange\n",
      "1357 solicita\n",
      "30 solicitacao\n",
      "76 solicitada\n",
      "7 solicitadas\n",
      "188 solicitado\n",
      "91 solicitados\n",
      "85 solicitamos\n",
      "98 solicitando\n",
      "91 solicitante\n",
      "277 solicitar\n",
      "27 solicite\n",
      "361 solicito\n",
      "269 solicitou\n",
      "7 solicta\n",
      "85 solu\n",
      "21 solucionado\n",
      "25 solucionar\n",
      "7 solucoes\n",
      "10 solutions\n",
      "13 som\n",
      "12 some\n",
      "145 somente\n",
      "30 sompxa\n",
      "41 sonia\n",
      "45 sons\n",
      "12 soube\n",
      "128 sousa\n",
      "9 souto\n",
      "223 souza\n",
      "10 sox\n",
      "86 sp\n",
      "7 spa\n",
      "18 spm\n",
      "96 spo\n",
      "11 sql\n",
      "138 sr\n",
      "12 sra\n",
      "64 srs\n",
      "7 srt\n",
      "14 ss\n",
      "8 sso\n",
      "17 ssp\n",
      "1395 st\n",
      "10 sta\n",
      "53 start\n",
      "797 status\n",
      "8 staus\n",
      "1411 stc\n",
      "7 stcab\n",
      "35 stcd\n",
      "8 stcvoz\n",
      "1583 step\n",
      "41 sti\n",
      "29 stica\n",
      "76 sticas\n",
      "49 su\n",
      "46 sub\n",
      "122 subfastve\n",
      "33 subiu\n",
      "64 subnum\n",
      "7 subprograma\n",
      "46 substitui\n",
      "17 substituir\n",
      "18 substituta\n",
      "23 substituto\n",
      "343 sucesso\n",
      "10 sueli\n",
      "59 sul\n",
      "11 sumiu\n",
      "17 super\n",
      "8 superior\n",
      "9 supermercado\n",
      "22 supersav\n",
      "52 supervisor\n",
      "14 supervisora\n",
      "78 suporte\n",
      "138 surge\n",
      "107 surgiu\n",
      "14 suspen\n",
      "74 suspens\n",
      "26 suspensa\n",
      "57 suspenso\n",
      "25 suspensos\n",
      "10 suzana\n",
      "8 sv\n",
      "58 sva\n",
      "12 svctb\n",
      "82 svoi\n",
      "7 sxp\n",
      "27 sylvia\n",
      "780 sysout\n",
      "25 ta\n",
      "32 tab\n",
      "85 tabela\n",
      "11 tabelas\n",
      "15 tadeu\n",
      "30 tais\n",
      "60 tal\n",
      "7 talita\n",
      "20 tamanho\n",
      "38 tambem\n",
      "20 tania\n",
      "52 tanto\n",
      "325 tarde\n",
      "557 tarefa\n",
      "19 tarefas\n",
      "47 tarif\n",
      "46 tarifa\n",
      "15 tarifacao\n",
      "18 tarifada\n",
      "9 tarifadas\n",
      "191 tarifado\n",
      "39 tarifados\n",
      "7 tarifando\n",
      "12 tarifario\n",
      "19 task\n",
      "11 tatiana\n",
      "20 tatiane\n",
      "58 tavares\n",
      "21 taxa\n",
      "11 tb\n",
      "7 tbm\n",
      "97 tc\n",
      "12 tced\n",
      "9 tceprbu\n",
      "7 tcof\n",
      "30 tcs\n",
      "24 tdm\n",
      "13 tec\n",
      "8 tecla\n",
      "111 tecle\n",
      "38 tecnica\n",
      "15 tecnico\n",
      "41 tecnicos\n",
      "38 tecnologia\n",
      "12 teis\n",
      "89 teixeira\n",
      "288 tel\n",
      "651 tela\n",
      "199 telas\n",
      "13 tele\n",
      "8 telecine\n",
      "64 telecom\n",
      "24 telecomunicacoes\n",
      "17 telef\n",
      "483 telefone\n",
      "66 telefones\n",
      "16 telefonica\n",
      "130 telemar\n",
      "16 teles\n",
      "31 televendas\n",
      "7 telma\n",
      "10 telr\n",
      "9 teminal\n",
      "18 template\n",
      "73 tempo\n",
      "20 tempor\n",
      "18 temporariamente\n",
      "250 tenta\n",
      "23 tentado\n",
      "110 tentamos\n",
      "362 tentando\n",
      "514 tentar\n",
      "39 tentarmos\n",
      "223 tentativa\n",
      "54 tentativas\n",
      "14 tentato\n",
      "81 tente\n",
      "22 tentei\n",
      "29 tento\n",
      "96 tentou\n",
      "15 teodoro\n",
      "9 ter\n",
      "16 terceiro\n",
      "14 terceiros\n",
      "20 terem\n",
      "17 teresinha\n",
      "15 tereza\n",
      "49 terezinha\n",
      "86 term\n",
      "24 termina\n",
      "437 terminais\n",
      "1197 terminal\n",
      "7 terminar\n",
      "19 termo\n",
      "9 termos\n",
      "11 terra\n",
      "106 testar\n",
      "45 teste\n",
      "16 testes\n",
      "8 textil\n",
      "10 tffd\n",
      "23 thais\n",
      "10 the\n",
      "68 thiago\n",
      "12 tht\n",
      "240 tiago\n",
      "592 tica\n",
      "28 ticas\n",
      "169 tico\n",
      "13 tijuca\n",
      "64 tim\n",
      "14 time\n",
      "16 timeout\n",
      "7 tipifica\n",
      "178 tipo\n",
      "15 tipodaos\n",
      "9 tirado\n",
      "25 tirar\n",
      "689 titular\n",
      "8 titulares\n",
      "94 titularidade\n",
      "8 tlm\n",
      "1577 tlmoi\n",
      "14 tlmpackageoriginalid\n",
      "19 tlv\n",
      "11 tm\n",
      "1333 tmapw\n",
      "9 tmarq\n",
      "542 tn\n",
      "8 tns\n",
      "78 to\n",
      "10 tocantins\n",
      "7 todo\n",
      "12 todvrgratis\n",
      "40 token\n",
      "16 toolkit\n",
      "60 top\n",
      "23 tor\n",
      "30 torpedo\n",
      "21 torpedos\n",
      "9 torre\n",
      "30 torres\n",
      "13 tot\n",
      "7 tota\n",
      "4262 total\n",
      "16 totalmente\n",
      "9 tp\n",
      "8 tpa\n",
      "333 tr\n",
      "67 tra\n",
      "10 traas\n",
      "77 trabalho\n",
      "18 tradu\n",
      "137 traducao\n",
      "9 trafegar\n",
      "24 trafego\n",
      "17 tramit\n",
      "206 tramita\n",
      "16 tramitacao\n",
      "45 tramitada\n",
      "10 tramitadas\n",
      "17 tramitado\n",
      "89 tramitando\n",
      "271 tramitar\n",
      "27 tramitaram\n",
      "266 tramite\n",
      "354 tramitou\n",
      "10 trans\n",
      "17 transa\n",
      "15 transact\n",
      "59 transfer\n",
      "10 transfere\n",
      "42 transferencia\n",
      "13 transferidor\n",
      "11 transferir\n",
      "23 transmiss\n",
      "13 transporte\n",
      "23 transportes\n",
      "35 trat\n",
      "241 trata\n",
      "42 tratada\n",
      "58 tratadas\n",
      "60 tratado\n",
      "18 tratados\n",
      "11 tratam\n",
      "449 tratamento\n",
      "10 tratamentos\n",
      "12 tratamos\n",
      "12 tratando\n",
      "563 tratar\n",
      "274 tratativa\n",
      "18 tratativas\n",
      "124 tratconv\n",
      "39 trava\n",
      "138 travada\n",
      "15 travadas\n",
      "354 travado\n",
      "12 travando\n",
      "11 traz\n",
      "10 trazendo\n",
      "15 tres\n",
      "40 tria\n",
      "37 tribunal\n",
      "12 tridigito\n",
      "32 trigger\n",
      "16 trindade\n",
      "10 trl\n",
      "257 troca\n",
      "48 trocar\n",
      "18 trocou\n",
      "33 tronco\n",
      "9 trunc\n",
      "8 trying\n",
      "18 tsa\n",
      "466 tt\n",
      "44 tts\n",
      "17 tulo\n",
      "17 turbo\n",
      "17 turismo\n",
      "2348 tv\n",
      "42 tvas\n",
      "17 tvspdcrc\n",
      "13 tx\n",
      "69 txt\n",
      "10 type\n",
      "8 udr\n",
      "302 uf\n",
      "35 ufacp\n",
      "10 uffd\n",
      "13 uffps\n",
      "13 uffpsel\n",
      "8 ufftp\n",
      "9 ufs\n",
      "37 ug\n",
      "32 ultima\n",
      "13 ultimapendencia\n",
      "9 ultimas\n",
      "12 ultimo\n",
      "7 un\n",
      "72 unica\n",
      "10 unico\n",
      "143 unid\n",
      "118 unidade\n",
      "15 unifica\n",
      "9 unificada\n",
      "15 unificado\n",
      "8 universal\n",
      "9 universidade\n",
      "14 unix\n",
      "66 up\n",
      "7 update\n",
      "47 upgrade\n",
      "41 ur\n",
      "38 ura\n",
      "116 urg\n",
      "174 urgencia\n",
      "66 urgente\n",
      "14 url\n",
      "7 usa\n",
      "37 usado\n",
      "39 usados\n",
      "24 usando\n",
      "25 usar\n",
      "10 user\n",
      "82 uso\n",
      "98 usos\n",
      "1114 usu\n",
      "64 usuaria\n",
      "141 usuario\n",
      "8 usuarios\n",
      "156 utcd\n",
      "25 utce\n",
      "8 utcm\n",
      "19 uteis\n",
      "77 utiliza\n",
      "15 utilizada\n",
      "85 utilizado\n",
      "14 utilizados\n",
      "25 utilizando\n",
      "68 utilizar\n",
      "17 utilize\n",
      "9 utilizo\n",
      "18 utilizou\n",
      "98 uv\n",
      "70 vaga\n",
      "10 vagner\n",
      "131 vago\n",
      "14 vagos\n",
      "149 vai\n",
      "21 val\n",
      "15 valdir\n",
      "43 vale\n",
      "24 valeria\n",
      "12 valerio\n",
      "8 valid\n",
      "152 valida\n",
      "7 validade\n",
      "11 validado\n",
      "8 validamos\n",
      "40 validar\n",
      "8 validate\n",
      "37 valido\n",
      "8 validos\n",
      "340 valor\n",
      "99 valores\n",
      "7 valquiria\n",
      "14 valter\n",
      "10 value\n",
      "23 vamos\n",
      "8 vanda\n",
      "9 vanderlei\n",
      "41 vanessa\n",
      "15 vania\n",
      "130 varejo\n",
      "23 vargas\n",
      "35 varias\n",
      "26 varios\n",
      "9 vasconcellos\n",
      "33 vasconcelos\n",
      "25 vaz\n",
      "8 vazio\n",
      "8 vazios\n",
      "109 vc\n",
      "12 vca\n",
      "48 vcoinr\n",
      "48 vctotal\n",
      "8 vdsl\n",
      "13 ve\n",
      "25 veiculos\n",
      "15 veiga\n",
      "33 veio\n",
      "156 veis\n",
      "18 veja\n",
      "1349 vel\n",
      "304 velocidade\n",
      "17 velocidades\n",
      "7 velos\n",
      "11 veloso\n",
      "826 velox\n",
      "54 vem\n",
      "18 venc\n",
      "8 vencer\n",
      "30 venceu\n",
      "409 vencida\n",
      "18 vencidas\n",
      "15 vencido\n",
      "138 vencimento\n",
      "9 vencimentos\n",
      "28 vend\n",
      "547 venda\n",
      "10 vendaconjuntar\n",
      "118 vendas\n",
      "178 vende\n",
      "300 vendedor\n",
      "124 vendedora\n",
      "11 vendedores\n",
      "8 vendendor\n",
      "9 vender\n",
      "8 venho\n",
      "37 vera\n",
      "8 verde\n",
      "21 verficar\n",
      "17 vericar\n",
      "14 verif\n",
      "24 verifcar\n",
      "821 verifica\n",
      "14 verificada\n",
      "249 verificado\n",
      "91 verificamos\n",
      "46 verificando\n",
      "1086 verificar\n",
      "25 verificarem\n",
      "23 verificou\n",
      "61 verifique\n",
      "20 verifiquei\n",
      "191 verifiquem\n",
      "19 veriricar\n",
      "13 veronica\n",
      "10 vers\n",
      "55 vetor\n",
      "54 vezes\n",
      "13 vga\n",
      "14 vi\n",
      "287 via\n",
      "313 viabilidade\n",
      "13 viagem\n",
      "11 viagens\n",
      "37 viana\n",
      "21 vicente\n",
      "16 victor\n",
      "46 vida\n",
      "18 vidas\n",
      "186 vide\n",
      "117 vieira\n",
      "11 view\n",
      "42 vig\n",
      "25 vigente\n",
      "21 vila\n",
      "9 vilela\n",
      "21 vilma\n",
      "12 vimos\n",
      "22 vincula\n",
      "112 vinculada\n",
      "18 vinculadas\n",
      "228 vinculado\n",
      "72 vinculados\n",
      "29 vincular\n",
      "24 vinculo\n",
      "57 vinicius\n",
      "55 vip\n",
      "9 vira\n",
      "25 virtual\n",
      "20 virtude\n",
      "8 vis\n",
      "19 visita\n",
      "46 vista\n",
      "164 visto\n",
      "89 visualiza\n",
      "18 visualizado\n",
      "14 visualizando\n",
      "198 visualizar\n",
      "10 vite\n",
      "30 vitor\n",
      "9 vitoria\n",
      "163 vitria\n",
      "7 vivian\n",
      "30 viviane\n",
      "270 vivo\n",
      "11 vizualizar\n",
      "16 vl\n",
      "14 vlox\n",
      "10 vlr\n",
      "20 vm\n",
      "13 vmp\n",
      "40 voc\n",
      "36 voice\n",
      "81 volta\n",
      "11 voltando\n",
      "20 voltar\n",
      "7 voltaram\n",
      "55 volte\n",
      "16 voltem\n",
      "19 voltou\n",
      "40 volume\n",
      "67 volumetria\n",
      "9 vossa\n",
      "17 vou\n",
      "505 voz\n",
      "60 vpn\n",
      "15 vrd\n",
      "7 vs\n",
      "19 vta\n",
      "14 vva\n",
      "17 vw\n",
      "24 wagner\n",
      "51 wainting\n",
      "47 waiting\n",
      "12 walter\n",
      "7 wanderson\n",
      "54 web\n",
      "13 webservice\n",
      "16 webshare\n",
      "38 wedo\n",
      "22 wellington\n",
      "28 wesley\n",
      "24 wf\n",
      "9 wfl\n",
      "623 wfm\n",
      "9 where\n",
      "7 while\n",
      "18 william\n",
      "20 willian\n",
      "19 wilson\n",
      "52 wll\n",
      "63 wllprd\n",
      "46 wllpx\n",
      "10 woi\n",
      "9 woiprd\n",
      "9 word\n",
      "7 work\n",
      "11 workflow\n",
      "42 xavier\n",
      "10 xfb\n",
      "31 xima\n",
      "12 ximo\n",
      "26 ximos\n",
      "58 xlsx\n",
      "33 xml\n",
      "11 xmlns\n",
      "45 xx\n",
      "10 xxx\n",
      "10 xxxx\n",
      "80 yahoo\n",
      "8 yuri\n",
      "605 zc\n",
      "13 zelia\n",
      "25 zerada\n",
      "13 zerado\n",
      "14 zero\n",
      "11 zga\n",
      "14 zilda\n",
      "13 zip\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sum up the counts of each vocabulary word\n",
    "dist = np.sum(train_features, axis=0)\n",
    "\n",
    "# For each, print the vocabulary word and the number of times it \n",
    "# appears in the training set\n",
    "for tag, count in zip(vocab, dist):\n",
    "    print count, tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Random Forest\n",
    "At this point, we have numeric training features from the Bag of Words and the original sentiment labels for each feature vector, so let's do some supervised learning! Here, we'll use the Random Forest classifier that we introduced in the Titanic tutorial.  The Random Forest algorithm is included in scikit-learn (Random Forest uses many tree-based classifiers to make predictions, hence the \"forest\"). Below, we set the number of trees to 100 as a reasonable default value. More trees may (or may not) perform better, but will certainly take longer to run. Likewise, the more features you include for each review, the longer this will take."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_results = cross_validation.cross_val_score(RandomForestClassifier(n_estimators=100), \n",
    "                                              data[data.columns.difference(['class'])], \n",
    "                                              data['class'], cv=10, scoring=\"accuracy\", n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    cv_re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create function to report results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the parameters to search for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_dist = {\"n_estimators\":[100, 400],\n",
    "              \"max_depth\": [3, None],\n",
    "              \"max_features\": sp_randint(1, 11),\n",
    "              \"min_samples_split\": sp_randint(5, 11),\n",
    "              \"min_samples_leaf\": sp_randint(5, 11),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a randomized parameter search to train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(forest, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/.local/lib/python2.7/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "random_search.fit(train_features, train.text)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the random forest...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "fit() got an unexpected keyword argument 'njobs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-1fb06b82f325>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# This may take a few minutes to run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mforest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnjobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: fit() got an unexpected keyword argument 'njobs'"
     ]
    }
   ],
   "source": [
    "print \"Training the random forest...\"\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize a Random Forest classifier with 100 trees\n",
    "forest = RandomForestClassifier(n_estimators = 100) \n",
    "\n",
    "# Fit the forest to the training set, using the bag of words as \n",
    "# features and the sentiment labels as the response variable\n",
    "#\n",
    "# This may take a few minutes to run\n",
    "forest = forest.fit( train_features, data[\"text\"], njobs = -1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Submission\n",
    "All that remains is to run the trained Random Forest on our test set and create a submission file. If you haven't already done so, download testData.tsv from the Data page. This file contains another 25,000 reviews and ids; our task is to predict the sentiment label.\n",
    "\n",
    "Note that when we use the Bag of Words for the test set, we only call \"transform\", not \"fit_transform\" as we did for the training set. In machine learning, you shouldn't use the test set to fit your model, otherwise you run the risk of overfitting. For this reason, we keep the test set off-limits until we are ready to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2)\n",
      "Cleaning and parsing the test set movie reviews...\n",
      "\n",
      "Review 1000 of 25000\n",
      "\n",
      "Review 2000 of 25000\n",
      "\n",
      "Review 3000 of 25000\n",
      "\n",
      "Review 4000 of 25000\n",
      "\n",
      "Review 5000 of 25000\n",
      "\n",
      "Review 6000 of 25000\n",
      "\n",
      "Review 7000 of 25000\n",
      "\n",
      "Review 8000 of 25000\n",
      "\n",
      "Review 9000 of 25000\n",
      "\n",
      "Review 10000 of 25000\n",
      "\n",
      "Review 11000 of 25000\n",
      "\n",
      "Review 12000 of 25000\n",
      "\n",
      "Review 13000 of 25000\n",
      "\n",
      "Review 14000 of 25000\n",
      "\n",
      "Review 15000 of 25000\n",
      "\n",
      "Review 16000 of 25000\n",
      "\n",
      "Review 17000 of 25000\n",
      "\n",
      "Review 18000 of 25000\n",
      "\n",
      "Review 19000 of 25000\n",
      "\n",
      "Review 20000 of 25000\n",
      "\n",
      "Review 21000 of 25000\n",
      "\n",
      "Review 22000 of 25000\n",
      "\n",
      "Review 23000 of 25000\n",
      "\n",
      "Review 24000 of 25000\n",
      "\n",
      "Review 25000 of 25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read the test data\n",
    "test = pd.read_csv(\"testData.tsv\", header=0, delimiter=\"\\t\", \\\n",
    "                   quoting=3 )\n",
    "\n",
    "# Verify that there are 25,000 rows and 2 columns\n",
    "print test.shape\n",
    "\n",
    "# Create an empty list and append the clean reviews one by one\n",
    "num_reviews = len(test[\"review\"])\n",
    "clean_test_reviews = [] \n",
    "\n",
    "print \"Cleaning and parsing the test set movie reviews...\\n\"\n",
    "for i in xrange(0,num_reviews):\n",
    "    if( (i+1) % 1000 == 0 ):\n",
    "        print \"Review %d of %d\\n\" % (i+1, num_reviews)\n",
    "    clean_review = review_to_words( test[\"review\"][i] )\n",
    "    clean_test_reviews.append( clean_review )\n",
    "\n",
    "# Get a bag of words for the test set, and convert to a numpy array\n",
    "test_data_features = vectorizer.transform(clean_test_reviews)\n",
    "test_data_features = test_data_features.toarray()\n",
    "\n",
    "# Use the random forest to make sentiment label predictions\n",
    "result = forest.predict(test_data_features)\n",
    "\n",
    "# Copy the results to a pandas dataframe with an \"id\" column and\n",
    "# a \"sentiment\" column\n",
    "output = pd.DataFrame( data={\"id\":test[\"id\"], \"sentiment\":result} )\n",
    "\n",
    "# Use pandas to write the comma-separated output file\n",
    "output.to_csv( \"Bag_of_Words_model.csv\", index=False, quoting=3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, you are ready to make your first submission! Try different things and see how your results change. You can clean the reviews differently, choose a different number of vocabulary words for the Bag of Words representation, try Porter Stemming, a different classifier, or any number of other things. To try out your NLP chops on a different data set, you can also head over to our Rotten Tomatoes competition. Or, if you're ready for something completely different, move along to the Deep Learning and Word Vector pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing to Train a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now down to the nitty-gritty! First, we read in the data with pandas, as we did in Part 1. Unlike Part 1, we now use unlabeledTrain.tsv, which contains 50,000 additional reviews with no labels. When we built the Bag of Words model in Part 1, extra unlabeled training reviews were not useful. However, since Word2Vec can learn from unlabeled data, these extra 50,000 reviews can now be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read data from files \n",
    "train = pd.read_csv( \"labeledTrainData.tsv\", header=0, \n",
    " delimiter=\"\\t\", quoting=3, encoding=\"utf-8\") \n",
    "test = pd.read_csv( \"testData.tsv\", header=0, delimiter=\"\\t\", quoting=3 , encoding=\"utf-8\")\n",
    "unlabeled_train = pd.read_csv( \"unlabeledTrainData.tsv\", header=0, \n",
    " delimiter=\"\\t\", quoting=3 , encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Verify the number of reviews that were read (100,000 in total)\n",
    "print \"Read %d labeled train reviews, %d labeled test reviews, \" \\\n",
    " \"and %d unlabeled reviews\\n\" % (train[\"review\"].size,  \n",
    " test[\"review\"].size, unlabeled_train[\"review\"].size )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions we write to clean the data are also similar to Part 1, although now there are a couple of differences. First, to train Word2Vec it is better not to remove stop words because the algorithm relies on the broader context of the sentence in order to produce high-quality word vectors. For this reason, we will make stop word removal optional in the functions below. It also might be better not to remove numbers, but we leave that as an exercise for the reader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import various modules for string cleaning\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def review_to_wordlist( review, remove_stopwords=False ):\n",
    "    # Function to convert a document to a sequence of words,\n",
    "    # optionally removing stop words.  Returns a list of words.\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(review).get_text()\n",
    "    #  \n",
    "    # 2. Remove non-letters\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    #\n",
    "    # 3. Convert words to lower case and split them\n",
    "    words = review_text.lower().split()\n",
    "    #\n",
    "    # 4. Optionally remove stop words (false by default)\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    #\n",
    "    # 5. Return a list of words\n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want a specific input format. Word2Vec expects single sentences, each one as a list of words. In other words, the input format is a list of lists.\n",
    "\n",
    "It is not at all straightforward how to split a paragraph into sentences. There are all kinds of gotchas in natural language. English sentences can end with \"?\", \"!\", \"\"\", or \".\", among other things, and spacing and capitalization are not reliable guides either. For this reason, we'll use NLTK's punkt tokenizer for sentence splitting. In order to use this, you will need to install NLTK and use nltk.download() to download the relevant training file for punkt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Download the punkt tokenizer for sentence splitting\n",
    "import nltk.data\n",
    "#nltk.download()   \n",
    "# Load the punkt tokenizer\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a function to split a review into parsed sentences\n",
    "def review_to_sentences( review, tokenizer, remove_stopwords=False ):\n",
    "    # Function to split a review into parsed sentences. Returns a \n",
    "    # list of sentences, where each sentence is a list of words\n",
    "    #\n",
    "    # 1. Use the NLTK tokenizer to split the paragraph into sentences\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "    #\n",
    "    # 2. Loop over each sentence\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        # If a sentence is empty, skip it\n",
    "        if len(raw_sentence) > 0:\n",
    "            # Otherwise, call review_to_wordlist to get a list of words\n",
    "            sentences.append( review_to_wordlist( raw_sentence, \\\n",
    "              remove_stopwords ))\n",
    "    #\n",
    "    # Return the list of sentences (each sentence is a list of words,\n",
    "    # so this returns a list of lists\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can apply this function to prepare our data for input to Word2Vec (this will take a couple minutes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "sentences = []  # Initialize an empty list of sentences\n",
    "\n",
    "print \"Parsing sentences from training set\"\n",
    "for review in train[\"review\"]:\n",
    "    sentences += review_to_sentences(review, tokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Parsing sentences from unlabeled set\"\n",
    "for review in unlabeled_train[\"review\"]:\n",
    "    sentences += review_to_sentences(review, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can apply this function to prepare our data for input to Word2Vec (this will take a couple minutes):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may get a few warnings from BeautifulSoup about URLs in the sentences. These are nothing to worry about (although you may want to consider removing URLs when cleaning the text). \n",
    "\n",
    "We can take a look at the output to see how this differs from Part 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Saving Your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the list of nicely parsed sentences, we're ready to train the model. There are a number of parameter choices that affect the run time and the quality of the final model that is produced. For details on the algorithms below, see the word2vec API documentation as well as the Google documentation. \n",
    "\n",
    "    Architecture: Architecture options are skip-gram (default) or continuous bag of words. We found that skip-gram was very slightly slower but produced better results.\n",
    "    Training algorithm: Hierarchical softmax (default) or negative sampling. For us, the default worked well.\n",
    "    Downsampling of frequent words: The Google documentation recommends values between .00001 and .001. For us, values closer 0.001 seemed to improve the accuracy of the final model.\n",
    "    Word vector dimensionality: More features result in longer runtimes, and often, but not always, result in better models. Reasonable values can be in the tens to hundreds; we used 300.\n",
    "    Context / window size: How many words of context should the training algorithm take into account? 10 seems to work well for hierarchical softmax (more is better, up to a point).\n",
    "    Worker threads: Number of parallel processes to run. This is computer-specific, but between 4 and 6 should work on most systems.\n",
    "    Minimum word count: This helps limit the size of the vocabulary to meaningful words. Any word that does not occur at least this many times across all documents is ignored. Reasonable values could be between 10 and 100. In this case, since each movie occurs 30 times, we set the minimum word count to 40, to avoid attaching too much importance to individual movie titles. This resulted in an overall vocabulary size of around 15,000 words. Higher values also help limit run time.\n",
    "\n",
    "Choosing parameters is not easy, but once we have chosen our parameters, creating a Word2Vec model is straightforward:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the built-in logging module and configure it so that Word2Vec \n",
    "# creates nice output messages\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "    level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set values for various parameters\n",
    "num_features = 300    # Word vector dimensionality                      \n",
    "min_word_count = 40   # Minimum word count                        \n",
    "num_workers = 8       # Number of threads to run in parallel\n",
    "context = 10          # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Initialize and train the model (this will take some time)\n",
    "from gensim.models import word2vec\n",
    "print \"Training model...\"\n",
    "model = word2vec.Word2Vec(sentences, workers=num_workers, \\\n",
    "            size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If you don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# It can be helpful to create a meaningful model name and \n",
    "# save the model for later use. You can load it later using Word2Vec.load()\n",
    "model_name = \"300features_40minwords_10context\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a dual-core Macbook Pro, this took less than 15 minutes to run using 4 worker threads. However, it will vary depending on your computer. Fortunately, the logging functionality prints informative messages.\n",
    "\n",
    "If you are on a Mac or Linux system, you can use the \"top\" command from within Terminal (not from within Python) to see if your system is successfully parallelizing while the model is training. Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the Model Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations on making it successfully through everything so far! Let's take a look at the model we created out of our 75,000 training reviews.\n",
    "\n",
    "The \"doesnt_match\" function will try to deduce which word in a set is most dissimilar from the others:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kitchen'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"man woman child kitchen\".split())\n",
    "'kitchen'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is capable of distinguishing differences in meaning! It knows that men, women and children are more similar to each other than they are to kitchens. More exploration shows that the model is sensitive to more subtle differences in meaning, such as differences between countries and cities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'berlin'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"france england germany berlin\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... although with the relatively small training set we used, it's certainly not perfect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'paris'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"paris berlin london austria\".split())\n",
    "'paris'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the \"most_similar\" function to get insight into the model's word clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'woman', 0.6322274208068848),\n",
       " (u'lady', 0.5871136784553528),\n",
       " (u'lad', 0.5658714175224304),\n",
       " (u'men', 0.5298689603805542),\n",
       " (u'monk', 0.5283631086349487),\n",
       " (u'businessman', 0.5234595537185669),\n",
       " (u'millionaire', 0.5194512605667114),\n",
       " (u'soldier', 0.5185883641242981),\n",
       " (u'guy', 0.5120233297348022),\n",
       " (u'person', 0.5120117664337158)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"man\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'princess', 0.6948347687721252),\n",
       " (u'bride', 0.6394442319869995),\n",
       " (u'goddess', 0.6107475161552429),\n",
       " (u'mistress', 0.6015448570251465),\n",
       " (u'mary', 0.5880306363105774),\n",
       " (u'eva', 0.5803037881851196),\n",
       " (u'angela', 0.5779411792755127),\n",
       " (u'duchess', 0.5745822787284851),\n",
       " (u'dame', 0.5716529488563538),\n",
       " (u'maid', 0.570807695388794)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"queen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given our particular training set, it's not surprising that \"Latifah\" is a top hit for similarity with \"Queen\".\n",
    "\n",
    "Or, more relevant for sentiment analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'terrible', 0.7888780832290649),\n",
       " (u'atrocious', 0.7586556673049927),\n",
       " (u'horrible', 0.7239440679550171),\n",
       " (u'horrendous', 0.7101829648017883),\n",
       " (u'dreadful', 0.7024926543235779),\n",
       " (u'abysmal', 0.6903165578842163),\n",
       " (u'horrid', 0.6864355206489563),\n",
       " (u'appalling', 0.6766446232795715),\n",
       " (u'crappy', 0.6405069828033447),\n",
       " (u'lousy', 0.638817548751831)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"awful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems we have a reasonably good model for semantic meaning - at least as good as Bag of Words. But how can we use these fancy distributed word vectors for supervised learning? The next section takes a stab at that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: More Fun With Word Vectors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numeric Representations of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a trained model with some semantic understanding of words, how should we use it? If you look beneath the hood, the Word2Vec model trained in Part 2 consists of a feature vector for each word in the vocabulary, stored in a numpy array called \"syn0\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the model that we created in Part 2\n",
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec.load(\"300features_40minwords_10context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.syn0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16490, 300)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.syn0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of rows in syn0 is the number of words in the model's vocabulary, and the number of columns corresponds to the size of the feature vector, which we set in Part 2.  Setting the minimum word count to 40 gave us a total vocabulary of 16,492 words with 300 features apiece. Individual word vectors can be accessed in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -3.55882496e-02,   2.47471277e-02,  -1.04208276e-01,\n",
       "         3.29137072e-02,   2.55899355e-02,   1.74981821e-02,\n",
       "         7.12182969e-02,  -1.42839095e-02,   1.58416592e-02,\n",
       "         9.37454402e-02,  -5.58592677e-02,  -9.29856598e-02,\n",
       "         3.26889344e-02,   1.06930472e-01,   1.85630401e-03,\n",
       "         1.11467671e-02,  -6.41966760e-02,  -2.04013456e-02,\n",
       "        -4.45806980e-02,  -6.75038025e-02,  -1.59813195e-01,\n",
       "        -2.08285563e-02,   1.11681387e-01,   7.89937824e-02,\n",
       "        -6.63784519e-02,  -1.86357126e-02,  -6.04835339e-02,\n",
       "        -7.14961141e-02,  -4.50195335e-02,  -2.05224138e-02,\n",
       "         3.61643173e-02,   9.60387886e-02,  -5.84295951e-02,\n",
       "         6.81338832e-02,  -9.61724818e-02,  -6.60632912e-04,\n",
       "        -8.50417186e-03,  -1.10230200e-01,   7.37866983e-02,\n",
       "         5.62555194e-02,  -2.51879990e-02,  -3.53787579e-02,\n",
       "        -1.61538199e-02,  -1.98000092e-02,   2.87626851e-02,\n",
       "        -6.33075312e-02,  -8.02566037e-02,  -3.68730538e-02,\n",
       "         4.61276323e-02,   1.12826891e-01,  -1.10806301e-01,\n",
       "         3.16583477e-02,   9.68787745e-02,  -4.78281304e-02,\n",
       "        -4.02895249e-02,  -3.52558605e-02,   1.55202113e-04,\n",
       "        -3.63130048e-02,  -1.43808022e-01,   4.42711962e-03,\n",
       "        -4.91630882e-02,  -1.77957595e-03,   5.67717180e-02,\n",
       "        -3.83522324e-02,  -9.60825905e-02,   6.81047961e-02,\n",
       "         3.63117419e-02,   5.61665557e-02,   3.71133909e-02,\n",
       "        -1.26478430e-02,  -6.53350949e-02,   8.99698865e-03,\n",
       "         3.25958407e-03,   1.46788033e-02,   3.01092640e-02,\n",
       "        -3.41891125e-02,  -5.50497361e-02,   3.73913646e-02,\n",
       "        -1.00466115e-02,   8.90686810e-02,   6.13426929e-03,\n",
       "         9.22860131e-02,   8.41703918e-03,  -1.25936776e-01,\n",
       "        -7.89619342e-04,  -3.82772870e-02,   5.67331575e-02,\n",
       "        -6.38181418e-02,   9.06023849e-03,   6.16012923e-02,\n",
       "        -6.06720746e-02,  -8.06147326e-03,  -3.72956885e-04,\n",
       "         5.19216955e-02,  -5.44601083e-02,  -3.51979248e-02,\n",
       "         7.26705790e-02,   2.23731669e-03,   4.48953360e-02,\n",
       "        -7.71032125e-02,  -1.06344307e-02,  -6.93584830e-02,\n",
       "         2.52024252e-02,  -9.72983018e-02,   2.93030590e-02,\n",
       "        -1.56248882e-01,  -3.70237827e-02,   6.73727319e-02,\n",
       "        -5.12270890e-02,  -1.60797134e-01,   3.43241543e-02,\n",
       "         5.93282981e-03,   1.59055933e-01,   2.00582650e-02,\n",
       "         5.54605983e-02,   2.42288113e-02,   7.22672716e-02,\n",
       "        -2.96430220e-03,   6.96482360e-02,   1.04704835e-01,\n",
       "         3.02894805e-02,   6.70118406e-02,  -2.81544216e-02,\n",
       "         7.29399323e-02,   3.37951556e-02,   7.13070156e-03,\n",
       "        -9.92850140e-02,   9.61361546e-03,   5.11280149e-02,\n",
       "         4.22588177e-02,   8.10209755e-03,  -1.09061738e-03,\n",
       "        -7.76890293e-02,  -3.46188061e-02,   1.34196421e-02,\n",
       "        -6.40526563e-02,  -8.23103786e-02,   2.44062040e-02,\n",
       "         1.25887990e-02,   9.38936695e-03,  -5.03795817e-02,\n",
       "         3.32552032e-03,  -3.43791284e-02,  -1.42201800e-02,\n",
       "         1.38962477e-01,  -1.03612412e-02,  -2.51625571e-02,\n",
       "         3.30625959e-02,  -4.99621741e-02,  -1.99146885e-02,\n",
       "         2.27263626e-02,  -1.37947993e-02,   5.35124466e-02,\n",
       "        -2.13138368e-02,   3.81628126e-02,   6.00395165e-02,\n",
       "        -9.40183997e-02,   4.64383997e-02,   6.40595704e-02,\n",
       "        -1.88648887e-02,  -5.72695062e-02,   8.58328715e-02,\n",
       "         2.68947389e-02,  -4.49149460e-02,  -4.95724566e-02,\n",
       "        -3.81453410e-02,  -5.25868274e-02,   4.20970023e-02,\n",
       "         4.30612825e-03,  -3.16251558e-03,  -7.42969811e-02,\n",
       "        -7.17648119e-02,  -2.11895574e-02,  -3.29929553e-02,\n",
       "         7.43309706e-02,   2.93748267e-02,  -7.64147267e-02,\n",
       "        -1.39336120e-02,   4.30943780e-02,  -4.05436642e-02,\n",
       "        -5.21518961e-02,  -4.67929468e-02,  -9.57569852e-02,\n",
       "        -3.45414095e-02,   4.56543751e-02,  -4.96648885e-02,\n",
       "         6.47902712e-02,  -1.09537117e-01,  -3.01021263e-02,\n",
       "        -5.76988794e-02,  -2.06429083e-02,  -5.73864058e-02,\n",
       "         1.38882454e-02,   8.62225331e-03,   7.58093819e-02,\n",
       "        -3.66315022e-02,  -2.12668721e-02,   2.15990487e-02,\n",
       "        -3.21666859e-02,   4.98779342e-02,   5.44862039e-02,\n",
       "        -2.67323270e-03,   2.70017143e-02,   1.29934018e-02,\n",
       "         7.21630380e-02,  -7.41390511e-02,  -8.98320079e-02,\n",
       "        -5.95589355e-02,   4.37078401e-02,   3.35343517e-02,\n",
       "        -4.02515046e-02,   3.59163433e-02,   5.97494794e-03,\n",
       "         4.70575094e-02,   3.90465595e-02,   2.56752651e-02,\n",
       "         1.86664872e-02,   2.13174466e-02,   7.76682347e-02,\n",
       "         3.57806496e-02,   8.86230394e-02,   3.34956795e-02,\n",
       "         3.75167541e-02,  -3.40588503e-02,   4.05320227e-02,\n",
       "        -5.96539229e-02,  -1.16136409e-02,  -4.03795727e-02,\n",
       "         2.83653308e-02,  -9.74851698e-02,   4.23166715e-03,\n",
       "        -2.19235495e-02,   4.66139913e-02,  -5.44767082e-02,\n",
       "        -1.74504835e-02,  -2.72377990e-02,   7.87099451e-03,\n",
       "        -5.81324883e-02,   3.79459560e-02,  -4.54776101e-02,\n",
       "         5.31399213e-02,   3.65951434e-02,  -2.69994903e-02,\n",
       "        -4.20414954e-02,   5.81425056e-03,  -2.17873976e-03,\n",
       "         5.61670475e-02,   1.80523936e-02,   5.16059995e-02,\n",
       "        -1.89411398e-02,   4.99554574e-02,  -1.73452199e-01,\n",
       "        -8.11168365e-03,   8.00325051e-02,   3.09167169e-02,\n",
       "         7.05138445e-02,   2.81192157e-02,  -4.04772460e-02,\n",
       "         4.82485071e-02,  -3.03900316e-02,   2.77718287e-02,\n",
       "        -2.99347639e-02,  -4.83625010e-02,   3.24691869e-02,\n",
       "        -1.30199073e-02,   4.38352562e-02,   1.05329327e-01,\n",
       "        -4.57907468e-02,  -1.88184604e-02,  -4.01927624e-03,\n",
       "        -4.49867286e-02,   7.14428127e-02,  -1.49682146e-02,\n",
       "         9.17007476e-02,   8.07429384e-03,  -8.74338076e-02,\n",
       "         4.05235700e-02,  -8.38367939e-02,  -8.38455185e-03,\n",
       "         2.78369524e-02,  -8.83844867e-02,   9.73052252e-03,\n",
       "         6.64622858e-02,  -2.72305161e-02,  -2.83894986e-02,\n",
       "         3.59206758e-02,  -1.57311093e-02,  -1.40985548e-01,\n",
       "        -1.39436973e-02,  -4.19071354e-02,  -2.50990260e-02,\n",
       "         3.58055793e-02,  -3.15005630e-02,   7.17863366e-02,\n",
       "        -8.48470554e-02,   1.39727769e-02,  -1.43942624e-01,\n",
       "         1.87910888e-02,   1.37729958e-01,   1.03993960e-01], dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[\"flower\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Words To Paragraphs, Attempt 1: Vector Averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One challenge with the IMDB dataset is the variable-length reviews. We need to find a way to take individual word vectors and transform them into a feature set that is the same length for every review.\n",
    "\n",
    "Since each word is a vector in 300-dimensional space, we can use vector operations to combine the words in each review. One method we tried was to simply average the word vectors in a given review (for this purpose, we removed stop words, which would just add noise).\n",
    "\n",
    "The following code averages the feature vectors, building on our code from Part 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np  # Make sure that numpy is imported\n",
    "\n",
    "def makeFeatureVec(words, model, num_features):\n",
    "    # Function to average all of the word vectors in a given\n",
    "    # paragraph\n",
    "    #\n",
    "    # Pre-initialize an empty numpy array (for speed)\n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    #\n",
    "    nwords = 0.\n",
    "    # \n",
    "    # Index2word is a list that contains the names of the words in \n",
    "    # the model's vocabulary. Convert it to a set, for speed \n",
    "    index2word_set = set(model.index2word)\n",
    "    #\n",
    "    # Loop over each word in the review and, if it is in the model's\n",
    "    # vocaublary, add its feature vector to the total\n",
    "    for word in words:\n",
    "        if word in index2word_set: \n",
    "            nwords = nwords + 1.\n",
    "            featureVec = np.add(featureVec,model[word])\n",
    "    # \n",
    "    # Divide the result by the number of words to get the average\n",
    "    featureVec = np.divide(featureVec,nwords)\n",
    "    return featureVec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getAvgFeatureVecs(reviews, model, num_features):\n",
    "    # Given a set of reviews (each one a list of words), calculate \n",
    "    # the average feature vector for each one and return a 2D numpy array \n",
    "    # \n",
    "    # Initialize a counter\n",
    "    counter = 0.\n",
    "    # \n",
    "    # Preallocate a 2D numpy array, for speed\n",
    "    reviewFeatureVecs = np.zeros((len(reviews),num_features),dtype=\"float32\")\n",
    "    # \n",
    "    # Loop through the reviews\n",
    "    for review in reviews:\n",
    "       #\n",
    "       # Print a status message every 1000th review\n",
    "       if counter%1000. == 0.:\n",
    "           print \"Review %d of %d\" % (counter, len(reviews))\n",
    "       # \n",
    "       # Call the function (defined above) that makes average feature vectors\n",
    "       reviewFeatureVecs[counter] = makeFeatureVec(review, model, \\\n",
    "           num_features)\n",
    "       #\n",
    "       # Increment the counter\n",
    "       counter = counter + 1.\n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can call these functions to create average vectors for each paragraph. The following operations will take a few minutes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ****************************************************************\n",
    "# Calculate average feature vectors for training and testing sets,\n",
    "# using the functions we defined above. Notice that we now use stop word\n",
    "# removal.\n",
    "\n",
    "clean_train_reviews = []\n",
    "for review in train[\"review\"]:\n",
    "    clean_train_reviews.append( review_to_wordlist( review, \\\n",
    "        remove_stopwords=True ))\n",
    "\n",
    "trainDataVecs = getAvgFeatureVecs( clean_train_reviews, model, num_features )\n",
    "\n",
    "print \"Creating average feature vecs for test reviews\"\n",
    "clean_test_reviews = []\n",
    "for review in test[\"review\"]:\n",
    "    clean_test_reviews.append( review_to_wordlist( review, \\\n",
    "        remove_stopwords=True ))\n",
    "\n",
    "testDataVecs = getAvgFeatureVecs( clean_test_reviews, model, num_features )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, use the average paragraph vectors to train a random forest. Note that, as in Part 1, we can only use the labeled training reviews to train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit a random forest to the training data, using 100 trees\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier( n_estimators = 100 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"Fitting a random forest to labeled training data...\"\n",
    "forest = forest.fit( trainDataVecs, train[\"sentiment\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test & extract results \n",
    "result = forest.predict( testDataVecs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write the test results \n",
    "output = pd.DataFrame( data={\"id\":test[\"id\"], \"sentiment\":result} )\n",
    "output.to_csv( \"Word2Vec_AverageVectors.csv\", index=False, quoting=3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that this produced results much better than chance, but underperformed Bag of Words by a few percentage points.\n",
    "\n",
    "Since the element-wise average of the vectors didn't produce spectacular results, perhaps we could do it in a more intelligent way? A standard way of weighting word vectors is to apply \"tf-idf\" weights, which measure how important a given word is within a given set of documents. One way to extract tf-idf weights in Python is by using scikit-learn's TfidfVectorizer, which has an interface similar to the CountVectorizer that we used in Part 1. However, when we tried weighting our word vectors in this way, we found no substantial improvement in performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Words to Paragraphs, Attempt 2: Clustering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec creates clusters of semantically related words, so another possible approach is to exploit the similarity of words within a cluster. Grouping vectors in this way is known as \"vector quantization.\" To accomplish this, we first need to find the centers of the word clusters, which we can do by using a clustering algorithm such as K-Means.\n",
    "\n",
    "In K-Means, the one parameter we need to set is \"K,\" or the number of clusters. How should we decide how many clusters to create? Trial and error suggested that small clusters, with an average of only 5 words or so per cluster, gave better results than large clusters with many words. Clustering code is given below. We use scikit-learn to perform our K-Means.\n",
    "\n",
    "K-Means clustering with large K can be very slow; the following code took more than 40 minutes on my computer. Below, we set a timer around the K-Means function to see how long it takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import time\n",
    "\n",
    "start = time.time() # Start time\n",
    "\n",
    "# Set \"k\" (num_clusters) to be 1/5th of the vocabulary size, or an\n",
    "# average of 5 words per cluster\n",
    "word_vectors = model.syn0\n",
    "num_clusters = word_vectors.shape[0] / 5\n",
    "\n",
    "# Initalize a k-means object and use it to extract centroids\n",
    "kmeans_clustering = KMeans( n_clusters = num_clusters )\n",
    "idx = kmeans_clustering.fit_predict( word_vectors )\n",
    "\n",
    "# Get the end time and print how long the process took\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print \"Time taken for K Means clustering: \", elapsed, \"seconds.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cluster assignment for each word is now stored in idx, and the vocabulary from our original Word2Vec model is still stored in model.index2word. For convenience, we zip these into one dictionary as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a Word / Index dictionary, mapping each vocabulary word to\n",
    "# a cluster number                                                                                            \n",
    "word_centroid_map = dict(zip( model.index2word, idx ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a little abstract, so let's take a closer look at what our clusters contain. Your clusters may differ, as Word2Vec relies on a random number seed. Here is a loop that prints out the words for clusters 0 through 9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For the first 10 clusters\n",
    "for cluster in xrange(0,10):\n",
    "    #\n",
    "    # Print the cluster number  \n",
    "    print \"\\nCluster %d\" % cluster\n",
    "    #\n",
    "    # Find all of the words for that cluster number, and print them out\n",
    "    words = []\n",
    "    for i in xrange(0,len(word_centroid_map.values())):\n",
    "        if( word_centroid_map.values()[i] == cluster ):\n",
    "            words.append(word_centroid_map.keys()[i])\n",
    "    print words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are very interesting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-101-ddaca8b2cd9f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-101-ddaca8b2cd9f>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Cluster 0\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Cluster 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cluster 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cluster 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cluster 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cluster 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cluster 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cluster 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cluster 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cluster 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cluster 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the clusters are of varying quality. Some make sense - Cluster 3 mostly contains names, and Clusters 6-8 contain related adjectives (Cluster 6 is my favorite). On the other hand, Cluster 5 is a little mystifying: What do a lobster and a deer have in common (besides being two animals)? Cluster 0 is even worse: Penthouses and suites seem to belong together, but they don't seem to belong with apples and passports. Cluster 2 contains ... maybe war-related words? Perhaps our algorithm works best on adjectives.\n",
    "\n",
    "At any rate, now we have a cluster (or \"centroid\") assignment for each word, and we can define a function to convert reviews into bags-of-centroids. This works just like Bag of Words but uses semantically related clusters instead of individual words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_bag_of_centroids( wordlist, word_centroid_map ):\n",
    "    #\n",
    "    # The number of clusters is equal to the highest cluster index\n",
    "    # in the word / centroid map\n",
    "    num_centroids = max( word_centroid_map.values() ) + 1\n",
    "    #\n",
    "    # Pre-allocate the bag of centroids vector (for speed)\n",
    "    bag_of_centroids = np.zeros( num_centroids, dtype=\"float32\" )\n",
    "    #\n",
    "    # Loop over the words in the review. If the word is in the vocabulary,\n",
    "    # find which cluster it belongs to, and increment that cluster count \n",
    "    # by one\n",
    "    for word in wordlist:\n",
    "        if word in word_centroid_map:\n",
    "            index = word_centroid_map[word]\n",
    "            bag_of_centroids[index] += 1\n",
    "    #\n",
    "    # Return the \"bag of centroids\"\n",
    "    return bag_of_centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function above will give us a numpy array for each review, each with a number of features equal to the number of clusters. Finally, we create bags of centroids for our training and test set, then train a random forest and extract results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pre-allocate an array for the training set bags of centroids (for speed)\n",
    "train_centroids = np.zeros( (train[\"review\"].size, num_clusters), \\\n",
    "    dtype=\"float32\" )\n",
    "\n",
    "# Transform the training set reviews into bags of centroids\n",
    "counter = 0\n",
    "for review in clean_train_reviews:\n",
    "    train_centroids[counter] = create_bag_of_centroids( review, \\\n",
    "        word_centroid_map )\n",
    "    counter += 1\n",
    "\n",
    "# Repeat for test reviews \n",
    "test_centroids = np.zeros(( test[\"review\"].size, num_clusters), \\\n",
    "    dtype=\"float32\" )\n",
    "\n",
    "counter = 0\n",
    "for review in clean_test_reviews:\n",
    "    test_centroids[counter] = create_bag_of_centroids( review, \\\n",
    "        word_centroid_map )\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit a random forest and extract predictions \n",
    "forest = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "# Fitting the forest may take a few minutes\n",
    "print \"Fitting a random forest to labeled training data...\"\n",
    "forest = forest.fit(train_centroids,train[\"sentiment\"])\n",
    "result = forest.predict(test_centroids)\n",
    "\n",
    "# Write the test results \n",
    "output = pd.DataFrame(data={\"id\":test[\"id\"], \"sentiment\":result})\n",
    "output.to_csv( \"BagOfCentroids.csv\", index=False, quoting=3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that the code above gives about the same (or slightly worse) results compared to the Bag of Words in Part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
