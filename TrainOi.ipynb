{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import numpy as np\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.learning_curve import learning_curve\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The necessary files can be downloaded from the Data page. The first file that you'll need is unlabeledTrainData.tsv, which contains 25,000 IMDB movie reviews, each with a positive or negative sentiment label.\n",
    "\n",
    "Next, read the tab-delimited file into Python. To do this, we can use the pandas package, introduced in the Titanic tutorial, which provides the read_csv function for easily reading and writing data files. If you haven't used pandas before, you may need to install it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the pandas package, then use the \"read_csv\" function to read\n",
    "# the labeled training data\n",
    "import pandas as pd       \n",
    "train = pd.read_csv(\"train.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, \"header=0\" indicates that the first line of the file contains column names, \"delimiter=\\t\" indicates that the fields are separated by tabs, and quoting=3 tells Python to ignore doubled quotes, otherwise you may encounter errors trying to read the file.\n",
    "\n",
    "We can make sure that we read 25,000 rows and 3 columns as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41686, 2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['text', 'class'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>automação travando z logof teclado mouse ctxre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c inadimplência terminais suspenso senhores ve...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tentato cancelamento executada invalido possiv...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enviada clarify ordem</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>interoperação wll novas falha devido usuária a...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  class\n",
       "0  automação travando z logof teclado mouse ctxre...      1\n",
       "1  c inadimplência terminais suspenso senhores ve...      1\n",
       "2  tentato cancelamento executada invalido possiv...      2\n",
       "3                              enviada clarify ordem      2\n",
       "4  interoperação wll novas falha devido usuária a...      2"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0:5]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The three columns are called \"id\", \"sentiment\", and \"array.\"  Now that you've read the training set, take a look at a few reviews:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a reminder, this will show you the first movie review in the column named \"review.\" You should see a review that starts like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automação travando z logof teclado mouse ctxrecsa opção máquinas sistema/serviço\n"
     ]
    }
   ],
   "source": [
    "print train[\"text\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing HTML Markup: The BeautifulSoup Package\n",
    "\n",
    "First, we'll remove the HTML tags. For this purpose, we'll use the Beautiful Soup library. If you don't have Beautiful soup installed, do:\n",
    "Then, from within Python, load the package and use it to extract the text from a review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automação travando z logof teclado mouse ctxrecsa opção máquinas sistema/serviço\n",
      "automação travando z logof teclado mouse ctxrecsa opção máquinas sistema/serviço\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 174 of the file /usr/lib/python2.7/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "# Import BeautifulSoup into your workspace\n",
    "from bs4 import BeautifulSoup             \n",
    "\n",
    "# Initialize the BeautifulSoup object on a single movie review     \n",
    "example1 = BeautifulSoup(train[\"text\"][0])  \n",
    "\n",
    "# Print the raw review and then the output of get_text(), for \n",
    "# comparison\n",
    "print train[\"text\"][0]\n",
    "print example1.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling get_text() gives you the text of the review, without tags or markup. If you browse the BeautifulSoup documentation, you'll see that it's a very powerful library - more powerful than we need for this dataset. However, it is not considered a reliable practice to remove markup using regular expressions, so even for an application as simple as this, it's usually best to use a package like BeautifulSoup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with Punctuation, Numbers and Stopwords: NLTK and regular expressions\n",
    "\n",
    "When considering how to clean the text, we should think about the data problem we are trying to solve. For many problems, it makes sense to remove punctuation. On the other hand, in this case, we are tackling a sentiment analysis problem, and it is possible that \"!!!\" or \":-(\" could carry sentiment, and should be treated as words. In this tutorial, for simplicity, we remove the punctuation altogether, but it is something you can play with on your own.\n",
    "\n",
    "Similarly, in this tutorial we will remove numbers, but there are other ways of dealing with them that make just as much sense. For example, we could treat them as words, or replace them all with a placeholder string such as \"NUM\".\n",
    "\n",
    "To remove punctuation and numbers, we will use a package for dealing with regular expressions, called re. The package comes built-in with Python; no need to install anything. For a detailed description of how regular expressions work, see the package documentation. Now, try the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automa  o travando z logof teclado mouse ctxrecsa op  o m quinas sistema servi o\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# Use regular expressions to do a find-and-replace\n",
    "letters_only = re.sub(\"[^a-zA-Z]\",           # The pattern to search for\n",
    "                      \" \",                   # The pattern to replace it with\n",
    "                      example1.get_text() )  # The text to search\n",
    "print letters_only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A full overview of regular expressions is beyond the scope of this tutorial, but for now it is sufficient to know that [] indicates group membership and ^ means \"not\". In other words, the re.sub() statement above says, \"Find anything that is NOT a lowercase letter (a-z) or an upper case letter (A-Z), and replace it with a space.\"\n",
    "\n",
    "We'll also convert our reviews to lower case and split them into individual words (called \"tokenization\" in NLP lingo):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lower_case = letters_only.lower()        # Convert to lower case\n",
    "words = lower_case.split()               # Split into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'automa', u'o', u'travando', u'z', u'logof']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to decide how to deal with frequently occurring words that don't carry much meaning. Such words are called \"stop words\"; in English they include words such as \"a\", \"and\", \"is\", and \"the\". Conveniently, there are Python packages that come with stop word lists built in. Let's import a stop word list from the Python Natural Language Toolkit (NLTK). You'll need to install the library if you don't already have it on your computer; you'll also need to install the data packages that come with it, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'de', u'a', u'o', u'que', u'e', u'do', u'da', u'em', u'um', u'para', u'com', u'n\\xe3o', u'uma', u'os', u'no', u'se', u'na', u'por', u'mais', u'as', u'dos', u'como', u'mas', u'ao', u'ele', u'das', u'\\xe0', u'seu', u'sua', u'ou', u'quando', u'muito', u'nos', u'j\\xe1', u'eu', u'tamb\\xe9m', u's\\xf3', u'pelo', u'pela', u'at\\xe9', u'isso', u'ela', u'entre', u'depois', u'sem', u'mesmo', u'aos', u'seus', u'quem', u'nas', u'me', u'esse', u'eles', u'voc\\xea', u'essa', u'num', u'nem', u'suas', u'meu', u'\\xe0s', u'minha', u'numa', u'pelos', u'elas', u'qual', u'n\\xf3s', u'lhe', u'deles', u'essas', u'esses', u'pelas', u'este', u'dele', u'tu', u'te', u'voc\\xeas', u'vos', u'lhes', u'meus', u'minhas', u'teu', u'tua', u'teus', u'tuas', u'nosso', u'nossa', u'nossos', u'nossas', u'dela', u'delas', u'esta', u'estes', u'estas', u'aquele', u'aquela', u'aqueles', u'aquelas', u'isto', u'aquilo', u'estou', u'est\\xe1', u'estamos', u'est\\xe3o', u'estive', u'esteve', u'estivemos', u'estiveram', u'estava', u'est\\xe1vamos', u'estavam', u'estivera', u'estiv\\xe9ramos', u'esteja', u'estejamos', u'estejam', u'estivesse', u'estiv\\xe9ssemos', u'estivessem', u'estiver', u'estivermos', u'estiverem', u'hei', u'h\\xe1', u'havemos', u'h\\xe3o', u'houve', u'houvemos', u'houveram', u'houvera', u'houv\\xe9ramos', u'haja', u'hajamos', u'hajam', u'houvesse', u'houv\\xe9ssemos', u'houvessem', u'houver', u'houvermos', u'houverem', u'houverei', u'houver\\xe1', u'houveremos', u'houver\\xe3o', u'houveria', u'houver\\xedamos', u'houveriam', u'sou', u'somos', u's\\xe3o', u'era', u'\\xe9ramos', u'eram', u'fui', u'foi', u'fomos', u'foram', u'fora', u'f\\xf4ramos', u'seja', u'sejamos', u'sejam', u'fosse', u'f\\xf4ssemos', u'fossem', u'for', u'formos', u'forem', u'serei', u'ser\\xe1', u'seremos', u'ser\\xe3o', u'seria', u'ser\\xedamos', u'seriam', u'tenho', u'tem', u'temos', u't\\xe9m', u'tinha', u't\\xednhamos', u'tinham', u'tive', u'teve', u'tivemos', u'tiveram', u'tivera', u'tiv\\xe9ramos', u'tenha', u'tenhamos', u'tenham', u'tivesse', u'tiv\\xe9ssemos', u'tivessem', u'tiver', u'tivermos', u'tiverem', u'terei', u'ter\\xe1', u'teremos', u'ter\\xe3o', u'teria', u'ter\\xedamos', u'teriam']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "print stopwords.words(\"portuguese\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will allow you to view the list of English-language stop words. To remove stop words from our movie review, do:\n",
    "This looks at each word in our \"words\" list, and discards anything that is found in the list of stop words. After all of these steps, your review should now begin something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'automa', u'travando', u'z', u'logof', u'teclado']\n"
     ]
    }
   ],
   "source": [
    "# Remove stop words from \"words\"\n",
    "words = [w for w in words if not w in stopwords.words(\"portuguese\")]\n",
    "print words[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't worry about the \"u\" before each word; it just indicates that Python is internally representing each word as a unicode string.\n",
    "\n",
    "There are many other things we could do to the data - For example, Porter Stemming and Lemmatizing (both available in NLTK) would allow us to treat \"messages\", \"message\", and \"messaging\" as the same word, which could certainly be useful. However, for simplicity, the tutorial will stop here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together\n",
    "Now we have code to clean one review - but we need to clean 25,000 training reviews! To make our code reusable, let's create a function that can be called many times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_to_words( raw_review ):\n",
    "    # Function to convert a raw review to a string of words\n",
    "    # The input is a single string (a raw movie review), and \n",
    "    # the output is a single string (a preprocessed movie review)\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(raw_review).get_text() \n",
    "    #\n",
    "    # 2. Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text) \n",
    "    #\n",
    "    # 3. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()                             \n",
    "    #\n",
    "    # 4. In Python, searching a set is much faster than searching\n",
    "    #   a list, so convert the stop words to a set\n",
    "    stops = set(stopwords.words(\"portuguese\"))                  \n",
    "    # \n",
    "    # 5. Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]   \n",
    "    #\n",
    "    # 6. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return( \" \".join( meaningful_words ))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two elements here are new: First, we converted the stop word list to a different data type, a set. This is for speed; since we'll be calling this function tens of thousands of times, it needs to be fast, and searching sets in Python is much faster than searching lists.\n",
    "\n",
    "Second, we joined the words back into one paragraph. This is to make the output easier to use in our Bag of Words, below. After defining the above function, if you call the function for a single review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automa travando z logof teclado mouse ctxrecsa op m quinas sistema servi\n"
     ]
    }
   ],
   "source": [
    "clean_train = text_to_words( train[\"text\"][0] )\n",
    "print clean_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it should give you exactly the same output as all of the individual steps we did in preceding tutorial sections. Now let's loop through and clean all of the training set at once (this might take a few minutes depending on your computer):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41686\n"
     ]
    }
   ],
   "source": [
    "# Get the number of reviews based on the dataframe column size\n",
    "num_text = train[\"text\"].size\n",
    "\n",
    "print num_text\n",
    "\n",
    "# Initialize an empty list to hold the clean reviews\n",
    "clean_train_text = []\n",
    "\n",
    "clean_train_text = train.text.apply(text_to_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41686,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(clean_train_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Features from a Bag of Words (Using scikit-learn)\n",
    "Now that we have our training reviews tidied up, how do we convert them to some kind of numeric representation for machine learning? One common approach is called a Bag of Words. The Bag of Words model learns a vocabulary from all of the documents, then models each document by counting the number of times each word appears. For example, consider the following two sentences:\n",
    "\n",
    "Sentence 1: \"The cat sat on the hat\"\n",
    "\n",
    "Sentence 2: \"The dog ate the cat and the hat\"\n",
    "\n",
    "From these two sentences, our vocabulary is as follows:\n",
    "\n",
    "{ the, cat, sat, on, hat, dog, ate, and }\n",
    "\n",
    "To get our bags of words, we count the number of times each word occurs in each sentence. In Sentence 1, \"the\" appears twice, and \"cat\", \"sat\", \"on\", and \"hat\" each appear once, so the feature vector for Sentence 1 is:\n",
    "\n",
    "{ the, cat, sat, on, hat, dog, ate, and }\n",
    "\n",
    "Sentence 1: { 2, 1, 1, 1, 1, 0, 0, 0 }\n",
    "\n",
    "Similarly, the features for Sentence 2 are: { 3, 1, 0, 0, 1, 1, 1, 1}\n",
    "\n",
    "In the IMDB data, we have a very large number of reviews, which will give us a large vocabulary. To limit the size of the feature vectors, we should choose some maximum vocabulary size. Below, we use the 5000 most frequent words (remembering that stop words have already been removed).\n",
    "\n",
    "We'll be using the feature_extraction module from scikit-learn to create bag-of-words features. If you did the Random Forest tutorial in the Titanic competition, you should already have scikit-learn installed; otherwise you will need to install it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the bag of words...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"Creating the bag of words...\\n\"\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "# bag of words tool.  \n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 5000) \n",
    "\n",
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocabulary; second, it transforms our training data\n",
    "# into feature vectors. The input to fit_transform should be a list of \n",
    "# strings.\n",
    "train_features = vectorizer.fit_transform(clean_train_text)\n",
    "\n",
    "# Numpy arrays are easy to work with, so convert the result to an \n",
    "# array\n",
    "train_features = train_features.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see what the training data array now looks like, do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41686, 5000)\n"
     ]
    }
   ],
   "source": [
    "print train_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has 25,000 rows and 5,000 features (one for each vocabulary word).\n",
    "\n",
    "Note that CountVectorizer comes with its own options to automatically do preprocessing, tokenization, and stop word removal -- for each of these, instead of specifying \"None\", we could have used a built-in method or specified our own function to use.  See the function documentation for more details. However, we wanted to write our own function for data cleaning in this tutorial to show you how it's done step by step.\n",
    "\n",
    "Now that the Bag of Words model is trained, let's look at the vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'aa', u'aaaammdd', u'aba', u'abaixo', u'abas', u'abd', u'abend', u'aberta', u'abertas', u'aberto', u'abertos', u'abertura', u'abo', u'abonador', u'abr', u'abra', u'abre', u'abreu', u'abri', u'abril', u'abrimos', u'abrindo', u'abrir', u'abriu', u'abrtelecom', u'ac', u'aca', u'acaa', u'acabou', u'acao']\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the words in the vocabulary\n",
    "vocab = vectorizer.get_feature_names()\n",
    "print vocab[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're interested, you can also print the counts of each word in\n",
    "the vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272 aa\n",
      "13 aaaammdd\n",
      "69 aba\n",
      "200 abaixo\n",
      "8 abas\n",
      "7 abd\n",
      "20 abend\n",
      "707 aberta\n",
      "168 abertas\n",
      "601 aberto\n",
      "124 abertos\n",
      "414 abertura\n",
      "9 abo\n",
      "27 abonador\n",
      "142 abr\n",
      "11 abra\n",
      "50 abre\n",
      "29 abreu\n",
      "10 abri\n",
      "73 abril\n",
      "21 abrimos\n",
      "21 abrindo\n",
      "221 abrir\n",
      "58 abriu\n",
      "15 abrtelecom\n",
      "108 ac\n",
      "8 aca\n",
      "24 acaa\n",
      "9 acabou\n",
      "18 acao\n",
      "35 acarretando\n",
      "20 acb\n",
      "26 acc\n",
      "8 accnt\n",
      "24 account\n",
      "18 acct\n",
      "8 acd\n",
      "40 aceita\n",
      "7 aceitando\n",
      "26 aceito\n",
      "12 aceitou\n",
      "61 acertar\n",
      "102 acerto\n",
      "10 acess\n",
      "44 acessa\n",
      "115 acessado\n",
      "271 acessar\n",
      "600 acesso\n",
      "8 acessorios\n",
      "290 acessos\n",
      "80 ach\n",
      "208 acima\n",
      "33 acionar\n",
      "391 acl\n",
      "12 acm\n",
      "165 acn\n",
      "22 acoes\n",
      "19 acompanhamento\n",
      "10 acompanhamos\n",
      "27 acompanhar\n",
      "46 acontece\n",
      "26 acontecendo\n",
      "19 aconteceu\n",
      "11 acordado\n",
      "147 acordo\n",
      "16 acpa\n",
      "9 acredito\n",
      "16 acrescenta\n",
      "8 acrescentar\n",
      "10 actc\n",
      "8 active\n",
      "44 acumulo\n",
      "63 acusa\n",
      "7 acusando\n",
      "8 acusou\n",
      "72 ad\n",
      "38 ada\n",
      "8 adalberto\n",
      "10 adao\n",
      "11 adcional\n",
      "7 adcionar\n",
      "20 add\n",
      "8 ademir\n",
      "20 aderir\n",
      "21 aderiu\n",
      "60 ades\n",
      "8 adesao\n",
      "10 adi\n",
      "134 adicionado\n",
      "121 adicionais\n",
      "160 adicional\n",
      "110 adicionar\n",
      "24 adilson\n",
      "9 adm\n",
      "16 administracao\n",
      "42 administrador\n",
      "17 administradora\n",
      "11 adnc\n",
      "113 ado\n",
      "15 ados\n",
      "66 adriana\n",
      "43 adriano\n",
      "203 adsl\n",
      "9 advogados\n",
      "17 ae\n",
      "17 aef\n",
      "9 aei\n",
      "8 aelac\n",
      "27 aelba\n",
      "24 aelbe\n",
      "7 aelbf\n",
      "8 aenxo\n",
      "19 aesc\n",
      "11 aeta\n",
      "13 aez\n",
      "63 afeta\n",
      "22 afetada\n",
      "25 afetadas\n",
      "217 afetado\n",
      "69 afetados\n",
      "1212 afetando\n",
      "7 afim\n",
      "66 afirma\n",
      "8 afirmou\n",
      "19 afonso\n",
      "80 ag\n",
      "43 agencia\n",
      "9 agenda\n",
      "25 agendada\n",
      "19 agendado\n",
      "300 agendamento\n",
      "11 agendamentos\n",
      "8 agendamos\n",
      "83 agendar\n",
      "34 agente\n",
      "19 agentes\n",
      "13 agilizar\n",
      "40 agilize\n",
      "23 aglutina\n",
      "20 aglutinado\n",
      "13 aglutinador\n",
      "14 ago\n",
      "7 agostinho\n",
      "64 agosto\n",
      "124 agr\n",
      "220 agrade\n",
      "46 agradecemos\n",
      "10 agrgy\n",
      "18 agrif\n",
      "29 agrig\n",
      "57 agrih\n",
      "9 agrii\n",
      "15 agrupada\n",
      "9 agrupadas\n",
      "19 agrupado\n",
      "161 agrupador\n",
      "50 agrupamento\n",
      "7 agrupar\n",
      "24 agrx\n",
      "14 agry\n",
      "90 aguard\n",
      "33 aguarda\n",
      "357 aguardando\n",
      "30 aguardar\n",
      "11 aguarde\n",
      "52 aguardo\n",
      "33 aguiar\n",
      "13 ai\n",
      "30 aice\n",
      "9 ailton\n",
      "8 aires\n",
      "11 aja\n",
      "23 aju\n",
      "42 ajuda\n",
      "126 ajudar\n",
      "15 ajustada\n",
      "19 ajustado\n",
      "197 ajustar\n",
      "70 ajuste\n",
      "11 ajustes\n",
      "87 al\n",
      "55 alarme\n",
      "61 alberto\n",
      "30 albuquerque\n",
      "12 alcantara\n",
      "8 aldo\n",
      "63 alega\n",
      "13 alegando\n",
      "10 alem\n",
      "24 alencar\n",
      "375 alerta\n",
      "21 alessandra\n",
      "8 alessandro\n",
      "32 alex\n",
      "7 alexandra\n",
      "72 alexandre\n",
      "10 alexia\n",
      "13 alfredo\n",
      "8 alho\n",
      "36 alice\n",
      "15 alimentos\n",
      "67 aline\n",
      "32 alinhado\n",
      "12 alinhamento\n",
      "7 all\n",
      "7 allan\n",
      "10 allitems\n",
      "16 allnet\n",
      "153 almeida\n",
      "8 almir\n",
      "52 alone\n",
      "7 already\n",
      "9 alt\n",
      "15 alta\n",
      "87 altctec\n",
      "12 altenda\n",
      "9 altendb\n",
      "404 altera\n",
      "32 alteracao\n",
      "16 alterada\n",
      "60 alteradas\n",
      "302 alterado\n",
      "46 alterados\n",
      "19 alterando\n",
      "283 alterar\n",
      "24 altere\n",
      "29 alterou\n",
      "13 altmeio\n",
      "66 alto\n",
      "56 altpdem\n",
      "19 altperc\n",
      "28 alttcir\n",
      "13 aluguel\n",
      "8 alvarenga\n",
      "12 alvaro\n",
      "209 alves\n",
      "8 alzira\n",
      "50 am\n",
      "14 amanda\n",
      "38 amaral\n",
      "12 amaro\n",
      "33 amb\n",
      "26 ambas\n",
      "83 ambiente\n",
      "8 ambientes\n",
      "422 ambos\n",
      "8 amea\n",
      "13 amelia\n",
      "10 amento\n",
      "7 americo\n",
      "39 amorim\n",
      "20 amos\n",
      "15 amostra\n",
      "178 an\n",
      "142 ana\n",
      "18 analisa\n",
      "16 analisado\n",
      "8 analisados\n",
      "11 analisando\n",
      "214 analisar\n",
      "258 analise\n",
      "21 analises\n",
      "19 analista\n",
      "361 anatel\n",
      "55 andamento\n",
      "11 andamentos\n",
      "8 andar\n",
      "55 anderson\n",
      "7 andr\n",
      "126 andrade\n",
      "77 andre\n",
      "27 andrea\n",
      "28 andreia\n",
      "10 andressa\n",
      "9 andreza\n",
      "80 anexa\n",
      "36 anexada\n",
      "31 anexadas\n",
      "74 anexado\n",
      "62 anexados\n",
      "102 anexar\n",
      "15 anexas\n",
      "1443 anexo\n",
      "104 anexos\n",
      "32 angela\n",
      "13 angelica\n",
      "10 angelita\n",
      "22 angelo\n",
      "22 anjos\n",
      "9 anna\n",
      "28 ano\n",
      "10 anos\n",
      "15 anote\n",
      "14 ans\n",
      "10 ant\n",
      "96 anterior\n",
      "19 anteriores\n",
      "25 anteriormente\n",
      "37 antiga\n",
      "9 antigas\n",
      "145 antigo\n",
      "10 antigos\n",
      "7 antiv\n",
      "17 antivirus\n",
      "25 antonia\n",
      "179 antonio\n",
      "24 antunes\n",
      "19 aonde\n",
      "51 ap\n",
      "8 apaa\n",
      "24 apaga\n",
      "63 apagada\n",
      "24 apagado\n",
      "313 apagar\n",
      "9 apagou\n",
      "9 apare\n",
      "431 aparece\n",
      "73 aparecem\n",
      "146 aparecendo\n",
      "39 aparecer\n",
      "31 apareceu\n",
      "144 aparecida\n",
      "46 aparecido\n",
      "18 aparelho\n",
      "15 aparelhos\n",
      "22 aparente\n",
      "8 apartamento\n",
      "150 apenas\n",
      "44 apesar\n",
      "90 aplic\n",
      "284 aplica\n",
      "24 aplicacao\n",
      "17 aplicacoes\n",
      "25 aplicada\n",
      "7 aplicadas\n",
      "46 aplicado\n",
      "13 aplicados\n",
      "7 aplicando\n",
      "177 aplicar\n",
      "31 aplicativo\n",
      "59 apn\n",
      "64 apoio\n",
      "8 aponta\n",
      "7 apontando\n",
      "100 apos\n",
      "20 app\n",
      "1005 application\n",
      "7 apra\n",
      "44 aprazada\n",
      "10 aprece\n",
      "28 aprensenta\n",
      "600 apresenta\n",
      "174 apresentada\n",
      "165 apresentado\n",
      "71 apresentam\n",
      "579 apresentando\n",
      "22 apresentar\n",
      "88 apresentaram\n",
      "9 apresente\n",
      "132 apresentou\n",
      "12 apresta\n",
      "27 aprisionamento\n",
      "39 aprov\n",
      "48 aprova\n",
      "21 aprovada\n",
      "52 aprovado\n",
      "7 aprovisionado\n",
      "212 aprovisionamento\n",
      "8 aproximadamente\n",
      "11 aproximado\n",
      "103 apura\n",
      "78 apurado\n",
      "48 apurar\n",
      "14 aq\n",
      "7 aqui\n",
      "22 aquino\n",
      "9 aquisi\n",
      "44 ar\n",
      "9 ara\n",
      "9 aragao\n",
      "8 arantes\n",
      "9 arapongas\n",
      "146 araujo\n",
      "230 arb\n",
      "9 arbo\n",
      "611 arbor\n",
      "146 arbpc\n",
      "69 arbpd\n",
      "30 arbpe\n",
      "15 arbrc\n",
      "7 arbre\n",
      "7 arbsourcetargetprodpcs\n",
      "8 arbtd\n",
      "18 arbtm\n",
      "68 area\n",
      "7 ari\n",
      "7 ariane\n",
      "61 arm\n",
      "11 armando\n",
      "41 armario\n",
      "9 arnaldo\n",
      "24 arq\n",
      "209 arquivo\n",
      "106 arquivos\n",
      "13 arrecadacao\n",
      "16 arruda\n",
      "590 ars\n",
      "14 arthur\n",
      "17 asap\n",
      "81 asg\n",
      "10 aspx\n",
      "20 ass\n",
      "10 assessoria\n",
      "9 asset\n",
      "120 assim\n",
      "95 assinante\n",
      "9 assinantes\n",
      "170 assinatura\n",
      "27 assinaturas\n",
      "40 assis\n",
      "8 assist\n",
      "8 assistencia\n",
      "46 associa\n",
      "35 associacao\n",
      "53 associada\n",
      "24 associadas\n",
      "234 associado\n",
      "40 associados\n",
      "15 associando\n",
      "64 associar\n",
      "43 assumir\n",
      "31 assumiu\n",
      "12 assuncao\n",
      "13 assunto\n",
      "124 at\n",
      "8 ataide\n",
      "69 ate\n",
      "52 atem\n",
      "26 atemb\n",
      "51 aten\n",
      "26 atenciosamente\n",
      "106 atende\n",
      "218 atendente\n",
      "53 atender\n",
      "16 atendida\n",
      "16 atendido\n",
      "124 atendimento\n",
      "32 ativ\n",
      "705 ativa\n",
      "40 ativacao\n",
      "63 ativada\n",
      "61 ativado\n",
      "13 ativados\n",
      "19 ativando\n",
      "170 ativar\n",
      "73 ativas\n",
      "332 atividade\n",
      "138 atividades\n",
      "381 ativo\n",
      "144 ativos\n",
      "32 ativou\n",
      "44 ato\n",
      "106 atraso\n",
      "46 atraves\n",
      "23 atrelada\n",
      "43 atrelado\n",
      "8 atrelados\n",
      "47 atribu\n",
      "23 atribui\n",
      "14 atribuido\n",
      "7 atribuir\n",
      "15 atributo\n",
      "81 att\n",
      "19 atu\n",
      "10 atua\n",
      "11 atuais\n",
      "155 atual\n",
      "215 atualiza\n",
      "117 atualizacao\n",
      "29 atualizada\n",
      "10 atualizadas\n",
      "92 atualizado\n",
      "24 atualizados\n",
      "18 atualizando\n",
      "593 atualizar\n",
      "8 atualizarem\n",
      "121 atualizou\n",
      "21 atualizr\n",
      "36 atualmente\n",
      "17 atuar\n",
      "8 atuarbterc\n",
      "22 atv\n",
      "29 auditoria\n",
      "57 augusto\n",
      "54 aumento\n",
      "7 aurea\n",
      "22 aurelio\n",
      "8 aurora\n",
      "8 aus\n",
      "36 autd\n",
      "216 autentica\n",
      "322 autenticar\n",
      "26 auto\n",
      "355 autom\n",
      "7 automa\n",
      "42 automatica\n",
      "77 automaticamente\n",
      "7 automaticas\n",
      "74 automatico\n",
      "123 autor\n",
      "49 autora\n",
      "12 autoridade\n",
      "88 autoriza\n",
      "10 autorizada\n",
      "40 autorizado\n",
      "17 autorizador\n",
      "8 autorizados\n",
      "21 autorizar\n",
      "19 aux\n",
      "10 auxiliadora\n",
      "7 auxiliamos\n",
      "41 auxiliar\n",
      "16 auxilio\n",
      "32 av\n",
      "26 ava\n",
      "28 avaliar\n",
      "107 avan\n",
      "13 avancado\n",
      "43 avaya\n",
      "7 avc\n",
      "17 averiguar\n",
      "22 avila\n",
      "11 avisar\n",
      "12 avise\n",
      "9 aviso\n",
      "11 avulsa\n",
      "88 avulso\n",
      "37 avulsos\n",
      "7 azambuja\n",
      "56 azevedo\n",
      "1982 ba\n",
      "40 back\n",
      "198 backlog\n",
      "97 backoffice\n",
      "21 backup\n",
      "34 bahia\n",
      "25 bairro\n",
      "383 baixa\n",
      "46 baixada\n",
      "72 baixadas\n",
      "13 baixado\n",
      "38 baixar\n",
      "7 baixas\n",
      "27 baixo\n",
      "9 baixou\n",
      "12 banc\n",
      "110 banco\n",
      "254 banda\n",
      "9 bandeira\n",
      "13 baptista\n",
      "9 bar\n",
      "19 barbara\n",
      "114 barbosa\n",
      "10 barboza\n",
      "12 barcelos\n",
      "24 barra\n",
      "53 barramento\n",
      "24 barras\n",
      "27 barreto\n",
      "73 barros\n",
      "9 barroso\n",
      "22 bartoline\n",
      "117 bas\n",
      "294 base\n",
      "50 basico\n",
      "7 bastante\n",
      "26 bastos\n",
      "17 bat\n",
      "9 batana\n",
      "16 batch\n",
      "33 bate\n",
      "117 batimento\n",
      "84 batista\n",
      "40 bauer\n",
      "59 bb\n",
      "23 bbiprd\n",
      "98 bc\n",
      "54 bcb\n",
      "7 bcu\n",
      "7 bcv\n",
      "243 bd\n",
      "13 bdea\n",
      "8 bded\n",
      "82 bdo\n",
      "14 bds\n",
      "26 beatriz\n",
      "39 belo\n",
      "33 bem\n",
      "8 ben\n",
      "22 benedito\n",
      "263 benef\n",
      "81 beneficio\n",
      "18 beneficios\n",
      "8 benites\n",
      "19 bento\n",
      "12 bernadete\n",
      "27 bernardo\n",
      "8 bet\n",
      "52 bezerra\n",
      "93 bhe\n",
      "9 bhya\n",
      "11 bhyd\n",
      "10 bianca\n",
      "13 bib\n",
      "41 biblioteca\n",
      "153 bif\n",
      "111 bilhete\n",
      "29 bilhetes\n",
      "276 bill\n",
      "14 billing\n",
      "80 bin\n",
      "17 binado\n",
      "14 bip\n",
      "14 bispo\n",
      "12 bitencourt\n",
      "187 bito\n",
      "133 bitos\n",
      "16 bko\n",
      "655 bl\n",
      "20 bla\n",
      "9 blackberry\n",
      "15 blico\n",
      "7 blindada\n",
      "18 blindado\n",
      "30 blindagem\n",
      "21 bll\n",
      "21 blm\n",
      "7 blo\n",
      "12 bloco\n",
      "14 bloddc\n",
      "7 blomov\n",
      "106 bloqueada\n",
      "11 bloqueadas\n",
      "171 bloqueado\n",
      "27 bloqueados\n",
      "7 bloqueando\n",
      "43 bloquear\n",
      "502 bloqueio\n",
      "24 bloqueios\n",
      "7 bloquieo\n",
      "11 bma\n",
      "141 bmc\n",
      "156 bo\n",
      "242 boa\n",
      "9 boas\n",
      "22 bol\n",
      "27 boleto\n",
      "7 bolso\n",
      "267 bom\n",
      "13 bonifica\n",
      "65 bonus\n",
      "13 borba\n",
      "75 borges\n",
      "106 bot\n",
      "12 botao\n",
      "33 bov\n",
      "470 bp\n",
      "27 bpr\n",
      "30 bps\n",
      "9 bqe\n",
      "125 br\n",
      "8 bracp\n",
      "18 bradesco\n",
      "42 braga\n",
      "13 braile\n",
      "178 branco\n",
      "24 brandao\n",
      "108 brasil\n",
      "8 brasileira\n",
      "12 braz\n",
      "9 brf\n",
      "7 bri\n",
      "57 brito\n",
      "199 brt\n",
      "53 bruna\n",
      "48 bruno\n",
      "18 bs\n",
      "232 bsa\n",
      "17 bsim\n",
      "11 bt\n",
      "8 btacp\n",
      "22 btdf\n",
      "24 bueno\n",
      "441 bundle\n",
      "23 bundles\n",
      "117 busca\n",
      "7 buscar\n",
      "11 business\n",
      "20 bva\n",
      "12 by\n",
      "107 ca\n",
      "7 cabe\n",
      "53 cabo\n",
      "21 cabral\n",
      "20 cache\n",
      "17 cad\n",
      "39 cadastra\n",
      "177 cadastrada\n",
      "40 cadastradas\n",
      "225 cadastrado\n",
      "86 cadastrados\n",
      "63 cadastrais\n",
      "54 cadastral\n",
      "43 cadastramento\n",
      "220 cadastrar\n",
      "12 cadastre\n",
      "480 cadastro\n",
      "13 cadastrou\n",
      "14 cadeia\n",
      "8 cadop\n",
      "17 caetano\n",
      "18 cai\n",
      "58 caindo\n",
      "8 cair\n",
      "57 caiu\n",
      "123 caixa\n",
      "10 calcados\n",
      "9 caldas\n",
      "47 call\n",
      "14 camapanha\n",
      "8 camara\n",
      "40 camargo\n",
      "33 camila\n",
      "13 camile\n",
      "29 caminho\n",
      "8 camp\n",
      "370 campanha\n",
      "83 campanhas\n",
      "265 campo\n",
      "133 campos\n",
      "21 canais\n",
      "126 canal\n",
      "28 canc\n",
      "33 cancel\n",
      "63 cancela\n",
      "415 cancelada\n",
      "64 canceladas\n",
      "436 cancelado\n",
      "71 cancelados\n",
      "1517 cancelamento\n",
      "49 cancelamentos\n",
      "24 cancelando\n",
      "555 cancelar\n",
      "10 cancele\n",
      "35 cancelou\n",
      "10 candida\n",
      "24 candido\n",
      "91 caracter\n",
      "8 caracteres\n",
      "40 caracteristicas\n",
      "7 caracterizando\n",
      "27 card\n",
      "85 cardoso\n",
      "72 carga\n",
      "8 cargas\n",
      "18 cargo\n",
      "15 carina\n",
      "8 carine\n",
      "48 carla\n",
      "160 carlos\n",
      "63 carmo\n",
      "38 carneiro\n",
      "38 carolina\n",
      "32 caroline\n",
      "198 caros\n",
      "37 carrega\n",
      "10 carregado\n",
      "20 carregados\n",
      "14 carregando\n",
      "13 carregar\n",
      "98 cart\n",
      "7 cartao\n",
      "78 carte\n",
      "143 carvalho\n",
      "7 cas\n",
      "53 casa\n",
      "7 casagrande\n",
      "20 cascavel\n",
      "35 case\n",
      "65 casella\n",
      "154 caso\n",
      "239 casos\n",
      "19 cassia\n",
      "9 cassio\n",
      "73 castro\n",
      "151 cat\n",
      "46 catarina\n",
      "12 categ\n",
      "537 categoria\n",
      "32 categoriza\n",
      "7 catfra\n",
      "8 catia\n",
      "10 catonx\n",
      "154 causa\n",
      "37 causando\n",
      "18 cavalcante\n",
      "9 cavalcanti\n",
      "19 cb\n",
      "122 cba\n",
      "29 cbb\n",
      "52 cbc\n",
      "175 cc\n",
      "8 cca\n",
      "1278 cco\n",
      "33 ccto\n",
      "64 cd\n",
      "117 cdi\n",
      "9 cdigatprdd\n",
      "11 cdipw\n",
      "73 cdr\n",
      "9 cdrinst\n",
      "112 cdrs\n",
      "115 ce\n",
      "12 ceara\n",
      "9 ceasing\n",
      "18 cecilia\n",
      "74 cel\n",
      "30 celia\n",
      "9 celio\n",
      "19 celso\n",
      "101 celular\n",
      "23 celulares\n",
      "79 cen\n",
      "10 cenario\n",
      "7 cennario\n",
      "45 center\n",
      "23 centrais\n",
      "102 central\n",
      "46 centro\n",
      "50 cep\n",
      "15 cerca\n",
      "12 cerqueira\n",
      "22 certo\n",
      "83 cesar\n",
      "19 cesta\n",
      "16 cezar\n",
      "84 cf\n",
      "81 cfg\n",
      "13 cg\n",
      "49 cga\n",
      "19 cgb\n",
      "167 cgc\n",
      "8 cgd\n",
      "10 cgds\n",
      "40 cge\n",
      "21 cgf\n",
      "15 cgo\n",
      "19 cgocs\n",
      "105 cgs\n",
      "77 ch\n",
      "23 cha\n",
      "57 chagas\n",
      "105 cham\n",
      "25 chama\n",
      "52 chamada\n",
      "100 chamadas\n",
      "399 chamado\n",
      "162 chamador\n",
      "23 chamados\n",
      "13 charlene\n",
      "25 charles\n",
      "103 chave\n",
      "31 chaves\n",
      "38 chega\n",
      "17 chegando\n",
      "48 chegar\n",
      "16 chegaram\n",
      "52 chegou\n",
      "14 chido\n",
      "72 chip\n",
      "20 chips\n",
      "8 chmd\n",
      "7 chn\n",
      "52 chrome\n",
      "69 cia\n",
      "14 cicero\n",
      "224 ciclo\n",
      "28 ciclos\n",
      "40 cidade\n",
      "32 cielo\n",
      "103 ciente\n",
      "8 cim\n",
      "14 cima\n",
      "8 cinco\n",
      "23 cinema\n",
      "11 cintia\n",
      "253 cio\n",
      "145 cios\n",
      "8 circ\n",
      "764 circuito\n",
      "184 circuitos\n",
      "8 circula\n",
      "10 citada\n",
      "18 citado\n",
      "13 citados\n",
      "27 citrix\n",
      "17 city\n",
      "7 civil\n",
      "32 cj\n",
      "17 cka\n",
      "8 ckz\n",
      "14 cl\n",
      "8 clarifay\n",
      "597 clarify\n",
      "82 claro\n",
      "118 classe\n",
      "8 classifica\n",
      "10 classificados\n",
      "57 claudia\n",
      "9 claudino\n",
      "57 claudio\n",
      "10 clck\n",
      "46 cld\n",
      "23 clean\n",
      "8 cleanup\n",
      "21 cleber\n",
      "14 cleide\n",
      "28 cleinte\n",
      "11 cleonice\n",
      "99 cli\n",
      "55 clica\n",
      "15 clicado\n",
      "15 clicamos\n",
      "7 clicando\n",
      "132 clicar\n",
      "1119 click\n",
      "60 clie\n",
      "17 client\n",
      "1063 cliente\n",
      "10 clienteoperacao\n",
      "654 clientes\n",
      "8 cliete\n",
      "15 clietne\n",
      "7 clinete\n",
      "17 clinica\n",
      "11 clinte\n",
      "12 clka\n",
      "43 clkb\n",
      "92 clke\n",
      "9 clkp\n",
      "8 cloud\n",
      "124 clt\n",
      "25 cly\n",
      "20 cm\n",
      "57 cmd\n",
      "14 cmf\n",
      "238 cmr\n",
      "105 cms\n",
      "34 cn\n",
      "10 cnf\n",
      "52 cnica\n",
      "129 cnico\n",
      "28 cnicos\n",
      "20 cnl\n",
      "556 cnpj\n",
      "7 cns\n",
      "148 co\n",
      "23 cob\n",
      "12 cober\n",
      "10 cobertura\n",
      "14 cobilling\n",
      "158 cobprd\n",
      "11 cobra\n",
      "54 cobrada\n",
      "26 cobradas\n",
      "259 cobrado\n",
      "22 cobrados\n",
      "332 cobran\n",
      "155 cobranca\n",
      "69 cobrando\n",
      "22 cobrar\n",
      "45 cobre\n",
      "8 cocorre\n",
      "166 cod\n",
      "7 code\n",
      "145 codigo\n",
      "8 codigos\n",
      "12 coelba\n",
      "65 coelho\n",
      "9 coimbra\n",
      "89 colaborador\n",
      "56 colaboradora\n",
      "37 colaboradores\n",
      "8 coleta\n",
      "8 coletar\n",
      "53 coloca\n",
      "36 colocada\n",
      "19 colocado\n",
      "15 colocamos\n",
      "28 colocando\n",
      "129 colocar\n",
      "8 colocou\n",
      "7 colombo\n",
      "32 coluna\n",
      "8 coma\n",
      "381 comando\n",
      "38 comandos\n",
      "14 combate\n",
      "7 combina\n",
      "30 combinado\n",
      "93 combo\n",
      "53 combos\n",
      "23 comcampoferta\n",
      "26 come\n",
      "37 coment\n",
      "91 comercial\n",
      "115 comercio\n",
      "16 comfra\n",
      "18 comissionadas\n",
      "46 comp\n",
      "15 companhia\n",
      "7 compartilhada\n",
      "8 compartilhado\n",
      "22 compartilhamento\n",
      "15 compat\n",
      "7 compativel\n",
      "12 complementar\n",
      "28 complemento\n",
      "7 complementos\n",
      "106 completa\n",
      "17 completada\n",
      "9 completado\n",
      "14 completar\n",
      "126 completo\n",
      "8 complexa\n",
      "37 component\n",
      "55 componente\n",
      "119 componentes\n",
      "26 composi\n",
      "10 compra\n",
      "31 comprobat\n",
      "23 comprova\n",
      "16 comprovando\n",
      "19 comprovante\n",
      "7 comprovantes\n",
      "9 computador\n",
      "16 comtemplados\n",
      "12 comum\n",
      "89 comunica\n",
      "14 comunicacao\n",
      "15 comunique\n",
      "15 comuta\n",
      "15 comverse\n",
      "26 con\n",
      "25 concede\n",
      "14 concedida\n",
      "56 concedido\n",
      "20 concei\n",
      "64 conceicao\n",
      "7 concentrador\n",
      "27 concess\n",
      "504 conclu\n",
      "22 concluam\n",
      "69 conclui\n",
      "68 concluida\n",
      "16 concluidas\n",
      "200 concluido\n",
      "18 concluidos\n",
      "12 concluindo\n",
      "540 concluir\n",
      "21 concluiu\n",
      "327 conclus\n",
      "22 conclusao\n",
      "11 cond\n",
      "104 condi\n",
      "68 condicao\n",
      "9 condicionada\n",
      "21 condominio\n",
      "12 cone\n",
      "35 conec\n",
      "10 conect\n",
      "389 conectado\n",
      "8 conector\n",
      "10 conex\n",
      "30 conf\n",
      "24 confeccoes\n",
      "9 confederacao\n",
      "33 confer\n",
      "7 conferem\n",
      "85 confian\n",
      "14 config\n",
      "181 configura\n",
      "10 configurada\n",
      "53 configurado\n",
      "138 configurador\n",
      "30 configurados\n",
      "221 configurar\n",
      "78 confira\n",
      "102 confirma\n",
      "23 confirmado\n",
      "9 confirmados\n",
      "36 confirmamos\n",
      "15 confirmando\n",
      "78 confirmar\n",
      "8 confirmou\n",
      "105 conflito\n",
      "8 confordercreated\n",
      "513 conforme\n",
      "107 conjunta\n",
      "12 conjunto\n",
      "84 connect\n",
      "29 conosco\n",
      "509 consegue\n",
      "112 conseguem\n",
      "64 consegui\n",
      "10 conseguia\n",
      "12 conseguido\n",
      "189 conseguimos\n",
      "330 conseguindo\n",
      "55 conseguir\n",
      "10 conseguiram\n",
      "12 conseguirmos\n",
      "47 conseguiu\n",
      "50 conseq\n",
      "41 consequ\n",
      "32 consequentemente\n",
      "7 considerar\n",
      "20 consiga\n",
      "71 consigo\n",
      "10 consolidado\n",
      "472 consta\n",
      "143 constam\n",
      "62 constando\n",
      "9 constantes\n",
      "22 constar\n",
      "17 constatado\n",
      "11 constatamos\n",
      "14 construcao\n",
      "11 construcoes\n",
      "15 construtora\n",
      "311 consulta\n",
      "20 consultado\n",
      "8 consultam\n",
      "26 consultamos\n",
      "54 consultando\n",
      "195 consultar\n",
      "12 consultas\n",
      "57 consultor\n",
      "11 consultora\n",
      "19 consultoria\n",
      "13 consumida\n",
      "12 consumido\n",
      "53 consumidor\n",
      "13 consumidora\n",
      "112 consumo\n",
      "205 cont\n",
      "685 conta\n",
      "31 contabilidade\n",
      "8 contabilizado\n",
      "19 contactar\n",
      "356 contas\n",
      "26 contatar\n",
      "1213 contato\n",
      "76 contatos\n",
      "21 contax\n",
      "10 conte\n",
      "7 contem\n",
      "13 contempla\n",
      "18 contemplado\n",
      "28 contendo\n",
      "14 contest\n",
      "223 contesta\n",
      "8 contestacoes\n",
      "52 contestada\n",
      "12 contestadas\n",
      "18 contestado\n",
      "12 contestar\n",
      "12 contidas\n",
      "53 conting\n",
      "12 contingencia\n",
      "17 contingencial\n",
      "373 continua\n",
      "64 continuam\n",
      "52 continuar\n",
      "9 continuarmos\n",
      "87 continuidade\n",
      "21 continuou\n",
      "30 contr\n",
      "29 contrata\n",
      "17 contratada\n",
      "15 contratado\n",
      "7 contratadooi\n",
      "8 contratados\n",
      "17 contratar\n",
      "675 contrato\n",
      "83 contratos\n",
      "60 contratou\n",
      "9 contratual\n",
      "16 contro\n",
      "44 control\n",
      "20 controlado\n",
      "494 controle\n",
      "795 controlm\n",
      "14 controlr\n",
      "9 conv\n",
      "99 convergente\n",
      "65 convergentes\n",
      "9 convers\n",
      "22 cooperativa\n",
      "12 cooperativas\n",
      "7 coordenador\n",
      "9 coordenadora\n",
      "30 cordeiro\n",
      "12 core\n",
      "19 corp\n",
      "36 corpo\n",
      "13 corporativa\n",
      "65 corporativo\n",
      "8 corrde\n",
      "336 corre\n",
      "56 correa\n",
      "13 correcao\n",
      "47 correia\n",
      "16 correios\n",
      "39 corrente\n",
      "15 correspond\n",
      "15 corresponde\n",
      "23 correspondente\n",
      "57 correspondentes\n",
      "87 correta\n",
      "144 corretamente\n",
      "18 corretas\n",
      "164 correto\n",
      "22 corretora\n",
      "94 corretos\n",
      "15 corridos\n",
      "14 corrigi\n",
      "11 corrigida\n",
      "37 corrigido\n",
      "294 corrigir\n",
      "8 corrijam\n",
      "58 corte\n",
      "8 cortes\n",
      "16 cortip\n",
      "176 costa\n",
      "21 coutinho\n",
      "15 couto\n",
      "14 cp\n",
      "17 cpa\n",
      "10 cpct\n",
      "214 cpe\n",
      "7 cpecom\n",
      "529 cpf\n",
      "42 cpfcnpj\n",
      "13 cpfs\n",
      "8 cpnj\n",
      "12 cps\n",
      "831 cr\n",
      "10 cracp\n",
      "8 creditado\n",
      "75 credito\n",
      "28 creditos\n",
      "29 crescente\n",
      "343 cria\n",
      "18 criacao\n",
      "28 criada\n",
      "10 criadas\n",
      "57 criado\n",
      "14 criados\n",
      "75 criar\n",
      "24 criem\n",
      "17 criou\n",
      "46 cristiane\n",
      "23 cristiano\n",
      "114 cristina\n",
      "13 crit\n",
      "917 critica\n",
      "51 criticada\n",
      "10 criticadas\n",
      "16 criticado\n",
      "27 criticados\n",
      "14 criticando\n",
      "14 criticas\n",
      "10 crjd\n",
      "854 crm\n",
      "19 crmbat\n",
      "8 crmcriatabela\n",
      "21 crmextrator\n",
      "11 crmmktgtwd\n",
      "55 crmoibatd\n",
      "20 crmoiftp\n",
      "7 crmpub\n",
      "21 crmpubsp\n",
      "21 crmshl\n",
      "7 crmshlinadeim\n",
      "82 crmshlsp\n",
      "9 crmshpsp\n",
      "21 crmsp\n",
      "29 cronol\n",
      "24 crtd\n",
      "71 cruz\n",
      "53 crv\n",
      "8 cs\n",
      "17 csp\n",
      "10 ct\n",
      "159 cta\n",
      "1582 ctm\n",
      "278 cto\n",
      "16 ctr\n",
      "80 ctrl\n",
      "138 ctt\n",
      "19 ctxsalpb\n",
      "32 cujo\n",
      "24 cula\n",
      "37 culas\n",
      "12 cumprimento\n",
      "71 cunha\n",
      "22 curitiba\n",
      "10 cust\n",
      "21 customer\n",
      "9 cvp\n",
      "19 cx\n",
      "79 dacc\n",
      "31 dad\n",
      "18 dada\n",
      "53 dado\n",
      "487 dados\n",
      "15 daiane\n",
      "135 daily\n",
      "8 dal\n",
      "10 dalva\n",
      "16 damasceno\n",
      "109 dando\n",
      "23 dani\n",
      "60 daniel\n",
      "135 daniela\n",
      "26 daniele\n",
      "10 danielle\n",
      "25 danilo\n",
      "18 dantas\n",
      "12 danubia\n",
      "178 dar\n",
      "24 darmos\n",
      "281 data\n",
      "23 dataquality\n",
      "27 datas\n",
      "11 date\n",
      "53 david\n",
      "10 dayane\n",
      "9 dc\n",
      "22 dd\n",
      "182 ddd\n",
      "9 ddi\n",
      "80 ddr\n",
      "8 debitado\n",
      "123 debito\n",
      "53 debitos\n",
      "28 debora\n",
      "16 dec\n",
      "7 declara\n",
      "24 decurso\n",
      "37 dedicado\n",
      "13 defeito\n",
      "16 defini\n",
      "9 definido\n",
      "28 definitiva\n",
      "9 definitivamente\n",
      "10 definitivo\n",
      "8 degrada\n",
      "11 deise\n",
      "117 deixa\n",
      "36 deixam\n",
      "109 deixando\n",
      "53 deixar\n",
      "11 deixou\n",
      "164 demais\n",
      "74 demanda\n",
      "10 demandante\n",
      "27 demandas\n",
      "13 demilson\n",
      "7 demonstra\n",
      "15 demonstrado\n",
      "21 demora\n",
      "12 demorando\n",
      "9 denilson\n",
      "26 denise\n",
      "180 dentro\n",
      "8 dep\n",
      "9 departamento\n",
      "199 dependente\n",
      "42 dependentes\n",
      "8 depositada\n",
      "11 deposito\n",
      "28 der\n",
      "14 deriva\n",
      "10 des\n",
      "80 desab\n",
      "13 desabilita\n",
      "13 desabilitada\n",
      "68 desabilitado\n",
      "17 desassocia\n",
      "21 desassociado\n",
      "73 desassociar\n",
      "108 desativa\n",
      "11 desativaacesso\n",
      "53 desativada\n",
      "104 desativado\n",
      "101 desativar\n",
      "7 desatribu\n",
      "24 desatualizado\n",
      "9 desatualizados\n",
      "18 desbloqueado\n",
      "30 desbloqueados\n",
      "60 desbloquear\n",
      "13 desbloqueiem\n",
      "289 desbloqueio\n",
      "13 desbloqueou\n",
      "130 desc\n",
      "13 desconectada\n",
      "92 desconex\n",
      "19 desconfigurar\n",
      "19 desconhece\n",
      "166 desconto\n",
      "34 descontos\n",
      "10 descreve\n",
      "227 descrever\n",
      "185 descri\n",
      "12 descric\n",
      "36 descricao\n",
      "8 descrita\n",
      "26 descrito\n",
      "543 desde\n",
      "287 deseja\n",
      "86 desejada\n",
      "17 desejado\n",
      "15 desenvolvimento\n",
      "16 desfazer\n",
      "86 designa\n",
      "22 designada\n",
      "44 designado\n",
      "179 designar\n",
      "14 desinstalar\n",
      "8 desist\n",
      "75 desistente\n",
      "42 desistiu\n",
      "56 desk\n",
      "13 desmembrada\n",
      "18 desmembrado\n",
      "181 desmembramento\n",
      "137 desmembrar\n",
      "19 desmembrou\n",
      "10 desmenbrar\n",
      "12 desmigra\n",
      "60 desmigrar\n",
      "41 desnecess\n",
      "14 despacho\n",
      "10 destaque\n",
      "8 destinat\n",
      "7 destinatario\n",
      "20 destino\n",
      "13 desvincula\n",
      "8 desvinculada\n",
      "30 desvinculado\n",
      "56 desvincular\n",
      "16 det\n",
      "22 detalha\n",
      "135 detalhada\n",
      "260 detalhadamente\n",
      "9 detalhadas\n",
      "14 detalhado\n",
      "105 detalhamento\n",
      "40 detalhar\n",
      "64 detalhe\n",
      "44 detalhes\n",
      "85 detectados\n",
      "28 determina\n",
      "14 determinado\n",
      "74 deu\n",
      "22 deve\n",
      "11 dever\n",
      "26 devida\n",
      "61 devidamente\n",
      "32 devidas\n",
      "262 devido\n",
      "8 devidos\n",
      "16 devolu\n",
      "58 devolvida\n",
      "9 devolvido\n",
      "15 dez\n",
      "50 dezembro\n",
      "310 df\n",
      "38 dg\n",
      "115 di\n",
      "552 dia\n",
      "8 diana\n",
      "51 diante\n",
      "144 diaria\n",
      "17 diariamente\n",
      "49 diario\n",
      "273 dias\n",
      "17 diasnatarefa\n",
      "7 dica\n",
      "13 dico\n",
      "43 diego\n",
      "11 diferen\n",
      "126 diferente\n",
      "55 diferentes\n",
      "261 dificuldade\n",
      "57 dificuldades\n",
      "11 dig\n",
      "30 digita\n",
      "27 digitado\n",
      "17 digitais\n",
      "260 digital\n",
      "78 digitar\n",
      "22 digito\n",
      "26 digitronco\n",
      "222 digo\n",
      "31 digos\n",
      "23 diniz\n",
      "9 dio\n",
      "15 diogo\n",
      "29 dir\n",
      "8 direciona\n",
      "18 direcionada\n",
      "40 direcionado\n",
      "9 direcionamento\n",
      "10 direcionar\n",
      "40 direito\n",
      "12 diret\n",
      "20 diretamente\n",
      "35 direto\n",
      "9 diretoria\n",
      "8 diretorio\n",
      "180 dispon\n",
      "90 disponibilidade\n",
      "106 disponibiliza\n",
      "26 disponibilizada\n",
      "31 disponibilizadas\n",
      "55 disponibilizado\n",
      "26 disponibilizados\n",
      "17 disponibilizando\n",
      "43 disponibilizar\n",
      "16 disponiveis\n",
      "112 disponivel\n",
      "22 disputa\n",
      "39 dissocia\n",
      "9 dissociar\n",
      "13 dist\n",
      "15 distancia\n",
      "11 distribuicao\n",
      "28 distribuidora\n",
      "91 dito\n",
      "25 ditos\n",
      "165 diverg\n",
      "88 divergencia\n",
      "77 divergente\n",
      "33 divergentes\n",
      "25 diversas\n",
      "71 diversos\n",
      "11 divina\n",
      "9 divis\n",
      "30 dizendo\n",
      "220 dk\n",
      "26 dm\n",
      "154 dn\n",
      "91 dnc\n",
      "23 doa\n",
      "30 doado\n",
      "302 doadora\n",
      "8 dobro\n",
      "236 doc\n",
      "41 documento\n",
      "8 documentoassociado\n",
      "10 docx\n",
      "119 dois\n",
      "62 dom\n",
      "25 domingos\n",
      "15 domingues\n",
      "26 dominio\n",
      "13 dores\n",
      "25 douglas\n",
      "9 dourado\n",
      "67 downgrade\n",
      "102 dp\n",
      "7 dqdbap\n",
      "18 dqx\n",
      "8 ds\n",
      "60 dsa\n",
      "7 dslam\n",
      "59 dsnames\n",
      "104 dt\n",
      "12 dta\n",
      "104 dth\n",
      "47 duarte\n",
      "119 duas\n",
      "9 dulce\n",
      "9 dulo\n",
      "20 dup\n",
      "23 dupl\n",
      "16 duplicada\n",
      "11 duplicadas\n",
      "32 duplicado\n",
      "63 duplicados\n",
      "125 duplicidade\n",
      "83 durante\n",
      "17 dutra\n",
      "43 duvidas\n",
      "31 dvr\n",
      "34 dw\n",
      "20 ea\n",
      "568 eai\n",
      "19 ebilling\n",
      "10 economica\n",
      "9 ed\n",
      "16 eder\n",
      "18 edificio\n",
      "11 edilson\n",
      "7 editar\n",
      "10 edmilson\n",
      "18 edna\n",
      "20 edson\n",
      "9 eduarda\n",
      "90 eduardo\n",
      "20 educa\n",
      "12 educacao\n",
      "15 efetiva\n",
      "13 efetivar\n",
      "26 efetivo\n",
      "23 efetua\n",
      "50 efetuada\n",
      "10 efetuadas\n",
      "53 efetuado\n",
      "20 efetuamos\n",
      "53 efetuando\n",
      "303 efetuar\n",
      "7 efetuei\n",
      "30 efetuem\n",
      "122 efetuou\n",
      "11 eh\n",
      "16 eild\n",
      "25 eireli\n",
      "14 el\n",
      "21 elaine\n",
      "67 eleg\n",
      "9 elegibilidade\n",
      "83 elemento\n",
      "111 elementos\n",
      "10 eliana\n",
      "30 eliane\n",
      "32 elias\n",
      "12 elizabete\n",
      "21 elizabeth\n",
      "8 ellen\n",
      "7 eloize\n",
      "7 elton\n",
      "9 elvira\n",
      "14 elza\n",
      "11 ema\n",
      "281 email\n",
      "9 embalagens\n",
      "16 embora\n",
      "84 embratel\n",
      "18 emerson\n",
      "47 emiss\n",
      "31 emissao\n",
      "14 emitida\n",
      "7 emitidas\n",
      "8 emitido\n",
      "50 emitir\n",
      "23 emp\n",
      "12 empacotamento\n",
      "13 empreendimentos\n",
      "180 empresa\n",
      "7 empresariais\n",
      "72 empresarial\n",
      "14 empresas\n",
      "9 en\n",
      "17 enc\n",
      "17 encaminhada\n",
      "9 encaminhadas\n",
      "40 encaminhado\n",
      "13 encaminhados\n",
      "21 encaminhamento\n",
      "8 encaminhando\n",
      "54 encaminhar\n",
      "9 encaminhou\n",
      "46 encerra\n",
      "301 encerrada\n",
      "46 encerradas\n",
      "469 encerrado\n",
      "76 encerrados\n",
      "41 encerram\n",
      "492 encerramento\n",
      "11 encerrando\n",
      "613 encerrar\n",
      "16 encerre\n",
      "16 encerrou\n",
      "560 encontra\n",
      "83 encontrada\n",
      "10 encontradas\n",
      "207 encontrado\n",
      "22 encontrados\n",
      "273 encontram\n",
      "37 encontramos\n",
      "29 encontrar\n",
      "9 encontrasse\n",
      "11 encontravam\n",
      "94 end\n",
      "492 endere\n",
      "10 endereco\n",
      "8 eng\n",
      "38 engenharia\n",
      "11 engenheiros\n",
      "21 enriquecendo\n",
      "41 enriquecer\n",
      "11 enriquecido\n",
      "50 enriquecidos\n",
      "14 enriquecimento\n",
      "42 ent\n",
      "88 entanto\n",
      "42 entemente\n",
      "40 entender\n",
      "120 enter\n",
      "92 entra\n",
      "90 entrada\n",
      "8 entrando\n",
      "214 entrar\n",
      "10 entraram\n",
      "13 entrega\n",
      "481 entregue\n",
      "122 entretanto\n",
      "8 entro\n",
      "420 entrou\n",
      "21 entry\n",
      "9 env\n",
      "32 envia\n",
      "324 enviada\n",
      "17 enviadas\n",
      "80 enviado\n",
      "28 enviados\n",
      "56 enviamos\n",
      "39 enviando\n",
      "211 enviar\n",
      "199 envio\n",
      "19 enviou\n",
      "11 envolvido\n",
      "21 envolvidos\n",
      "7 eo\n",
      "65 eot\n",
      "93 epp\n",
      "122 eqn\n",
      "14 equipamento\n",
      "32 equipamentos\n",
      "91 equipe\n",
      "8 er\n",
      "13 erica\n",
      "8 erick\n",
      "10 erika\n",
      "7 ernesto\n",
      "11 ero\n",
      "89 err\n",
      "33 errada\n",
      "62 errado\n",
      "13 errados\n",
      "828 erro\n",
      "7 errocriandoosoms\n",
      "20 erroneamente\n",
      "22 error\n",
      "153 erros\n",
      "1301 es\n",
      "11 esb\n",
      "42 escolha\n",
      "7 escolhe\n",
      "18 escolher\n",
      "8 escolhida\n",
      "11 escopo\n",
      "10 escrito\n",
      "25 esp\n",
      "10 espa\n",
      "28 espec\n",
      "26 especiais\n",
      "76 especial\n",
      "8 especialista\n",
      "9 especificada\n",
      "18 especificado\n",
      "21 especifico\n",
      "7 especificos\n",
      "7 espelhado\n",
      "8 espelhamento\n",
      "14 espelhar\n",
      "315 espelho\n",
      "40 espera\n",
      "16 esperado\n",
      "14 espirito\n",
      "29 esqueceu\n",
      "8 esqueci\n",
      "41 est\n",
      "73 estacao\n",
      "8 estacoes\n",
      "149 estado\n",
      "8 estados\n",
      "42 estadual\n",
      "1211 estah\n",
      "8 estam\n",
      "68 estando\n",
      "95 estao\n",
      "159 estar\n",
      "26 estarem\n",
      "7 estatus\n",
      "7 estela\n",
      "7 ester\n",
      "29 estimado\n",
      "8 estoque\n",
      "12 estornado\n",
      "42 estorno\n",
      "25 estourado\n",
      "17 estudo\n",
      "38 etapa\n",
      "11 etapas\n",
      "61 etc\n",
      "9 eth\n",
      "9 etiquetas\n",
      "8 etx\n",
      "11 eunice\n",
      "12 eustaquio\n",
      "14 ev\n",
      "16 eva\n",
      "14 evandro\n",
      "16 evangelista\n",
      "156 evento\n",
      "186 eventos\n",
      "14 eventual\n",
      "9 everton\n",
      "1245 evid\n",
      "433 evidencia\n",
      "17 evidenciada\n",
      "206 evidenciado\n",
      "476 evidencias\n",
      "59 evitar\n",
      "8 evolu\n",
      "50 ex\n",
      "7 exatamente\n",
      "8 exce\n",
      "12 excedente\n",
      "20 excedentes\n",
      "7 excedido\n",
      "13 excel\n",
      "25 exceto\n",
      "53 exclu\n",
      "16 excluido\n",
      "71 excluir\n",
      "50 exclus\n",
      "16 exclusao\n",
      "201 exclusiva\n",
      "8 exclusivo\n",
      "52 exec\n",
      "224 execu\n",
      "209 execucao\n",
      "26 executa\n",
      "148 executada\n",
      "19 executadas\n",
      "99 executado\n",
      "9 executados\n",
      "230 executando\n",
      "262 executar\n",
      "91 exemplo\n",
      "88 exemplos\n",
      "29 exibe\n",
      "16 exibida\n",
      "29 exibido\n",
      "9 exibir\n",
      "7 exige\n",
      "10 exigida\n",
      "32 exist\n",
      "335 existe\n",
      "127 existem\n",
      "74 existente\n",
      "13 existentes\n",
      "8 existia\n",
      "7 exists\n",
      "7 exito\n",
      "216 expediter\n",
      "97 expert\n",
      "8 expira\n",
      "13 expirada\n",
      "30 expirado\n",
      "9 expirados\n",
      "16 expirou\n",
      "21 explica\n",
      "11 explicar\n",
      "62 explorer\n",
      "7 exportacao\n",
      "32 exposta\n",
      "33 exposto\n",
      "125 ext\n",
      "23 externa\n",
      "37 external\n",
      "24 externo\n",
      "57 extra\n",
      "35 extracao\n",
      "20 extrai\n",
      "9 extrair\n",
      "30 extrator\n",
      "7 extratos\n",
      "28 fa\n",
      "36 fabiana\n",
      "10 fabiane\n",
      "21 fabiano\n",
      "73 fabio\n",
      "14 fabrica\n",
      "19 fabricio\n",
      "21 fac\n",
      "31 fachada\n",
      "240 facilidade\n",
      "117 facilidades\n",
      "11 fagundes\n",
      "75 faixa\n",
      "9 fala\n",
      "10 falamos\n",
      "22 falar\n",
      "43 fale\n",
      "412 falha\n",
      "27 falhas\n",
      "73 falta\n",
      "23 faltando\n",
      "10 faltantes\n",
      "188 fam\n",
      "180 familia\n",
      "36 faria\n",
      "35 farias\n",
      "7 farmacia\n",
      "7 fase\n",
      "43 fast\n",
      "12 fastfu\n",
      "9 fastvb\n",
      "44 fastve\n",
      "88 fat\n",
      "71 fatima\n",
      "29 fato\n",
      "436 fatura\n",
      "10 faturadas\n",
      "57 faturado\n",
      "15 faturados\n",
      "319 faturamento\n",
      "13 faturamentos\n",
      "81 faturando\n",
      "25 faturar\n",
      "371 faturas\n",
      "13 faturou\n",
      "15 favo\n",
      "1278 favor\n",
      "80 faz\n",
      "18 fazem\n",
      "43 fazemos\n",
      "7 fazia\n",
      "10 fbb\n",
      "20 fbltv\n",
      "8 fc\n",
      "43 fd\n",
      "11 feb\n",
      "18 febraban\n",
      "25 fecha\n",
      "178 fechada\n",
      "64 fechadas\n",
      "560 fechado\n",
      "128 fechados\n",
      "755 fechamento\n",
      "12 fechamos\n",
      "10 fechando\n",
      "267 fechar\n",
      "22 fechou\n",
      "10 federacao\n",
      "62 federal\n",
      "37 fego\n",
      "7 feijo\n",
      "10 feira\n",
      "12 feitosa\n",
      "8 felicio\n",
      "71 felipe\n",
      "21 felix\n",
      "25 fen\n",
      "67 fernanda\n",
      "98 fernandes\n",
      "108 fernando\n",
      "216 ferramenta\n",
      "12 ferramentas\n",
      "8 ferrari\n",
      "11 ferraz\n",
      "202 ferreira\n",
      "12 fev\n",
      "101 fevereiro\n",
      "115 fez\n",
      "12 ff\n",
      "11 fhynbeen\n",
      "10 fi\n",
      "8 fialho\n",
      "1268 fibra\n",
      "194 fica\n",
      "26 ficam\n",
      "87 ficando\n",
      "40 ficar\n",
      "15 ficaram\n",
      "63 ficha\n",
      "64 fico\n",
      "9 ficos\n",
      "224 ficou\n",
      "86 fict\n",
      "48 ficticio\n",
      "444 fid\n",
      "13 fidel\n",
      "10 fidelidade\n",
      "13 fideliza\n",
      "8 figueira\n",
      "46 figueiredo\n",
      "337 fila\n",
      "22 filas\n",
      "28 file\n",
      "85 filho\n",
      "29 filiais\n",
      "141 filial\n",
      "73 fim\n",
      "15 finais\n",
      "134 final\n",
      "135 finaliza\n",
      "42 finalizada\n",
      "10 finalizadas\n",
      "150 finalizado\n",
      "8 finalizando\n",
      "175 finalizar\n",
      "40 financeira\n",
      "125 financeiro\n",
      "52 fique\n",
      "20 fiquem\n",
      "12 firefox\n",
      "11 fiscais\n",
      "45 fiscal\n",
      "19 fisica\n",
      "74 fisico\n",
      "35 fix\n",
      "284 fixa\n",
      "14 fixas\n",
      "2339 fixo\n",
      "17 fixos\n",
      "17 fiz\n",
      "25 fizemos\n",
      "13 fizeram\n",
      "7 fj\n",
      "49 fla\n",
      "170 flag\n",
      "61 flat\n",
      "26 flavia\n",
      "36 flavio\n",
      "8 fleg\n",
      "11 flegue\n",
      "17 flex\n",
      "18 flg\n",
      "29 flores\n",
      "70 fluxo\n",
      "16 fm\n",
      "13 fnb\n",
      "166 fns\n",
      "8 fo\n",
      "9 focal\n",
      "125 fone\n",
      "54 fonseca\n",
      "7 fonte\n",
      "17 fontes\n",
      "193 forma\n",
      "10 forms\n",
      "17 fortaleza\n",
      "9 fortuna\n",
      "7 foto\n",
      "8 fotogr\n",
      "16 found\n",
      "7 foz\n",
      "67 fr\n",
      "25 fraga\n",
      "15 frame\n",
      "21 franca\n",
      "7 franciele\n",
      "47 francisca\n",
      "101 francisco\n",
      "33 franco\n",
      "379 franquia\n",
      "24 franquias\n",
      "109 fraude\n",
      "13 frederico\n",
      "18 freire\n",
      "101 freitas\n",
      "43 frqvc\n",
      "7 fsa\n",
      "34 ft\n",
      "21 ftp\n",
      "21 ftv\n",
      "17 full\n",
      "22 fun\n",
      "19 funciona\n",
      "40 funcional\n",
      "37 funcionalidade\n",
      "7 funcionalidades\n",
      "18 funcionamento\n",
      "55 funcionando\n",
      "15 funcionar\n",
      "13 funcionou\n",
      "13 fundacao\n",
      "11 fundo\n",
      "11 furtado\n",
      "11 futuras\n",
      "10 futuro\n",
      "18 fv\n",
      "36 fvr\n",
      "7 fw\n",
      "7 fx\n",
      "39 ga\n",
      "789 gaap\n",
      "31 gabriel\n",
      "20 gabriela\n",
      "8 galdino\n",
      "10 galvao\n",
      "14 gama\n",
      "85 garantir\n",
      "43 garcia\n",
      "11 garimpo\n",
      "11 gas\n",
      "319 gb\n",
      "61 gcob\n",
      "336 gde\n",
      "30 gdes\n",
      "9 ge\n",
      "39 geco\n",
      "21 ged\n",
      "25 gen\n",
      "8 generico\n",
      "18 geneva\n",
      "292 gentileza\n",
      "37 ger\n",
      "359 gera\n",
      "23 geracao\n",
      "185 gerada\n",
      "63 geradas\n",
      "260 gerado\n",
      "42 gerados\n",
      "23 gerais\n",
      "27 geral\n",
      "35 geraldo\n",
      "11 geralmente\n",
      "7 geramos\n",
      "268 gerando\n",
      "442 gerar\n",
      "22 geraram\n",
      "10 gere\n",
      "28 gerei\n",
      "16 gerencia\n",
      "14 gerenciamento\n",
      "28 gerenciar\n",
      "27 gerente\n",
      "8 gero\n",
      "402 gerou\n",
      "8 gerson\n",
      "20 gest\n",
      "90 gestor\n",
      "12 getnet\n",
      "10 gf\n",
      "131 gfr\n",
      "11 gi\n",
      "30 gica\n",
      "7 gid\n",
      "24 gilberto\n",
      "12 gilmar\n",
      "19 gilson\n",
      "35 gina\n",
      "7 gio\n",
      "14 gisele\n",
      "21 gl\n",
      "15 global\n",
      "14 globalweb\n",
      "11 globo\n",
      "10 gloria\n",
      "160 gmail\n",
      "16 gmud\n",
      "216 gna\n",
      "371 go\n",
      "8 goes\n",
      "8 goi\n",
      "7 goiania\n",
      "12 goias\n",
      "132 gomes\n",
      "27 gon\n",
      "128 goncalves\n",
      "7 gontijo\n",
      "7 gonzaga\n",
      "27 google\n",
      "48 gostaria\n",
      "10 goulart\n",
      "10 gov\n",
      "9 governo\n",
      "100 gpon\n",
      "8 gpp\n",
      "29 gprs\n",
      "38 gr\n",
      "62 gra\n",
      "29 gracas\n",
      "22 grade\n",
      "11 grafico\n",
      "49 granite\n",
      "180 grata\n",
      "160 grato\n",
      "14 gratuito\n",
      "17 grava\n",
      "13 graziela\n",
      "23 grosso\n",
      "802 group\n",
      "8 grta\n",
      "46 grupo\n",
      "18 gse\n",
      "34 gsm\n",
      "22 gt\n",
      "10 gtf\n",
      "7 gti\n",
      "10 gua\n",
      "16 guedes\n",
      "8 guerra\n",
      "39 guia\n",
      "38 guilherme\n",
      "7 guimar\n",
      "59 guimaraes\n",
      "45 gustavo\n",
      "45 gvt\n",
      "1237 ha\n",
      "130 habilita\n",
      "23 habilitada\n",
      "67 habilitado\n",
      "69 habilitar\n",
      "7 hamilton\n",
      "8 haroldo\n",
      "19 havendo\n",
      "44 haver\n",
      "23 havia\n",
      "21 hb\n",
      "78 hd\n",
      "83 hdca\n",
      "14 hdcbj\n",
      "14 hdck\n",
      "71 helena\n",
      "14 helio\n",
      "32 help\n",
      "102 henrique\n",
      "7 hffd\n",
      "14 hibrido\n",
      "15 hierarquia\n",
      "179 hist\n",
      "19 histo\n",
      "50 historico\n",
      "7 hl\n",
      "77 hlr\n",
      "16 hlrbsi\n",
      "11 hoa\n",
      "21 hob\n",
      "61 hoje\n",
      "7 hollanda\n",
      "13 home\n",
      "45 hor\n",
      "158 hora\n",
      "12 horario\n",
      "405 horas\n",
      "17 horasnatarefa\n",
      "41 horizonte\n",
      "32 hot\n",
      "7 hotel\n",
      "88 hotline\n",
      "137 hotmail\n",
      "48 hrs\n",
      "107 hs\n",
      "68 htcd\n",
      "9 htce\n",
      "448 http\n",
      "7 https\n",
      "10 hugo\n",
      "11 humberto\n",
      "88 ia\n",
      "8 iai\n",
      "29 ib\n",
      "201 ic\n",
      "18 iccid\n",
      "8 icms\n",
      "443 ics\n",
      "7 icsldrparc\n",
      "402 id\n",
      "49 iddaordem\n",
      "45 ident\n",
      "20 identifica\n",
      "15 identificada\n",
      "157 identificado\n",
      "63 identificador\n",
      "13 identificados\n",
      "72 identificamos\n",
      "13 identificando\n",
      "153 identificar\n",
      "10 identificou\n",
      "10 identifiquei\n",
      "12 idpositivo\n",
      "12 ids\n",
      "68 ie\n",
      "7 ieda\n",
      "13 if\n",
      "10 iffd\n",
      "11 ig\n",
      "8 ignorando\n",
      "14 igor\n",
      "7 iguais\n",
      "85 igual\n",
      "9 ih\n",
      "9 ii\n",
      "7 iig\n",
      "31 ijb\n",
      "18 il\n",
      "15 ilha\n",
      "14 ilim\n",
      "11 ilimitada\n",
      "11 ilimitadas\n",
      "54 ilimitado\n",
      "18 ilimitados\n",
      "16 imagem\n",
      "49 imagens\n",
      "35 imediatamente\n",
      "14 imediato\n",
      "9 imei\n",
      "8 imeis\n",
      "8 imobiliarios\n",
      "8 imoveis\n",
      "55 imp\n",
      "20 impacta\n",
      "16 impactada\n",
      "10 impactadas\n",
      "12 impactado\n",
      "21 impactados\n",
      "119 impactando\n",
      "46 impacto\n",
      "12 impe\n",
      "113 impede\n",
      "12 impedi\n",
      "64 impedida\n",
      "10 impedidas\n",
      "28 impedido\n",
      "80 impedimento\n",
      "272 impedindo\n",
      "7 impedir\n",
      "20 impeditivo\n",
      "11 impendindo\n",
      "12 implanta\n",
      "65 implantar\n",
      "11 importacao\n",
      "18 impossibilidade\n",
      "50 impossibilita\n",
      "30 impossibilitado\n",
      "274 impossibilitando\n",
      "7 impossibilitanto\n",
      "10 imposto\n",
      "13 impress\n",
      "26 imprimir\n",
      "12 improcedente\n",
      "15 imput\n",
      "8 imputar\n",
      "57 imsi\n",
      "107 in\n",
      "14 inacio\n",
      "122 inadimpl\n",
      "36 inadimplencia\n",
      "27 inadimplente\n",
      "16 inadiplencia\n",
      "127 inativa\n",
      "13 inativacao\n",
      "29 inativado\n",
      "17 inativados\n",
      "90 inativar\n",
      "33 inativas\n",
      "199 inativo\n",
      "57 inativos\n",
      "32 inativou\n",
      "167 incentiva\n",
      "93 incidente\n",
      "51 inclu\n",
      "12 inclua\n",
      "20 inclui\n",
      "10 incluido\n",
      "12 incluindo\n",
      "197 incluir\n",
      "168 inclus\n",
      "18 inclusa\n",
      "14 inclusao\n",
      "14 inclusas\n",
      "17 inclusive\n",
      "35 incluso\n",
      "31 inclusos\n",
      "80 incompat\n",
      "23 incompatibilidade\n",
      "54 incompativel\n",
      "79 inconsist\n",
      "13 inconsistencia\n",
      "33 inconsistente\n",
      "20 inconsistentes\n",
      "36 incorreta\n",
      "18 incorretamente\n",
      "85 incorreto\n",
      "111 incorretos\n",
      "43 ind\n",
      "14 independente\n",
      "13 indeterminado\n",
      "122 indevida\n",
      "209 indevidamente\n",
      "49 indevidas\n",
      "125 indevido\n",
      "16 indevidos\n",
      "28 indica\n",
      "8 indicado\n",
      "16 indicador\n",
      "10 indicadores\n",
      "122 indispon\n",
      "26 indisponibilidade\n",
      "76 indisponivel\n",
      "13 individual\n",
      "20 indo\n",
      "55 industria\n",
      "13 ines\n",
      "9 inesistente\n",
      "23 inesperado\n",
      "223 inexistente\n",
      "33 inexistentes\n",
      "19 inf\n",
      "28 inferior\n",
      "23 infnc\n",
      "13 info\n",
      "7 infoma\n",
      "8 inform\n",
      "2166 informa\n",
      "35 informacoes\n",
      "94 informada\n",
      "14 informadas\n",
      "403 informado\n",
      "46 informados\n",
      "444 informando\n",
      "166 informar\n",
      "13 informaram\n",
      "57 informatica\n",
      "112 informe\n",
      "14 informo\n",
      "255 informou\n",
      "7 ingl\n",
      "9 ingrid\n",
      "13 inibi\n",
      "7 inibidas\n",
      "60 inibidos\n",
      "11 inibir\n",
      "25 iniciada\n",
      "12 iniciais\n",
      "128 inicial\n",
      "24 iniciar\n",
      "42 inicio\n",
      "17 iniciodatarefa\n",
      "18 input\n",
      "87 ins\n",
      "153 insadsl\n",
      "7 insagrrw\n",
      "16 insantvir\n",
      "11 insapoio\n",
      "10 insatisfeito\n",
      "7 insblo\n",
      "10 inscirc\n",
      "20 inscomod\n",
      "10 inscorins\n",
      "28 inscpe\n",
      "7 inscpecov\n",
      "34 inser\n",
      "14 insere\n",
      "13 inserida\n",
      "8 inseridas\n",
      "105 inserido\n",
      "17 inseridos\n",
      "176 inserir\n",
      "19 insfastfu\n",
      "339 insfastve\n",
      "8 inshabf\n",
      "8 insinet\n",
      "17 insmodcli\n",
      "16 insnfilim\n",
      "16 insnfm\n",
      "74 insoitot\n",
      "17 inspcte\n",
      "74 insplano\n",
      "16 inspor\n",
      "404 inst\n",
      "14 insta\n",
      "17 instal\n",
      "552 instala\n",
      "210 instalacao\n",
      "109 instalada\n",
      "17 instaladas\n",
      "288 instalado\n",
      "58 instalados\n",
      "285 instalar\n",
      "7 instalou\n",
      "28 instance\n",
      "61 instancia\n",
      "124 instancias\n",
      "14 instituto\n",
      "8 insva\n",
      "85 int\n",
      "48 intcel\n",
      "542 integra\n",
      "8 integradas\n",
      "11 integrado\n",
      "10 integral\n",
      "24 intelig\n",
      "8 intenret\n",
      "42 inter\n",
      "14 intera\n",
      "18 intercepta\n",
      "13 interesse\n",
      "576 interface\n",
      "7 interfacear\n",
      "22 interfaces\n",
      "12 interfacesbcv\n",
      "12 interm\n",
      "43 intermedi\n",
      "54 intermediario\n",
      "11 intermitente\n",
      "35 interna\n",
      "32 internacionais\n",
      "31 internacional\n",
      "9 internaliza\n",
      "9 internalizados\n",
      "247 internet\n",
      "42 interno\n",
      "21 interopera\n",
      "11 interrompida\n",
      "27 interven\n",
      "21 intragrupo\n",
      "9 intranet\n",
      "18 intrarrede\n",
      "286 inv\n",
      "20 inva\n",
      "8 inval\n",
      "88 invalida\n",
      "181 invalido\n",
      "67 invalidos\n",
      "81 investiga\n",
      "39 investigado\n",
      "194 investigar\n",
      "126 investigativa\n",
      "9 investigue\n",
      "20 inviabilidade\n",
      "7 iolanda\n",
      "9 ione\n",
      "101 ip\n",
      "11 ipc\n",
      "93 iptv\n",
      "64 ir\n",
      "14 ira\n",
      "13 iracema\n",
      "9 iremos\n",
      "10 irene\n",
      "7 iria\n",
      "11 irla\n",
      "39 is\n",
      "20 isabel\n",
      "8 isabela\n",
      "44 isen\n",
      "7 isenta\n",
      "21 isentar\n",
      "17 isento\n",
      "7 ismael\n",
      "12 israel\n",
      "24 it\n",
      "12 ita\n",
      "19 itau\n",
      "49 item\n",
      "53 itens\n",
      "21 ivan\n",
      "7 ivo\n",
      "16 ivone\n",
      "17 izabel\n",
      "7 izaias\n",
      "303 ja\n",
      "13 jacarepagua\n",
      "9 jair\n",
      "8 jairo\n",
      "7 jamc\n",
      "15 jan\n",
      "15 janaina\n",
      "12 jane\n",
      "93 janeiro\n",
      "133 janela\n",
      "34 jaqueline\n",
      "22 jardim\n",
      "7 jd\n",
      "21 jean\n",
      "18 jec\n",
      "15 jeferson\n",
      "14 jefferson\n",
      "37 jessica\n",
      "96 jesus\n",
      "24 jfa\n",
      "37 jo\n",
      "18 joana\n",
      "111 joao\n",
      "15 joaquim\n",
      "894 job\n",
      "545 jobid\n",
      "9 jobs\n",
      "18 joel\n",
      "8 jogar\n",
      "14 joice\n",
      "7 jonas\n",
      "42 jorge\n",
      "29 jos\n",
      "178 jose\n",
      "10 josefa\n",
      "9 josiane\n",
      "9 joyce\n",
      "16 jpa\n",
      "7 jti\n",
      "7 juarez\n",
      "177 judicial\n",
      "7 juizado\n",
      "12 jul\n",
      "75 julho\n",
      "15 julia\n",
      "48 juliana\n",
      "13 juliano\n",
      "29 julio\n",
      "43 jumper\n",
      "49 jumpers\n",
      "8 jun\n",
      "61 junho\n",
      "17 junio\n",
      "134 junior\n",
      "35 juntamente\n",
      "81 junto\n",
      "20 jur\n",
      "7 juridico\n",
      "33 juros\n",
      "36 justica\n",
      "7 justificativa\n",
      "12 jve\n",
      "12 karina\n",
      "11 karine\n",
      "17 karla\n",
      "39 katia\n",
      "21 kbps\n",
      "42 keller\n",
      "34 kelly\n",
      "12 ken\n",
      "203 kenpx\n",
      "9 key\n",
      "119 kit\n",
      "8 kleber\n",
      "65 la\n",
      "17 lacerda\n",
      "157 lado\n",
      "7 lago\n",
      "53 lais\n",
      "90 lan\n",
      "14 lara\n",
      "148 larga\n",
      "19 larissa\n",
      "20 las\n",
      "22 laura\n",
      "11 layout\n",
      "8 lazaro\n",
      "9 lcg\n",
      "8 lculo\n",
      "360 ld\n",
      "20 ldi\n",
      "14 lditotal\n",
      "59 ldn\n",
      "11 ldntotal\n",
      "8 le\n",
      "31 leal\n",
      "58 leandro\n",
      "117 legado\n",
      "109 legados\n",
      "14 leitao\n",
      "50 leite\n",
      "13 leitura\n",
      "15 lembra\n",
      "59 lembramos\n",
      "19 lembrando\n",
      "8 lemes\n",
      "14 lemos\n",
      "27 lentid\n",
      "64 leonardo\n",
      "19 leticia\n",
      "56 levantamento\n",
      "16 levantamentos\n",
      "23 levantar\n",
      "11 lfe\n",
      "24 lg\n",
      "75 li\n",
      "198 lia\n",
      "27 lib\n",
      "370 libera\n",
      "16 liberacao\n",
      "229 liberada\n",
      "47 liberadas\n",
      "64 liberado\n",
      "15 liberados\n",
      "15 liberamos\n",
      "14 liberando\n",
      "305 liberar\n",
      "7 liberem\n",
      "9 liberou\n",
      "7 lica\n",
      "196 lico\n",
      "53 lida\n",
      "15 lidas\n",
      "8 lider\n",
      "7 lidia\n",
      "8 lidiane\n",
      "120 lido\n",
      "122 lidos\n",
      "9 liente\n",
      "240 liga\n",
      "8 ligado\n",
      "18 ligar\n",
      "189 light\n",
      "7 ligmix\n",
      "9 ligou\n",
      "10 lilian\n",
      "186 lima\n",
      "76 limbo\n",
      "9 limitada\n",
      "41 limite\n",
      "11 limites\n",
      "56 limpar\n",
      "33 limpeza\n",
      "29 line\n",
      "37 linh\n",
      "741 linha\n",
      "8 linhares\n",
      "415 linhas\n",
      "37 link\n",
      "8 lino\n",
      "10 lins\n",
      "54 lio\n",
      "7 lira\n",
      "15 lisboa\n",
      "135 lise\n",
      "19 lises\n",
      "8 list\n",
      "79 lista\n",
      "11 listada\n",
      "11 listadas\n",
      "89 listados\n",
      "32 listagem\n",
      "11 listando\n",
      "18 listar\n",
      "12 live\n",
      "17 livia\n",
      "14 livre\n",
      "7 liz\n",
      "7 lj\n",
      "12 lobo\n",
      "62 loc\n",
      "25 locais\n",
      "200 local\n",
      "304 localidade\n",
      "24 localidades\n",
      "26 localiza\n",
      "28 localizada\n",
      "7 localizadas\n",
      "60 localizado\n",
      "9 localizamos\n",
      "33 localizar\n",
      "10 loctotal\n",
      "68 log\n",
      "7 loga\n",
      "7 logada\n",
      "9 logadas\n",
      "36 logar\n",
      "55 logi\n",
      "370 login\n",
      "45 logins\n",
      "14 logistica\n",
      "65 logo\n",
      "63 logradouro\n",
      "20 logradouros\n",
      "35 logs\n",
      "8 loguin\n",
      "112 loja\n",
      "17 lojas\n",
      "117 lojista\n",
      "25 longa\n",
      "120 lopes\n",
      "8 lorena\n",
      "45 los\n",
      "24 lote\n",
      "10 louise\n",
      "43 lourdes\n",
      "16 lourenco\n",
      "14 lpa\n",
      "24 lt\n",
      "8 ltd\n",
      "159 ltda\n",
      "17 ltiplo\n",
      "10 luan\n",
      "29 luana\n",
      "58 lucas\n",
      "7 lucena\n",
      "93 lucia\n",
      "40 luciana\n",
      "9 luciane\n",
      "24 luciano\n",
      "12 luciene\n",
      "8 lucilene\n",
      "18 lucio\n",
      "16 lugar\n",
      "75 luis\n",
      "139 luiz\n",
      "29 luiza\n",
      "27 lula\n",
      "9 lurdes\n",
      "33 luz\n",
      "19 luzia\n",
      "8 lw\n",
      "10 lyra\n",
      "45 ma\n",
      "32 macedo\n",
      "88 machado\n",
      "29 maciel\n",
      "109 macro\n",
      "22 macros\n",
      "16 madalena\n",
      "74 mae\n",
      "30 magalhaes\n",
      "9 magno\n",
      "20 mahi\n",
      "31 maia\n",
      "137 mail\n",
      "50 mailing\n",
      "8 mainframe\n",
      "71 maio\n",
      "41 maior\n",
      "78 maiores\n",
      "10 maioria\n",
      "8 maira\n",
      "8 man\n",
      "7 manda\n",
      "7 mandar\n",
      "16 maneira\n",
      "8 manh\n",
      "14 manobra\n",
      "48 manoel\n",
      "10 mantendo\n",
      "21 manter\n",
      "10 manteve\n",
      "126 manual\n",
      "254 manualmente\n",
      "9 manuel\n",
      "15 manuten\n",
      "7 manutencao\n",
      "7 map\n",
      "12 maquina\n",
      "13 maquinas\n",
      "265 mar\n",
      "23 mara\n",
      "48 marca\n",
      "7 marcada\n",
      "46 marcado\n",
      "8 marcados\n",
      "54 marcar\n",
      "7 marcel\n",
      "16 marcelino\n",
      "98 marcelo\n",
      "79 marcia\n",
      "53 marcio\n",
      "62 marco\n",
      "102 marcos\n",
      "15 marcus\n",
      "7 margarete\n",
      "11 margarida\n",
      "202 maria\n",
      "33 mariana\n",
      "18 mariane\n",
      "20 mariano\n",
      "15 marilene\n",
      "11 marilia\n",
      "8 marina\n",
      "20 marinho\n",
      "7 marins\n",
      "7 marint\n",
      "22 mario\n",
      "9 marisa\n",
      "8 mariza\n",
      "25 marketing\n",
      "30 marlene\n",
      "17 marli\n",
      "106 marques\n",
      "7 mart\n",
      "24 marta\n",
      "9 martha\n",
      "9 martinez\n",
      "148 martins\n",
      "8 mary\n",
      "15 masc\n",
      "8 mascara\n",
      "50 massa\n",
      "55 massivo\n",
      "23 master\n",
      "14 mat\n",
      "39 materiais\n",
      "20 mateus\n",
      "23 matheus\n",
      "11 matias\n",
      "25 mato\n",
      "32 matos\n",
      "61 matr\n",
      "50 matricula\n",
      "57 matriculas\n",
      "8 matriz\n",
      "17 mattos\n",
      "29 mauricio\n",
      "17 mauro\n",
      "10 max\n",
      "11 maxima\n",
      "12 maximo\n",
      "9 mayara\n",
      "278 mb\n",
      "18 mbps\n",
      "8 mcdu\n",
      "24 mco\n",
      "12 md\n",
      "54 medeiros\n",
      "26 media\n",
      "11 mediante\n",
      "11 medina\n",
      "84 medio\n",
      "56 mega\n",
      "55 megas\n",
      "284 meio\n",
      "73 meios\n",
      "9 meira\n",
      "29 melhor\n",
      "35 mello\n",
      "77 melo\n",
      "12 mencionado\n",
      "85 mendes\n",
      "23 mendonca\n",
      "38 menezes\n",
      "49 menor\n",
      "35 menos\n",
      "371 mensagem\n",
      "29 mensagens\n",
      "12 mensais\n",
      "42 mensal\n",
      "107 menu\n",
      "21 mercado\n",
      "16 merge\n",
      "732 mero\n",
      "91 meros\n",
      "41 mes\n",
      "67 meses\n",
      "31 mesquita\n",
      "10 messias\n",
      "203 met\n",
      "9 metalurgica\n",
      "15 metro\n",
      "24 metroeth\n",
      "9 metros\n",
      "482 mg\n",
      "20 mgid\n",
      "85 mi\n",
      "95 mica\n",
      "8 micas\n",
      "9 michel\n",
      "15 michele\n",
      "17 michelle\n",
      "134 mico\n",
      "96 micro\n",
      "10 micros\n",
      "8 microservi\n",
      "36 mig\n",
      "539 migra\n",
      "16 migracao\n",
      "35 migrada\n",
      "18 migradas\n",
      "120 migrado\n",
      "20 migrador\n",
      "31 migrados\n",
      "15 migrando\n",
      "244 migrar\n",
      "16 migraram\n",
      "112 migrou\n",
      "32 miguel\n",
      "15 mil\n",
      "13 militar\n",
      "10 milton\n",
      "62 min\n",
      "23 minas\n",
      "10 minhaoi\n",
      "87 mini\n",
      "76 miniciclo\n",
      "10 ministerio\n",
      "143 minutos\n",
      "63 miranda\n",
      "9 miriam\n",
      "20 mirian\n",
      "28 mite\n",
      "123 mix\n",
      "28 mkt\n",
      "10 mktrel\n",
      "16 mm\n",
      "31 mms\n",
      "20 mns\n",
      "23 mobile\n",
      "13 mobilidade\n",
      "31 modalidade\n",
      "24 modelo\n",
      "170 modem\n",
      "107 modifica\n",
      "10 modificado\n",
      "29 modificar\n",
      "21 modo\n",
      "106 modulo\n",
      "8 moises\n",
      "197 momento\n",
      "140 mon\n",
      "9 monet\n",
      "22 monica\n",
      "8 monit\n",
      "50 monitor\n",
      "9 monitoracao\n",
      "16 monitorar\n",
      "8 monte\n",
      "54 monteiro\n",
      "11 monthly\n",
      "82 moraes\n",
      "49 morais\n",
      "90 moreira\n",
      "9 moreno\n",
      "35 mos\n",
      "156 mostra\n",
      "10 mostrado\n",
      "7 mostram\n",
      "17 mostrando\n",
      "20 mota\n",
      "245 motivo\n",
      "11 motivos\n",
      "14 motta\n",
      "75 moura\n",
      "15 mov\n",
      "72 moveis\n",
      "385 movel\n",
      "14 mover\n",
      "16 movimento\n",
      "9 mozila\n",
      "60 mozilla\n",
      "7 mp\n",
      "11 mpa\n",
      "60 mpn\n",
      "433 ms\n",
      "43 msg\n",
      "290 msisdn\n",
      "42 msisdns\n",
      "16 mssisdn\n",
      "15 msz\n",
      "29 mszc\n",
      "229 mt\n",
      "11 mu\n",
      "8 mua\n",
      "98 mud\n",
      "37 muda\n",
      "404 mudan\n",
      "13 mudanca\n",
      "7 mudando\n",
      "71 mudar\n",
      "9 mudarea\n",
      "69 mudend\n",
      "42 mudext\n",
      "153 mudinho\n",
      "29 mudla\n",
      "33 mudou\n",
      "34 mudporta\n",
      "23 mudqlinha\n",
      "13 muller\n",
      "176 multa\n",
      "30 multas\n",
      "12 multi\n",
      "28 multiplicidade\n",
      "51 multiprodutos\n",
      "8 mundo\n",
      "13 munic\n",
      "49 municipal\n",
      "47 municipio\n",
      "14 muniz\n",
      "9 murilo\n",
      "41 nacional\n",
      "50 nada\n",
      "15 nadia\n",
      "8 nadir\n",
      "121 name\n",
      "540 nao\n",
      "16 nara\n",
      "144 nasc\n",
      "247 nascimento\n",
      "65 nat\n",
      "10 natal\n",
      "32 natalia\n",
      "7 natbetx\n",
      "17 nathalia\n",
      "31 navegador\n",
      "70 navegadores\n",
      "8 nayara\n",
      "7 nazare\n",
      "23 nba\n",
      "36 nc\n",
      "2061 ncia\n",
      "9 nciado\n",
      "11 ncial\n",
      "1032 ncias\n",
      "9 nculo\n",
      "7 nds\n",
      "8 ne\n",
      "242 necess\n",
      "9 necessarias\n",
      "72 necessario\n",
      "23 necessidade\n",
      "31 necessita\n",
      "48 necessitam\n",
      "11 necessitamos\n",
      "18 necessito\n",
      "20 neg\n",
      "31 negado\n",
      "10 negocia\n",
      "14 negocio\n",
      "13 negocios\n",
      "7 nehuma\n",
      "7 neide\n",
      "7 neli\n",
      "25 nelson\n",
      "176 nenhuma\n",
      "7 neogrid\n",
      "10 nery\n",
      "43 nesse\n",
      "11 nesses\n",
      "80 neste\n",
      "92 net\n",
      "7 netb\n",
      "14 netiwn\n",
      "71 neto\n",
      "7 netprd\n",
      "28 netwin\n",
      "8 neusa\n",
      "21 neuza\n",
      "55 neves\n",
      "32 nextel\n",
      "17 nf\n",
      "9 nffd\n",
      "7 nfid\n",
      "11 nia\n",
      "126 nica\n",
      "10 nicas\n",
      "22 nico\n",
      "8 nilson\n",
      "8 nilton\n",
      "10 nilza\n",
      "76 nimo\n",
      "63 nio\n",
      "19 niter\n",
      "13 niteroi\n",
      "20 niu\n",
      "156 nivel\n",
      "12 nm\n",
      "17 nnf\n",
      "52 nobill\n",
      "9 nobre\n",
      "80 noc\n",
      "21 node\n",
      "790 nodeid\n",
      "40 nogueira\n",
      "84 noite\n",
      "37 nok\n",
      "707 nome\n",
      "14 nomenclatura\n",
      "8 nomes\n",
      "11 nonato\n",
      "12 noncat\n",
      "103 norm\n",
      "7 normais\n",
      "163 normal\n",
      "8 normalizado\n",
      "8 normalizar\n",
      "113 normalmente\n",
      "8 norte\n",
      "19 not\n",
      "87 nota\n",
      "32 notas\n",
      "12 notifica\n",
      "9 nov\n",
      "191 nova\n",
      "13 novaes\n",
      "103 novamente\n",
      "31 novas\n",
      "16 novembro\n",
      "331 novo\n",
      "62 novos\n",
      "19 np\n",
      "54 npac\n",
      "42 nr\n",
      "211 nrc\n",
      "20 nrcs\n",
      "30 nres\n",
      "30 nri\n",
      "18 nro\n",
      "11 nrs\n",
      "14 ns\n",
      "9 nsc\n",
      "23 nt\n",
      "64 ntcd\n",
      "22 ntce\n",
      "12 ntcm\n",
      "24 ntl\n",
      "10 nu\n",
      "51 null\n",
      "15 nulo\n",
      "7 number\n",
      "10 numera\n",
      "12 numeracao\n",
      "15 numerador\n",
      "441 numero\n",
      "30 numeros\n",
      "80 nunes\n",
      "280 nus\n",
      "10 oa\n",
      "8 obj\n",
      "8 object\n",
      "29 objectel\n",
      "12 obriga\n",
      "147 obrigada\n",
      "157 obrigado\n",
      "116 obrigat\n",
      "8 obrigatorio\n",
      "394 obs\n",
      "55 observa\n",
      "9 observar\n",
      "8 obter\n",
      "13 obteve\n",
      "7 obtivemos\n",
      "12 ocasionando\n",
      "8 occurred\n",
      "10 ocm\n",
      "347 oco\n",
      "66 ocorr\n",
      "30 ocorra\n",
      "260 ocorre\n",
      "11 ocorrencia\n",
      "115 ocorrendo\n",
      "28 ocorrer\n",
      "9 ocorreram\n",
      "335 ocorreu\n",
      "9 ocorrida\n",
      "38 ocorrido\n",
      "30 ocos\n",
      "136 ocs\n",
      "318 oct\n",
      "12 octlight\n",
      "42 ocupado\n",
      "12 od\n",
      "548 odate\n",
      "163 odo\n",
      "38 odos\n",
      "10 oe\n",
      "56 oes\n",
      "11 oeste\n",
      "12 of\n",
      "33 ofc\n",
      "350 oferta\n",
      "14 ofertado\n",
      "51 ofertas\n",
      "30 off\n",
      "14 office\n",
      "23 offline\n",
      "57 ogs\n",
      "4567 oi\n",
      "20 oidigital\n",
      "26 oiofc\n",
      "7 oipaggo\n",
      "9 oipontos\n",
      "28 oit\n",
      "30 oitot\n",
      "73 oitotal\n",
      "74 oitv\n",
      "26 oivende\n",
      "211 ok\n",
      "7 ol\n",
      "11 old\n",
      "266 oliveira\n",
      "232 om\n",
      "168 omr\n",
      "763 oms\n",
      "12 omvelox\n",
      "35 on\n",
      "193 onde\n",
      "32 online\n",
      "20 ontem\n",
      "383 op\n",
      "49 opcao\n",
      "41 opcional\n",
      "24 open\n",
      "517 opera\n",
      "148 operacao\n",
      "10 operacional\n",
      "38 operador\n",
      "376 operadora\n",
      "31 operadoras\n",
      "42 operadores\n",
      "27 optica\n",
      "10 opvprd\n",
      "15 or\n",
      "10 oracle\n",
      "677 ordem\n",
      "196 ordens\n",
      "71 order\n",
      "1336 orderid\n",
      "8 organiza\n",
      "9 orgao\n",
      "60 orienta\n",
      "34 orientada\n",
      "43 orientado\n",
      "287 origem\n",
      "7 originadas\n",
      "16 originado\n",
      "86 original\n",
      "7 ortega\n",
      "7 osc\n",
      "22 oscrm\n",
      "173 oss\n",
      "16 ossac\n",
      "12 osvaldo\n",
      "15 osvc\n",
      "643 ot\n",
      "7 otavio\n",
      "8 otl\n",
      "27 out\n",
      "11 outlook\n",
      "58 outubro\n",
      "14 ouve\n",
      "102 ouvidoria\n",
      "10 override\n",
      "126 pa\n",
      "11 pablo\n",
      "31 pabx\n",
      "7 pac\n",
      "22 pacheco\n",
      "34 pack\n",
      "17 package\n",
      "339 pacote\n",
      "209 pacotes\n",
      "8 padilha\n",
      "11 padr\n",
      "146 pae\n",
      "15 paes\n",
      "126 paga\n",
      "252 pagamento\n",
      "11 pagando\n",
      "16 pagar\n",
      "279 pagas\n",
      "16 paggo\n",
      "49 pagina\n",
      "571 pago\n",
      "13 pagos\n",
      "51 pagou\n",
      "9 pagseguro\n",
      "158 pai\n",
      "12 painel\n",
      "11 pais\n",
      "31 paiva\n",
      "9 paixao\n",
      "7 palno\n",
      "8 paludo\n",
      "7 pamela\n",
      "21 paola\n",
      "42 pap\n",
      "15 papel\n",
      "49 papo\n",
      "269 par\n",
      "746 parada\n",
      "204 paradas\n",
      "181 parado\n",
      "106 parados\n",
      "18 parametriza\n",
      "24 parametrizada\n",
      "11 parametro\n",
      "7 paran\n",
      "8 parana\n",
      "7 parc\n",
      "116 parceiro\n",
      "9 parcela\n",
      "76 parcelamento\n",
      "7 parcelar\n",
      "61 parcial\n",
      "7 parcialmente\n",
      "19 parece\n",
      "17 parecer\n",
      "13 parm\n",
      "17 parou\n",
      "113 parte\n",
      "51 participante\n",
      "8 partindo\n",
      "34 partir\n",
      "8 partiu\n",
      "18 pas\n",
      "12 pass\n",
      "31 passa\n",
      "24 passada\n",
      "24 passado\n",
      "7 passados\n",
      "11 passando\n",
      "31 passar\n",
      "9 passaram\n",
      "151 passo\n",
      "24 passos\n",
      "58 passou\n",
      "15 pasta\n",
      "12 patr\n",
      "75 patricia\n",
      "127 paula\n",
      "13 paulino\n",
      "140 paulo\n",
      "11 paz\n",
      "49 pb\n",
      "11 pbat\n",
      "111 pbi\n",
      "167 pc\n",
      "7 pcb\n",
      "17 pcd\n",
      "16 pcdi\n",
      "18 pcen\n",
      "7 pcmais\n",
      "8 pcp\n",
      "40 pcpprd\n",
      "241 pcrm\n",
      "94 pcs\n",
      "18 pct\n",
      "8 pcte\n",
      "65 pdf\n",
      "1055 pdv\n",
      "8 pdvs\n",
      "457 pe\n",
      "28 pecas\n",
      "85 pede\n",
      "8 pedencia\n",
      "21 pedente\n",
      "1858 pedido\n",
      "129 pedidos\n",
      "14 pedimos\n",
      "31 pedindo\n",
      "11 pedir\n",
      "46 pediu\n",
      "86 pedro\n",
      "7 pef\n",
      "9 pegar\n",
      "22 pegasus\n",
      "29 peixoto\n",
      "8 pelican\n",
      "690 pend\n",
      "8 pendecia\n",
      "440 pendencia\n",
      "36 pendenciada\n",
      "50 pendenciado\n",
      "17 pendenciar\n",
      "54 pendencias\n",
      "556 pendente\n",
      "97 pendentes\n",
      "14 penha\n",
      "199 per\n",
      "54 percentual\n",
      "67 perda\n",
      "19 perdeu\n",
      "10 perdido\n",
      "211 pereira\n",
      "9 peres\n",
      "7 perez\n",
      "138 perfil\n",
      "10 perfis\n",
      "17 periodo\n",
      "9 permance\n",
      "279 permanece\n",
      "181 permanecem\n",
      "27 permanecendo\n",
      "85 permanecer\n",
      "28 permaneceram\n",
      "81 permaneceu\n",
      "18 permiss\n",
      "301 permite\n",
      "14 permitem\n",
      "8 permiti\n",
      "108 permitida\n",
      "116 permitido\n",
      "132 permitindo\n",
      "31 permitir\n",
      "47 permitiu\n",
      "8 pernambuco\n",
      "113 persiste\n",
      "92 pertence\n",
      "14 pertencem\n",
      "8 pertencentes\n",
      "90 pesquisa\n",
      "15 pesquisar\n",
      "22 pesquisas\n",
      "48 pessoa\n",
      "13 pessoal\n",
      "65 pessoas\n",
      "102 pf\n",
      "21 pfat\n",
      "10 pfc\n",
      "304 pfx\n",
      "14 pg\n",
      "563 pgm\n",
      "792 php\n",
      "41 pi\n",
      "138 pics\n",
      "29 pida\n",
      "11 pido\n",
      "15 piloto\n",
      "13 pimenta\n",
      "7 pimentel\n",
      "24 pinf\n",
      "48 pinheiro\n",
      "10 pinho\n",
      "58 pinto\n",
      "12 pio\n",
      "38 pip\n",
      "11 pipeline\n",
      "51 pires\n",
      "8 pj\n",
      "63 pke\n",
      "27 pl\n",
      "41 plabil\n",
      "12 plaf\n",
      "8 plan\n",
      "13 planas\n",
      "7 planejamento\n",
      "116 planilha\n",
      "657 plano\n",
      "143 planos\n",
      "36 planta\n",
      "10 plat\n",
      "68 plataforma\n",
      "20 plataformas\n",
      "7 playboy\n",
      "11 plsql\n",
      "7 plt\n",
      "35 plus\n",
      "12 pmj\n",
      "24 pmkt\n",
      "123 pms\n",
      "81 pnet\n",
      "7 pneus\n",
      "37 po\n",
      "115 podem\n",
      "33 podemos\n",
      "64 poder\n",
      "44 podera\n",
      "14 podermos\n",
      "9 policia\n",
      "45 ponta\n",
      "7 ponte\n",
      "20 pontes\n",
      "177 ponto\n",
      "128 pontos\n",
      "10 pontual\n",
      "26 pop\n",
      "15 popular\n",
      "11 porcentagem\n",
      "389 porem\n",
      "10 porqu\n",
      "11 port\n",
      "106 porta\n",
      "12 portab\n",
      "545 portabilidade\n",
      "10 portabilidades\n",
      "32 portada\n",
      "12 portadas\n",
      "273 portado\n",
      "51 portador\n",
      "25 portadora\n",
      "20 portados\n",
      "672 portal\n",
      "60 portanto\n",
      "24 portar\n",
      "28 portas\n",
      "18 portf\n",
      "13 portfolio\n",
      "19 portif\n",
      "18 portifolio\n",
      "20 porto\n",
      "21 portou\n",
      "398 pos\n",
      "8 posbif\n",
      "18 posconec\n",
      "21 posi\n",
      "14 positiva\n",
      "321 poss\n",
      "122 possa\n",
      "22 possam\n",
      "153 possamos\n",
      "67 possibilidade\n",
      "10 possibilita\n",
      "7 possibilitando\n",
      "235 possivel\n",
      "7 possivelmente\n",
      "94 possu\n",
      "16 possue\n",
      "72 possuem\n",
      "445 possui\n",
      "24 possuia\n",
      "9 possuimos\n",
      "25 possuir\n",
      "8 possuo\n",
      "48 postal\n",
      "24 posterior\n",
      "18 posteriormente\n",
      "895 posto\n",
      "24 postos\n",
      "8 poup\n",
      "18 pp\n",
      "9 ppi\n",
      "17 pprt\n",
      "9 pq\n",
      "1065 pr\n",
      "115 pra\n",
      "24 prado\n",
      "8 prates\n",
      "280 prazo\n",
      "17 prazos\n",
      "547 prc\n",
      "9 prd\n",
      "271 pre\n",
      "108 precisa\n",
      "43 precisam\n",
      "262 precisamos\n",
      "7 precisando\n",
      "160 preciso\n",
      "11 preco\n",
      "7 predio\n",
      "12 preechemos\n",
      "14 preen\n",
      "7 preencha\n",
      "10 preenche\n",
      "126 preencher\n",
      "18 preenchida\n",
      "7 preenchidas\n",
      "67 preenchido\n",
      "21 preenchidos\n",
      "34 preenchimento\n",
      "59 prefeitura\n",
      "16 prefixo\n",
      "8 prefixos\n",
      "7 premier\n",
      "14 premiere\n",
      "163 prep\n",
      "19 prepago\n",
      "22 preq\n",
      "231 presa\n",
      "27 presas\n",
      "55 presente\n",
      "10 presentes\n",
      "229 preso\n",
      "20 presos\n",
      "13 prestada\n",
      "7 prestadora\n",
      "9 prestes\n",
      "9 preven\n",
      "9 prevista\n",
      "10 previsto\n",
      "7 preza\n",
      "119 prezado\n",
      "349 prezados\n",
      "22 prezadx\n",
      "7 prezo\n",
      "1583 pri\n",
      "50 prim\n",
      "8 primario\n",
      "36 primeira\n",
      "29 prin\n",
      "43 principal\n",
      "8 principio\n",
      "537 print\n",
      "146 prints\n",
      "40 prioridade\n",
      "9 prioriza\n",
      "23 priorizar\n",
      "31 priscila\n",
      "7 prive\n",
      "63 prj\n",
      "135 pro\n",
      "276 problema\n",
      "135 problemas\n",
      "37 proc\n",
      "10 procede\n",
      "17 procedente\n",
      "137 proceder\n",
      "226 procedimento\n",
      "24 procedimentos\n",
      "20 procedure\n",
      "13 proceguir\n",
      "12 process\n",
      "10 processa\n",
      "15 processada\n",
      "20 processado\n",
      "128 processamento\n",
      "9 processar\n",
      "239 processo\n",
      "12 processos\n",
      "93 procon\n",
      "10 procsim\n",
      "7 procuradoria\n",
      "10 procurar\n",
      "105 prod\n",
      "83 prodtrap\n",
      "26 produ\n",
      "397 produto\n",
      "9 produtor\n",
      "215 produtos\n",
      "60 profissional\n",
      "59 proforma\n",
      "307 programa\n",
      "7 programada\n",
      "15 progressao\n",
      "8 proje\n",
      "8 projetada\n",
      "44 projetado\n",
      "41 projeto\n",
      "41 projetos\n",
      "100 promessa\n",
      "66 promo\n",
      "18 promocional\n",
      "19 pronta\n",
      "24 pronto\n",
      "50 propensos\n",
      "11 proporcional\n",
      "37 proposta\n",
      "7 propostas\n",
      "14 propriedade\n",
      "8 proprio\n",
      "29 prorroga\n",
      "10 prorrogadas\n",
      "33 prorrogar\n",
      "13 proseguindo\n",
      "17 proseguir\n",
      "35 prossegue\n",
      "15 prosseguimento\n",
      "299 prosseguir\n",
      "17 prosseguirmos\n",
      "11 prosseguiu\n",
      "348 protocolo\n",
      "24 protocolos\n",
      "11 provavelmente\n",
      "26 provedor\n",
      "47 prover\n",
      "379 providenciar\n",
      "54 provis\n",
      "14 provisionado\n",
      "294 provisionamento\n",
      "21 provisionar\n",
      "8 provisonamento\n",
      "15 provisorio\n",
      "7 prs\n",
      "167 prvnosb\n",
      "25 ps\n",
      "11 psa\n",
      "34 psbl\n",
      "17 psul\n",
      "7 pta\n",
      "9 ptica\n",
      "33 pts\n",
      "20 ptvs\n",
      "9 publica\n",
      "37 publico\n",
      "8 puxa\n",
      "7 puxar\n",
      "10 pv\n",
      "63 pvo\n",
      "8 pvw\n",
      "10 pzlv\n",
      "9 qabr\n",
      "8 qago\n",
      "10 qdez\n",
      "11 qfev\n",
      "8 qjun\n",
      "10 qmai\n",
      "8 qnov\n",
      "99 qr\n",
      "37 qtd\n",
      "26 qtde\n",
      "12 qu\n",
      "8 quadro\n",
      "7 quadros\n",
      "17 qualifica\n",
      "8 qualificacao\n",
      "14 qualificada\n",
      "115 qualificar\n",
      "13 quality\n",
      "88 qualquer\n",
      "111 quantidade\n",
      "38 quarentena\n",
      "11 quase\n",
      "10 quatro\n",
      "7 queda\n",
      "25 queiroz\n",
      "75 queixa\n",
      "102 quer\n",
      "97 quest\n",
      "14 questionamentos\n",
      "12 questionando\n",
      "7 qui\n",
      "37 quina\n",
      "7 quinas\n",
      "97 quitado\n",
      "34 quot\n",
      "13 qy\n",
      "124 ra\n",
      "8 rabelo\n",
      "7 rachel\n",
      "92 rafael\n",
      "19 rafaela\n",
      "14 raimunda\n",
      "33 raimundo\n",
      "178 raiz\n",
      "7 ram\n",
      "68 ramais\n",
      "70 ramal\n",
      "12 ramalho\n",
      "10 ramon\n",
      "70 ramos\n",
      "15 rangel\n",
      "15 raphael\n",
      "28 raquel\n",
      "10 rata\n",
      "130 raz\n",
      "9 raza\n",
      "37 razao\n",
      "108 rb\n",
      "9 rbce\n",
      "27 rbo\n",
      "8 rbt\n",
      "557 rc\n",
      "25 rce\n",
      "20 rcs\n",
      "22 re\n",
      "99 rea\n",
      "23 reagendamento\n",
      "81 reagendar\n",
      "45 reais\n",
      "7 reajuste\n",
      "18 real\n",
      "90 realiza\n",
      "157 realizada\n",
      "29 realizadas\n",
      "204 realizado\n",
      "16 realizados\n",
      "13 realizam\n",
      "36 realizamos\n",
      "42 realizando\n",
      "544 realizar\n",
      "56 realizarmos\n",
      "13 realize\n",
      "121 realizou\n",
      "70 realmente\n",
      "11 reas\n",
      "9 reason\n",
      "113 reativa\n",
      "44 reativada\n",
      "45 reativar\n",
      "25 rec\n",
      "27 recado\n",
      "174 recarga\n",
      "35 recargas\n",
      "11 receba\n",
      "85 recebe\n",
      "9 recebem\n",
      "45 recebemos\n",
      "203 recebendo\n",
      "107 receber\n",
      "52 receberam\n",
      "12 receberretornosolicitbilheteportab\n",
      "10 receberretornosolicitportab\n",
      "255 recebeu\n",
      "8 recebida\n",
      "78 recebido\n",
      "61 recebimento\n",
      "66 receita\n",
      "9 recente\n",
      "8 recentemente\n",
      "67 recentes\n",
      "280 recep\n",
      "48 receptiva\n",
      "43 receptivo\n",
      "112 receptor\n",
      "63 receptora\n",
      "12 receptores\n",
      "12 reciclagem\n",
      "12 reciclo\n",
      "9 recife\n",
      "75 recl\n",
      "284 reclama\n",
      "98 reclamada\n",
      "22 reclamadas\n",
      "197 reclamado\n",
      "17 reclamados\n",
      "14 reclamando\n",
      "63 reclamante\n",
      "18 recomandar\n",
      "10 reconhe\n",
      "172 reconhece\n",
      "9 reconhecendo\n",
      "8 reconheceu\n",
      "16 reconhecido\n",
      "11 recorre\n",
      "39 recorrente\n",
      "8 recupera\n",
      "78 recuperar\n",
      "8 recursos\n",
      "11 recusa\n",
      "250 recusada\n",
      "14 recusado\n",
      "94 rede\n",
      "17 redecard\n",
      "10 redes\n",
      "15 redirect\n",
      "31 redu\n",
      "9 reduzir\n",
      "47 reenviar\n",
      "19 reenvio\n",
      "279 ref\n",
      "27 refazer\n",
      "78 refer\n",
      "15 refere\n",
      "54 referencia\n",
      "258 referente\n",
      "95 referentes\n",
      "13 referido\n",
      "8 referidos\n",
      "11 reflete\n",
      "14 refletido\n",
      "8 refletidos\n",
      "11 refletindo\n",
      "8 refletir\n",
      "92 refletiu\n",
      "17 reflita\n",
      "89 reg\n",
      "80 regi\n",
      "10 regiane\n",
      "13 regiao\n",
      "78 regina\n",
      "19 reginaldo\n",
      "15 regionais\n",
      "165 regional\n",
      "9 regis\n",
      "9 registra\n",
      "9 registrada\n",
      "32 registrado\n",
      "35 registrar\n",
      "201 registro\n",
      "62 registros\n",
      "11 rego\n",
      "66 regra\n",
      "8 regras\n",
      "18 regularizar\n",
      "18 reinaldo\n",
      "10 reincidente\n",
      "15 reiniciou\n",
      "75 reinstala\n",
      "32 reinstalar\n",
      "101 reis\n",
      "12 rej\n",
      "52 rejei\n",
      "23 rejeitado\n",
      "22 rejeitados\n",
      "105 rel\n",
      "62 rela\n",
      "9 relacionadas\n",
      "17 relacionado\n",
      "10 relacionados\n",
      "8 relacionamento\n",
      "90 relat\n",
      "52 relata\n",
      "19 relatorio\n",
      "93 relatorios\n",
      "10 relay\n",
      "30 relfat\n",
      "11 remedy\n",
      "17 remessa\n",
      "8 remessas\n",
      "48 remo\n",
      "70 remover\n",
      "19 removeu\n",
      "15 removido\n",
      "10 renan\n",
      "57 renata\n",
      "37 renato\n",
      "11 rentabiliza\n",
      "11 rep\n",
      "212 reparo\n",
      "38 reparos\n",
      "8 repassado\n",
      "30 repasse\n",
      "11 replica\n",
      "10 replicacao\n",
      "13 reporta\n",
      "20 reppx\n",
      "25 representacoes\n",
      "9 reproc\n",
      "8 reprocessado\n",
      "15 reprocessados\n",
      "27 reprocessamento\n",
      "22 reprocessar\n",
      "18 req\n",
      "12 requer\n",
      "20 request\n",
      "43 requisi\n",
      "145 res\n",
      "9 resende\n",
      "96 reserva\n",
      "80 reservada\n",
      "30 reservado\n",
      "8 reservar\n",
      "220 reset\n",
      "53 resetar\n",
      "26 resgatar\n",
      "62 resgate\n",
      "34 resid\n",
      "16 residencia\n",
      "165 residencial\n",
      "7 residual\n",
      "18 resolu\n",
      "29 resolver\n",
      "8 resolveu\n",
      "18 resolvida\n",
      "34 resolvido\n",
      "16 resolvo\n",
      "9 resp\n",
      "11 respectiva\n",
      "14 respectivamente\n",
      "15 respectivas\n",
      "59 respectivos\n",
      "17 respeitando\n",
      "14 responda\n",
      "18 responde\n",
      "95 respons\n",
      "9 responsabilidade\n",
      "28 responsavel\n",
      "11 response\n",
      "44 resposta\n",
      "11 ressaltar\n",
      "33 ressalto\n",
      "7 ressubmeter\n",
      "11 ressubmiss\n",
      "20 rest\n",
      "15 restante\n",
      "7 restaurante\n",
      "8 restaurar\n",
      "26 restri\n",
      "12 resubmeter\n",
      "51 resultado\n",
      "8 resumindo\n",
      "109 resumo\n",
      "350 ret\n",
      "20 retadsl\n",
      "29 retblo\n",
      "11 retbusca\n",
      "14 reteild\n",
      "302 reten\n",
      "13 retencao\n",
      "7 retfway\n",
      "17 retida\n",
      "11 retidas\n",
      "8 retido\n",
      "7 retifica\n",
      "12 retificada\n",
      "7 retinet\n",
      "47 retinsmud\n",
      "62 retinsmudnum\n",
      "11 retir\n",
      "52 retira\n",
      "599 retirada\n",
      "12 retiradas\n",
      "155 retirado\n",
      "37 retirados\n",
      "19 retirando\n",
      "317 retirar\n",
      "14 retire\n",
      "8 retirem\n",
      "14 retirou\n",
      "9 retitar\n",
      "7 retmtro\n",
      "18 retoitot\n",
      "153 retorna\n",
      "24 retornada\n",
      "40 retornado\n",
      "10 retornam\n",
      "60 retornando\n",
      "60 retornar\n",
      "10 retornaram\n",
      "11 retorne\n",
      "206 retorno\n",
      "7 retornos\n",
      "305 retornou\n",
      "44 retplano\n",
      "61 retransmitir\n",
      "7 retroativas\n",
      "54 rev\n",
      "67 revenda\n",
      "24 revers\n",
      "10 review\n",
      "10 revis\n",
      "18 rezende\n",
      "29 rf\n",
      "10 rffd\n",
      "9 rffps\n",
      "9 rffpsel\n",
      "269 rg\n",
      "7 rgio\n",
      "21 ri\n",
      "606 ria\n",
      "135 rias\n",
      "10 ribas\n",
      "164 ribeiro\n",
      "96 ricardo\n",
      "189 rico\n",
      "18 rie\n",
      "14 rii\n",
      "1500 rio\n",
      "247 rios\n",
      "14 risco\n",
      "48 rita\n",
      "424 rj\n",
      "231 rjo\n",
      "33 rmino\n",
      "37 rn\n",
      "163 ro\n",
      "30 roaming\n",
      "18 roberta\n",
      "175 roberto\n",
      "51 robo\n",
      "42 robson\n",
      "99 rocha\n",
      "11 rodando\n",
      "43 rodar\n",
      "10 rodolfo\n",
      "84 rodrigo\n",
      "168 rodrigues\n",
      "7 roger\n",
      "74 rogerio\n",
      "15 rogero\n",
      "8 rolagem\n",
      "9 romero\n",
      "26 ronaldo\n",
      "9 rondonia\n",
      "8 roque\n",
      "98 rosa\n",
      "9 rosana\n",
      "15 rosangela\n",
      "11 rosario\n",
      "11 rose\n",
      "8 roseli\n",
      "9 rosilene\n",
      "9 rossi\n",
      "8 rot\n",
      "13 rota\n",
      "29 rotina\n",
      "12 rotinas\n",
      "8 roubo\n",
      "65 row\n",
      "37 rp\n",
      "9 rpc\n",
      "20 rr\n",
      "142 rs\n",
      "120 rt\n",
      "96 rtcd\n",
      "14 rtcm\n",
      "31 rua\n",
      "18 rubens\n",
      "9 rufino\n",
      "27 rural\n",
      "9 rus\n",
      "8 rute\n",
      "19 rv\n",
      "11 rvd\n",
      "96 sa\n",
      "13 sabe\n",
      "11 sabemos\n",
      "34 saber\n",
      "8 sabrina\n",
      "1613 sac\n",
      "84 saf\n",
      "15 sag\n",
      "20 sai\n",
      "8 saindo\n",
      "17 sair\n",
      "23 saiu\n",
      "7 saldanha\n",
      "98 saldo\n",
      "42 sales\n",
      "12 salete\n",
      "10 salles\n",
      "21 salvador\n",
      "15 salvar\n",
      "46 sampaio\n",
      "71 sample\n",
      "17 samuel\n",
      "7 sanches\n",
      "36 sandra\n",
      "21 sandro\n",
      "8 sant\n",
      "49 santa\n",
      "61 santana\n",
      "38 santander\n",
      "24 santiago\n",
      "24 santo\n",
      "227 santos\n",
      "36 sao\n",
      "81 sap\n",
      "10 saraiva\n",
      "7 satus\n",
      "24 saude\n",
      "11 saulo\n",
      "27 sav\n",
      "69 sbl\n",
      "10 sbloitotal\n",
      "8 sblpx\n",
      "414 sc\n",
      "8 scacp\n",
      "10 scb\n",
      "21 schedule\n",
      "17 scom\n",
      "10 scp\n",
      "13 sd\n",
      "9 sdcorp\n",
      "59 sdr\n",
      "7 seabra\n",
      "8 sebastiana\n",
      "22 sebastiao\n",
      "52 sec\n",
      "48 secretaria\n",
      "45 secund\n",
      "8 seg\n",
      "75 segmenta\n",
      "84 segmento\n",
      "7 segmentos\n",
      "1414 segue\n",
      "155 seguem\n",
      "7 segui\n",
      "22 seguida\n",
      "22 seguindo\n",
      "198 seguinte\n",
      "41 seguintes\n",
      "332 seguir\n",
      "10 seguirmos\n",
      "9 seguiu\n",
      "48 segunda\n",
      "50 segundo\n",
      "10 segundos\n",
      "29 seguran\n",
      "20 seguranca\n",
      "24 seguros\n",
      "8 seis\n",
      "7 seixas\n",
      "22 sele\n",
      "8 seleciona\n",
      "15 selecionada\n",
      "66 selecionado\n",
      "54 selecionar\n",
      "8 selma\n",
      "95 semana\n",
      "10 semanas\n",
      "21 sena\n",
      "386 senha\n",
      "8 senhora\n",
      "59 senhores\n",
      "12 separada\n",
      "21 separadamente\n",
      "23 separadas\n",
      "16 separado\n",
      "11 sequ\n",
      "15 sequencia\n",
      "71 sequencial\n",
      "278 ser\n",
      "34 sera\n",
      "21 serede\n",
      "57 serem\n",
      "12 sereno\n",
      "74 sergio\n",
      "8 sergipe\n",
      "7 serie\n",
      "27 serpa\n",
      "32 serra\n",
      "48 serv\n",
      "19 server\n",
      "841 servi\n",
      "46 service\n",
      "7 services\n",
      "173 servico\n",
      "92 servicos\n",
      "19 servidor\n",
      "10 servidores\n",
      "8 sess\n",
      "22 set\n",
      "61 setembro\n",
      "53 setor\n",
      "21 sev\n",
      "10 severidade\n",
      "17 severino\n",
      "8 sex\n",
      "24 sexy\n",
      "297 sfa\n",
      "423 sge\n",
      "10 sgeb\n",
      "21 sgef\n",
      "33 sgft\n",
      "17 sgo\n",
      "14 sh\n",
      "10 sharepoint\n",
      "14 sheila\n",
      "277 siac\n",
      "116 sibel\n",
      "45 sica\n",
      "286 sico\n",
      "12 sicos\n",
      "18 sidara\n",
      "13 sidnei\n",
      "8 sidney\n",
      "2018 siebel\n",
      "11 siebelbatimento\n",
      "13 siebelcdi\n",
      "11 siebeldataguard\n",
      "22 siebelmkt\n",
      "151 siebelreport\n",
      "34 siga\n",
      "149 sigla\n",
      "10 siin\n",
      "286 silva\n",
      "43 silvana\n",
      "84 silveira\n",
      "7 silvestre\n",
      "22 silvia\n",
      "11 silvio\n",
      "301 sim\n",
      "8 simao\n",
      "8 simas\n",
      "12 simcard\n",
      "8 simcards\n",
      "18 simoes\n",
      "50 simone\n",
      "19 simples\n",
      "18 simproc\n",
      "96 simula\n",
      "7 simulada\n",
      "34 simular\n",
      "12 sin\n",
      "152 sinal\n",
      "30 sincronismo\n",
      "314 sinn\n",
      "8 sinndth\n",
      "11 sinnweb\n",
      "46 siqueira\n",
      "13 sirlene\n",
      "93 sis\n",
      "7 sisbel\n",
      "218 sisjur\n",
      "294 sisraf\n",
      "234 sist\n",
      "8 sistem\n",
      "595 sistema\n",
      "182 sistemas\n",
      "18 sistemica\n",
      "78 sistemico\n",
      "25 sit\n",
      "908 site\n",
      "20 sitema\n",
      "52 sitescope\n",
      "16 sito\n",
      "30 sittel\n",
      "170 situa\n",
      "16 situacao\n",
      "7 skill\n",
      "17 sla\n",
      "9 sldd\n",
      "7 sle\n",
      "18 slot\n",
      "23 sls\n",
      "8 smb\n",
      "11 smi\n",
      "10 smkprd\n",
      "8 smpe\n",
      "145 sms\n",
      "10 sno\n",
      "87 so\n",
      "44 soa\n",
      "10 soapenv\n",
      "9 soapx\n",
      "124 soares\n",
      "15 soasync\n",
      "1121 soc\n",
      "162 social\n",
      "11 sociedade\n",
      "16 socorro\n",
      "32 sofreram\n",
      "34 sofreu\n",
      "9 sol\n",
      "18 solange\n",
      "11 solic\n",
      "1362 solicita\n",
      "32 solicitacao\n",
      "80 solicitada\n",
      "186 solicitado\n",
      "97 solicitados\n",
      "86 solicitamos\n",
      "107 solicitando\n",
      "90 solicitante\n",
      "275 solicitar\n",
      "27 solicite\n",
      "363 solicito\n",
      "264 solicitou\n",
      "8 solicta\n",
      "82 solu\n",
      "26 solucionado\n",
      "27 solucionar\n",
      "8 solucoes\n",
      "8 solutions\n",
      "11 som\n",
      "15 some\n",
      "149 somente\n",
      "27 sompxa\n",
      "50 sonia\n",
      "7 sonilza\n",
      "48 sons\n",
      "10 soo\n",
      "12 soube\n",
      "123 sousa\n",
      "8 souto\n",
      "222 souza\n",
      "11 sox\n",
      "81 sp\n",
      "7 spa\n",
      "16 spm\n",
      "102 spo\n",
      "11 sql\n",
      "139 sr\n",
      "11 sra\n",
      "65 srs\n",
      "10 ss\n",
      "8 sso\n",
      "20 ssp\n",
      "1414 st\n",
      "9 sta\n",
      "47 start\n",
      "802 status\n",
      "10 staus\n",
      "1402 stc\n",
      "11 stcab\n",
      "35 stcd\n",
      "1660 step\n",
      "40 sti\n",
      "29 stica\n",
      "73 sticas\n",
      "7 ststus\n",
      "39 su\n",
      "41 sub\n",
      "128 subfastve\n",
      "34 subiu\n",
      "65 subnum\n",
      "7 subprograma\n",
      "44 substitui\n",
      "15 substituir\n",
      "21 substituta\n",
      "19 substituto\n",
      "350 sucesso\n",
      "10 sueli\n",
      "50 sul\n",
      "10 sumiu\n",
      "9 sup\n",
      "18 super\n",
      "10 superior\n",
      "12 supermercado\n",
      "23 supersav\n",
      "56 supervisor\n",
      "18 supervisora\n",
      "73 suporte\n",
      "145 surge\n",
      "106 surgiu\n",
      "8 susini\n",
      "13 suspen\n",
      "72 suspens\n",
      "25 suspensa\n",
      "55 suspenso\n",
      "21 suspensos\n",
      "9 suzana\n",
      "10 sv\n",
      "55 sva\n",
      "15 svctb\n",
      "95 svoi\n",
      "26 sylvia\n",
      "785 sysout\n",
      "30 ta\n",
      "31 tab\n",
      "82 tabela\n",
      "10 tabelas\n",
      "13 tadeu\n",
      "7 taiane\n",
      "31 tais\n",
      "7 taise\n",
      "60 tal\n",
      "20 tamanho\n",
      "42 tambem\n",
      "21 tania\n",
      "51 tanto\n",
      "310 tarde\n",
      "561 tarefa\n",
      "24 tarefas\n",
      "48 tarif\n",
      "41 tarifa\n",
      "19 tarifacao\n",
      "15 tarifada\n",
      "8 tarifadas\n",
      "181 tarifado\n",
      "37 tarifados\n",
      "7 tarifando\n",
      "12 tarifario\n",
      "23 task\n",
      "14 tatiana\n",
      "17 tatiane\n",
      "51 tavares\n",
      "23 taxa\n",
      "14 tb\n",
      "97 tc\n",
      "11 tced\n",
      "8 tceprbu\n",
      "34 tcs\n",
      "26 tdm\n",
      "15 tec\n",
      "105 tecle\n",
      "32 tecnica\n",
      "17 tecnico\n",
      "43 tecnicos\n",
      "44 tecnologia\n",
      "14 teis\n",
      "90 teixeira\n",
      "272 tel\n",
      "662 tela\n",
      "206 telas\n",
      "15 tele\n",
      "10 telecine\n",
      "70 telecom\n",
      "18 telecomunicacoes\n",
      "16 telef\n",
      "464 telefone\n",
      "66 telefones\n",
      "13 telefonica\n",
      "131 telemar\n",
      "18 teles\n",
      "40 televendas\n",
      "10 telr\n",
      "7 teminal\n",
      "15 template\n",
      "74 tempo\n",
      "22 tempor\n",
      "18 temporariamente\n",
      "7 tenata\n",
      "255 tenta\n",
      "24 tentado\n",
      "7 tentam\n",
      "109 tentamos\n",
      "346 tentando\n",
      "501 tentar\n",
      "39 tentarmos\n",
      "223 tentativa\n",
      "53 tentativas\n",
      "20 tentato\n",
      "73 tente\n",
      "25 tentei\n",
      "31 tento\n",
      "90 tentou\n",
      "11 teodoro\n",
      "13 ter\n",
      "15 terceiro\n",
      "13 terceiros\n",
      "21 terem\n",
      "10 teresa\n",
      "22 teresinha\n",
      "11 tereza\n",
      "51 terezinha\n",
      "85 term\n",
      "27 termina\n",
      "443 terminais\n",
      "1209 terminal\n",
      "7 terminar\n",
      "21 termo\n",
      "11 termos\n",
      "13 terra\n",
      "102 testar\n",
      "51 teste\n",
      "15 testes\n",
      "9 tffd\n",
      "28 thais\n",
      "11 the\n",
      "69 thiago\n",
      "16 tht\n",
      "233 tiago\n",
      "594 tica\n",
      "32 ticas\n",
      "183 tico\n",
      "16 tijuca\n",
      "64 tim\n",
      "13 time\n",
      "17 timeout\n",
      "180 tipo\n",
      "18 tipodaos\n",
      "9 tirado\n",
      "26 tirar\n",
      "680 titular\n",
      "7 titulares\n",
      "93 titularidade\n",
      "10 tlm\n",
      "1582 tlmoi\n",
      "14 tlmpackageoriginalid\n",
      "22 tlv\n",
      "11 tm\n",
      "1356 tmapw\n",
      "11 tmarq\n",
      "524 tn\n",
      "8 tns\n",
      "77 to\n",
      "7 tocantins\n",
      "8 todo\n",
      "14 todvrgratis\n",
      "48 token\n",
      "20 toolkit\n",
      "62 top\n",
      "25 tor\n",
      "36 torpedo\n",
      "21 torpedos\n",
      "11 torre\n",
      "28 torres\n",
      "12 tot\n",
      "7 tota\n",
      "4316 total\n",
      "7 totalcinema\n",
      "14 totalmente\n",
      "8 tpa\n",
      "346 tr\n",
      "62 tra\n",
      "10 traas\n",
      "78 trabalho\n",
      "17 tradu\n",
      "140 traducao\n",
      "8 trafegar\n",
      "21 trafego\n",
      "18 tramit\n",
      "208 tramita\n",
      "16 tramitacao\n",
      "48 tramitada\n",
      "11 tramitadas\n",
      "21 tramitado\n",
      "86 tramitando\n",
      "276 tramitar\n",
      "28 tramitaram\n",
      "264 tramite\n",
      "359 tramitou\n",
      "8 trans\n",
      "18 transa\n",
      "14 transact\n",
      "67 transfer\n",
      "10 transfere\n",
      "39 transferencia\n",
      "14 transferidor\n",
      "9 transferir\n",
      "25 transmiss\n",
      "16 transporte\n",
      "20 transportes\n",
      "33 trat\n",
      "252 trata\n",
      "41 tratada\n",
      "55 tratadas\n",
      "52 tratado\n",
      "21 tratados\n",
      "10 tratam\n",
      "467 tratamento\n",
      "10 tratamentos\n",
      "12 tratamos\n",
      "15 tratando\n",
      "553 tratar\n",
      "268 tratativa\n",
      "19 tratativas\n",
      "128 tratconv\n",
      "32 trava\n",
      "135 travada\n",
      "16 travadas\n",
      "368 travado\n",
      "12 travando\n",
      "11 traz\n",
      "8 trazendo\n",
      "14 tres\n",
      "36 tria\n",
      "34 tribunal\n",
      "13 tridigito\n",
      "31 trigger\n",
      "15 trindade\n",
      "9 trl\n",
      "245 troca\n",
      "7 trocado\n",
      "48 trocar\n",
      "16 trocou\n",
      "35 tronco\n",
      "9 trunc\n",
      "18 tsa\n",
      "467 tt\n",
      "40 tts\n",
      "17 tulo\n",
      "19 turbo\n",
      "16 turismo\n",
      "2351 tv\n",
      "48 tvas\n",
      "20 tvspdcrc\n",
      "17 tx\n",
      "60 txt\n",
      "10 type\n",
      "12 udr\n",
      "293 uf\n",
      "39 ufacp\n",
      "11 uffd\n",
      "15 uffps\n",
      "15 uffpsel\n",
      "11 ufs\n",
      "42 ug\n",
      "30 ultima\n",
      "13 ultimapendencia\n",
      "10 ultimas\n",
      "15 ultimo\n",
      "9 un\n",
      "69 unica\n",
      "9 unico\n",
      "151 unid\n",
      "121 unidade\n",
      "17 unifica\n",
      "10 unificada\n",
      "16 unificado\n",
      "10 universidade\n",
      "15 unix\n",
      "72 up\n",
      "10 update\n",
      "44 upgrade\n",
      "42 ur\n",
      "44 ura\n",
      "107 urg\n",
      "177 urgencia\n",
      "65 urgente\n",
      "15 url\n",
      "8 usa\n",
      "40 usado\n",
      "39 usados\n",
      "24 usando\n",
      "32 usar\n",
      "9 user\n",
      "75 uso\n",
      "95 usos\n",
      "1096 usu\n",
      "60 usuaria\n",
      "157 usuario\n",
      "175 utcd\n",
      "8 utcdc\n",
      "27 utce\n",
      "17 uteis\n",
      "77 utiliza\n",
      "18 utilizada\n",
      "82 utilizado\n",
      "17 utilizados\n",
      "31 utilizando\n",
      "69 utilizar\n",
      "17 utilize\n",
      "10 utilizo\n",
      "20 utilizou\n",
      "100 uv\n",
      "69 vaga\n",
      "13 vagner\n",
      "132 vago\n",
      "17 vagos\n",
      "136 vai\n",
      "23 val\n",
      "14 valdir\n",
      "40 vale\n",
      "24 valeria\n",
      "15 valerio\n",
      "10 valid\n",
      "175 valida\n",
      "9 validado\n",
      "42 validar\n",
      "33 valido\n",
      "8 validos\n",
      "350 valor\n",
      "92 valores\n",
      "12 valter\n",
      "11 value\n",
      "23 vamos\n",
      "8 vanda\n",
      "9 vanderlei\n",
      "42 vanessa\n",
      "18 vania\n",
      "133 varejo\n",
      "7 varela\n",
      "24 vargas\n",
      "31 varias\n",
      "27 varios\n",
      "33 vasconcelos\n",
      "28 vaz\n",
      "7 vazio\n",
      "7 vazios\n",
      "106 vc\n",
      "11 vca\n",
      "39 vcoinr\n",
      "37 vctotal\n",
      "10 vdsl\n",
      "13 ve\n",
      "24 veiculos\n",
      "14 veiga\n",
      "37 veio\n",
      "148 veis\n",
      "20 veja\n",
      "1322 vel\n",
      "285 velocidade\n",
      "18 velocidades\n",
      "12 veloso\n",
      "816 velox\n",
      "57 vem\n",
      "19 venc\n",
      "33 venceu\n",
      "394 vencida\n",
      "19 vencidas\n",
      "19 vencido\n",
      "150 vencimento\n",
      "10 vencimentos\n",
      "28 vend\n",
      "552 venda\n",
      "113 vendas\n",
      "193 vende\n",
      "302 vendedor\n",
      "135 vendedora\n",
      "8 vendedores\n",
      "7 vendendor\n",
      "9 vender\n",
      "7 venho\n",
      "32 vera\n",
      "9 verde\n",
      "20 verficar\n",
      "17 vericar\n",
      "14 verif\n",
      "22 verifcar\n",
      "809 verifica\n",
      "14 verificada\n",
      "237 verificado\n",
      "94 verificamos\n",
      "46 verificando\n",
      "1085 verificar\n",
      "22 verificarem\n",
      "19 verificou\n",
      "67 verifique\n",
      "20 verifiquei\n",
      "193 verifiquem\n",
      "22 veriricar\n",
      "14 veronica\n",
      "12 vers\n",
      "61 vetor\n",
      "58 vezes\n",
      "10 vga\n",
      "16 vi\n",
      "294 via\n",
      "324 viabilidade\n",
      "13 viagem\n",
      "12 viagens\n",
      "37 viana\n",
      "16 vicente\n",
      "20 victor\n",
      "47 vida\n",
      "15 vidas\n",
      "186 vide\n",
      "121 vieira\n",
      "12 view\n",
      "48 vig\n",
      "9 vigencia\n",
      "25 vigente\n",
      "22 vila\n",
      "12 vilela\n",
      "22 vilma\n",
      "8 vilmar\n",
      "14 vimos\n",
      "20 vincula\n",
      "116 vinculada\n",
      "20 vinculadas\n",
      "239 vinculado\n",
      "63 vinculados\n",
      "34 vincular\n",
      "22 vinculo\n",
      "9 vinculou\n",
      "52 vinicius\n",
      "57 vip\n",
      "8 vira\n",
      "7 vire\n",
      "8 virginia\n",
      "7 virou\n",
      "22 virtual\n",
      "20 virtude\n",
      "9 vis\n",
      "20 visita\n",
      "43 vista\n",
      "163 visto\n",
      "98 visualiza\n",
      "16 visualizado\n",
      "17 visualizando\n",
      "194 visualizar\n",
      "9 vite\n",
      "36 vitor\n",
      "8 vitoria\n",
      "160 vitria\n",
      "27 viviane\n",
      "266 vivo\n",
      "9 vizualizar\n",
      "7 vl\n",
      "13 vlox\n",
      "8 vlr\n",
      "21 vm\n",
      "10 vmp\n",
      "45 voc\n",
      "34 voice\n",
      "78 volta\n",
      "16 voltando\n",
      "21 voltar\n",
      "9 voltaram\n",
      "51 volte\n",
      "16 voltem\n",
      "20 voltou\n",
      "41 volume\n",
      "71 volumetria\n",
      "8 vossa\n",
      "16 vou\n",
      "519 voz\n",
      "68 vpn\n",
      "12 vrd\n",
      "18 vta\n",
      "13 vva\n",
      "18 vw\n",
      "25 wagner\n",
      "54 wainting\n",
      "51 waiting\n",
      "7 wal\n",
      "10 walter\n",
      "9 wanderson\n",
      "52 web\n",
      "17 webservice\n",
      "12 webshare\n",
      "41 wedo\n",
      "20 wellington\n",
      "26 wesley\n",
      "23 wf\n",
      "8 wfl\n",
      "614 wfm\n",
      "7 white\n",
      "17 william\n",
      "20 willian\n",
      "7 wilma\n",
      "17 wilson\n",
      "51 wll\n",
      "8 wllgatprdd\n",
      "66 wllprd\n",
      "49 wllpx\n",
      "11 woi\n",
      "9 woiprd\n",
      "9 word\n",
      "14 workflow\n",
      "35 xavier\n",
      "11 xfb\n",
      "32 xima\n",
      "10 ximo\n",
      "23 ximos\n",
      "52 xlsx\n",
      "33 xml\n",
      "11 xmlns\n",
      "45 xx\n",
      "12 xxx\n",
      "15 xxxx\n",
      "71 yahoo\n",
      "7 yuri\n",
      "611 zc\n",
      "9 zelia\n",
      "28 zerada\n",
      "12 zerado\n",
      "10 zero\n",
      "11 zga\n",
      "10 zilda\n",
      "7 zip\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sum up the counts of each vocabulary word\n",
    "dist = np.sum(train_features, axis=0)\n",
    "\n",
    "# For each, print the vocabulary word and the number of times it \n",
    "# appears in the training set\n",
    "for tag, count in zip(vocab, dist):\n",
    "    print count, tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Random Forest\n",
    "At this point, we have numeric training features from the Bag of Words and the original sentiment labels for each feature vector, so let's do some supervised learning! Here, we'll use the Random Forest classifier that we introduced in the Titanic tutorial.  The Random Forest algorithm is included in scikit-learn (Random Forest uses many tree-based classifiers to make predictions, hence the \"forest\"). Below, we set the number of trees to 100 as a reasonable default value. More trees may (or may not) perform better, but will certainly take longer to run. Likewise, the more features you include for each review, the longer this will take."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/.local/lib/python2.7/site-packages/sklearn/cross_validation.py:552: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=10.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0xc3 in position 405: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-f9925d94b6de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m cv_results = cross_validation.cross_val_score(RandomForestClassifier(n_estimators=100), \n\u001b[1;32m      2\u001b[0m                                               \u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                                               scoring=\"accuracy\", n_jobs = -1)\n\u001b[0m",
      "\u001b[0;32m/home/rodrigo/.local/lib/python2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m   1569\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1570\u001b[0m                                               fit_params)\n\u001b[0;32m-> 1571\u001b[0;31m                       for train, test in cv)\n\u001b[0m\u001b[1;32m   1572\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rodrigo/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rodrigo/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    694\u001b[0m                     \u001b[0;31m# stack in addition to the distant stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m                     this_report = format_outer_frames(context=10,\n\u001b[0;32m--> 696\u001b[0;31m                                                       stack_start=1)\n\u001b[0m\u001b[1;32m    697\u001b[0m                     report = \"\"\"Multiprocessing exception:\n\u001b[1;32m    698\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rodrigo/.local/lib/python2.7/site-packages/sklearn/externals/joblib/format_stack.pyc\u001b[0m in \u001b[0;36mformat_outer_frames\u001b[0;34m(context, stack_start, stack_end, ignore_ipython)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0mbuf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLINES_POS\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstack_end\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstack_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xc3 in position 405: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "cv_results = cross_validation.cross_val_score(RandomForestClassifier(n_estimators=100), \n",
    "                                              train_features, train.text, cv=10, \n",
    "                                              scoring=\"accuracy\", n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create function to report results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the parameters to search for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_dist = {\"n_estimators\":[100, 400],\n",
    "              \"max_depth\": [3, None],\n",
    "              \"max_features\": sp_randint(1, 11),\n",
    "              \"min_samples_split\": sp_randint(5, 11),\n",
    "              \"min_samples_leaf\": sp_randint(5, 11),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a randomized parameter search to train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(forest, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/.local/lib/python2.7/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "random_search.fit(train_features, train.text)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the random forest...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "fit() got an unexpected keyword argument 'njobs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-1fb06b82f325>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# This may take a few minutes to run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mforest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnjobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: fit() got an unexpected keyword argument 'njobs'"
     ]
    }
   ],
   "source": [
    "print \"Training the random forest...\"\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize a Random Forest classifier with 100 trees\n",
    "forest = RandomForestClassifier(n_estimators = 100) \n",
    "\n",
    "# Fit the forest to the training set, using the bag of words as \n",
    "# features and the sentiment labels as the response variable\n",
    "#\n",
    "# This may take a few minutes to run\n",
    "forest = forest.fit( train_features, data[\"text\"], njobs = -1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Submission\n",
    "All that remains is to run the trained Random Forest on our test set and create a submission file. If you haven't already done so, download testData.tsv from the Data page. This file contains another 25,000 reviews and ids; our task is to predict the sentiment label.\n",
    "\n",
    "Note that when we use the Bag of Words for the test set, we only call \"transform\", not \"fit_transform\" as we did for the training set. In machine learning, you shouldn't use the test set to fit your model, otherwise you run the risk of overfitting. For this reason, we keep the test set off-limits until we are ready to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2)\n",
      "Cleaning and parsing the test set movie reviews...\n",
      "\n",
      "Review 1000 of 25000\n",
      "\n",
      "Review 2000 of 25000\n",
      "\n",
      "Review 3000 of 25000\n",
      "\n",
      "Review 4000 of 25000\n",
      "\n",
      "Review 5000 of 25000\n",
      "\n",
      "Review 6000 of 25000\n",
      "\n",
      "Review 7000 of 25000\n",
      "\n",
      "Review 8000 of 25000\n",
      "\n",
      "Review 9000 of 25000\n",
      "\n",
      "Review 10000 of 25000\n",
      "\n",
      "Review 11000 of 25000\n",
      "\n",
      "Review 12000 of 25000\n",
      "\n",
      "Review 13000 of 25000\n",
      "\n",
      "Review 14000 of 25000\n",
      "\n",
      "Review 15000 of 25000\n",
      "\n",
      "Review 16000 of 25000\n",
      "\n",
      "Review 17000 of 25000\n",
      "\n",
      "Review 18000 of 25000\n",
      "\n",
      "Review 19000 of 25000\n",
      "\n",
      "Review 20000 of 25000\n",
      "\n",
      "Review 21000 of 25000\n",
      "\n",
      "Review 22000 of 25000\n",
      "\n",
      "Review 23000 of 25000\n",
      "\n",
      "Review 24000 of 25000\n",
      "\n",
      "Review 25000 of 25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read the test data\n",
    "test = pd.read_csv(\"testData.tsv\", header=0, delimiter=\"\\t\", \\\n",
    "                   quoting=3 )\n",
    "\n",
    "# Verify that there are 25,000 rows and 2 columns\n",
    "print test.shape\n",
    "\n",
    "# Create an empty list and append the clean reviews one by one\n",
    "num_reviews = len(test[\"review\"])\n",
    "clean_test_reviews = [] \n",
    "\n",
    "print \"Cleaning and parsing the test set movie reviews...\\n\"\n",
    "for i in xrange(0,num_reviews):\n",
    "    if( (i+1) % 1000 == 0 ):\n",
    "        print \"Review %d of %d\\n\" % (i+1, num_reviews)\n",
    "    clean_review = review_to_words( test[\"review\"][i] )\n",
    "    clean_test_reviews.append( clean_review )\n",
    "\n",
    "# Get a bag of words for the test set, and convert to a numpy array\n",
    "test_data_features = vectorizer.transform(clean_test_reviews)\n",
    "test_data_features = test_data_features.toarray()\n",
    "\n",
    "# Use the random forest to make sentiment label predictions\n",
    "result = forest.predict(test_data_features)\n",
    "\n",
    "# Copy the results to a pandas dataframe with an \"id\" column and\n",
    "# a \"sentiment\" column\n",
    "output = pd.DataFrame( data={\"id\":test[\"id\"], \"sentiment\":result} )\n",
    "\n",
    "# Use pandas to write the comma-separated output file\n",
    "output.to_csv( \"Bag_of_Words_model.csv\", index=False, quoting=3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, you are ready to make your first submission! Try different things and see how your results change. You can clean the reviews differently, choose a different number of vocabulary words for the Bag of Words representation, try Porter Stemming, a different classifier, or any number of other things. To try out your NLP chops on a different data set, you can also head over to our Rotten Tomatoes competition. Or, if you're ready for something completely different, move along to the Deep Learning and Word Vector pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing to Train a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now down to the nitty-gritty! First, we read in the data with pandas, as we did in Part 1. Unlike Part 1, we now use unlabeledTrain.tsv, which contains 50,000 additional reviews with no labels. When we built the Bag of Words model in Part 1, extra unlabeled training reviews were not useful. However, since Word2Vec can learn from unlabeled data, these extra 50,000 reviews can now be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read data from files \n",
    "train = pd.read_csv( \"labeledTrainData.tsv\", header=0, \n",
    " delimiter=\"\\t\", quoting=3, encoding=\"utf-8\") \n",
    "test = pd.read_csv( \"testData.tsv\", header=0, delimiter=\"\\t\", quoting=3 , encoding=\"utf-8\")\n",
    "unlabeled_train = pd.read_csv( \"unlabeledTrainData.tsv\", header=0, \n",
    " delimiter=\"\\t\", quoting=3 , encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Verify the number of reviews that were read (100,000 in total)\n",
    "print \"Read %d labeled train reviews, %d labeled test reviews, \" \\\n",
    " \"and %d unlabeled reviews\\n\" % (train[\"review\"].size,  \n",
    " test[\"review\"].size, unlabeled_train[\"review\"].size )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions we write to clean the data are also similar to Part 1, although now there are a couple of differences. First, to train Word2Vec it is better not to remove stop words because the algorithm relies on the broader context of the sentence in order to produce high-quality word vectors. For this reason, we will make stop word removal optional in the functions below. It also might be better not to remove numbers, but we leave that as an exercise for the reader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import various modules for string cleaning\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def review_to_wordlist( review, remove_stopwords=False ):\n",
    "    # Function to convert a document to a sequence of words,\n",
    "    # optionally removing stop words.  Returns a list of words.\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(review).get_text()\n",
    "    #  \n",
    "    # 2. Remove non-letters\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    #\n",
    "    # 3. Convert words to lower case and split them\n",
    "    words = review_text.lower().split()\n",
    "    #\n",
    "    # 4. Optionally remove stop words (false by default)\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    #\n",
    "    # 5. Return a list of words\n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want a specific input format. Word2Vec expects single sentences, each one as a list of words. In other words, the input format is a list of lists.\n",
    "\n",
    "It is not at all straightforward how to split a paragraph into sentences. There are all kinds of gotchas in natural language. English sentences can end with \"?\", \"!\", \"\"\", or \".\", among other things, and spacing and capitalization are not reliable guides either. For this reason, we'll use NLTK's punkt tokenizer for sentence splitting. In order to use this, you will need to install NLTK and use nltk.download() to download the relevant training file for punkt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Download the punkt tokenizer for sentence splitting\n",
    "import nltk.data\n",
    "#nltk.download()   \n",
    "# Load the punkt tokenizer\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a function to split a review into parsed sentences\n",
    "def review_to_sentences( review, tokenizer, remove_stopwords=False ):\n",
    "    # Function to split a review into parsed sentences. Returns a \n",
    "    # list of sentences, where each sentence is a list of words\n",
    "    #\n",
    "    # 1. Use the NLTK tokenizer to split the paragraph into sentences\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "    #\n",
    "    # 2. Loop over each sentence\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        # If a sentence is empty, skip it\n",
    "        if len(raw_sentence) > 0:\n",
    "            # Otherwise, call review_to_wordlist to get a list of words\n",
    "            sentences.append( review_to_wordlist( raw_sentence, \\\n",
    "              remove_stopwords ))\n",
    "    #\n",
    "    # Return the list of sentences (each sentence is a list of words,\n",
    "    # so this returns a list of lists\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can apply this function to prepare our data for input to Word2Vec (this will take a couple minutes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "sentences = []  # Initialize an empty list of sentences\n",
    "\n",
    "print \"Parsing sentences from training set\"\n",
    "for review in train[\"review\"]:\n",
    "    sentences += review_to_sentences(review, tokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Parsing sentences from unlabeled set\"\n",
    "for review in unlabeled_train[\"review\"]:\n",
    "    sentences += review_to_sentences(review, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can apply this function to prepare our data for input to Word2Vec (this will take a couple minutes):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may get a few warnings from BeautifulSoup about URLs in the sentences. These are nothing to worry about (although you may want to consider removing URLs when cleaning the text). \n",
    "\n",
    "We can take a look at the output to see how this differs from Part 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Saving Your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the list of nicely parsed sentences, we're ready to train the model. There are a number of parameter choices that affect the run time and the quality of the final model that is produced. For details on the algorithms below, see the word2vec API documentation as well as the Google documentation. \n",
    "\n",
    "    Architecture: Architecture options are skip-gram (default) or continuous bag of words. We found that skip-gram was very slightly slower but produced better results.\n",
    "    Training algorithm: Hierarchical softmax (default) or negative sampling. For us, the default worked well.\n",
    "    Downsampling of frequent words: The Google documentation recommends values between .00001 and .001. For us, values closer 0.001 seemed to improve the accuracy of the final model.\n",
    "    Word vector dimensionality: More features result in longer runtimes, and often, but not always, result in better models. Reasonable values can be in the tens to hundreds; we used 300.\n",
    "    Context / window size: How many words of context should the training algorithm take into account? 10 seems to work well for hierarchical softmax (more is better, up to a point).\n",
    "    Worker threads: Number of parallel processes to run. This is computer-specific, but between 4 and 6 should work on most systems.\n",
    "    Minimum word count: This helps limit the size of the vocabulary to meaningful words. Any word that does not occur at least this many times across all documents is ignored. Reasonable values could be between 10 and 100. In this case, since each movie occurs 30 times, we set the minimum word count to 40, to avoid attaching too much importance to individual movie titles. This resulted in an overall vocabulary size of around 15,000 words. Higher values also help limit run time.\n",
    "\n",
    "Choosing parameters is not easy, but once we have chosen our parameters, creating a Word2Vec model is straightforward:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the built-in logging module and configure it so that Word2Vec \n",
    "# creates nice output messages\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "    level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set values for various parameters\n",
    "num_features = 300    # Word vector dimensionality                      \n",
    "min_word_count = 40   # Minimum word count                        \n",
    "num_workers = 8       # Number of threads to run in parallel\n",
    "context = 10          # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Initialize and train the model (this will take some time)\n",
    "from gensim.models import word2vec\n",
    "print \"Training model...\"\n",
    "model = word2vec.Word2Vec(sentences, workers=num_workers, \\\n",
    "            size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If you don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# It can be helpful to create a meaningful model name and \n",
    "# save the model for later use. You can load it later using Word2Vec.load()\n",
    "model_name = \"300features_40minwords_10context\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a dual-core Macbook Pro, this took less than 15 minutes to run using 4 worker threads. However, it will vary depending on your computer. Fortunately, the logging functionality prints informative messages.\n",
    "\n",
    "If you are on a Mac or Linux system, you can use the \"top\" command from within Terminal (not from within Python) to see if your system is successfully parallelizing while the model is training. Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the Model Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations on making it successfully through everything so far! Let's take a look at the model we created out of our 75,000 training reviews.\n",
    "\n",
    "The \"doesnt_match\" function will try to deduce which word in a set is most dissimilar from the others:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kitchen'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"man woman child kitchen\".split())\n",
    "'kitchen'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is capable of distinguishing differences in meaning! It knows that men, women and children are more similar to each other than they are to kitchens. More exploration shows that the model is sensitive to more subtle differences in meaning, such as differences between countries and cities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'berlin'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"france england germany berlin\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... although with the relatively small training set we used, it's certainly not perfect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'paris'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"paris berlin london austria\".split())\n",
    "'paris'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the \"most_similar\" function to get insight into the model's word clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'woman', 0.6322274208068848),\n",
       " (u'lady', 0.5871136784553528),\n",
       " (u'lad', 0.5658714175224304),\n",
       " (u'men', 0.5298689603805542),\n",
       " (u'monk', 0.5283631086349487),\n",
       " (u'businessman', 0.5234595537185669),\n",
       " (u'millionaire', 0.5194512605667114),\n",
       " (u'soldier', 0.5185883641242981),\n",
       " (u'guy', 0.5120233297348022),\n",
       " (u'person', 0.5120117664337158)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"man\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'princess', 0.6948347687721252),\n",
       " (u'bride', 0.6394442319869995),\n",
       " (u'goddess', 0.6107475161552429),\n",
       " (u'mistress', 0.6015448570251465),\n",
       " (u'mary', 0.5880306363105774),\n",
       " (u'eva', 0.5803037881851196),\n",
       " (u'angela', 0.5779411792755127),\n",
       " (u'duchess', 0.5745822787284851),\n",
       " (u'dame', 0.5716529488563538),\n",
       " (u'maid', 0.570807695388794)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"queen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given our particular training set, it's not surprising that \"Latifah\" is a top hit for similarity with \"Queen\".\n",
    "\n",
    "Or, more relevant for sentiment analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'terrible', 0.7888780832290649),\n",
       " (u'atrocious', 0.7586556673049927),\n",
       " (u'horrible', 0.7239440679550171),\n",
       " (u'horrendous', 0.7101829648017883),\n",
       " (u'dreadful', 0.7024926543235779),\n",
       " (u'abysmal', 0.6903165578842163),\n",
       " (u'horrid', 0.6864355206489563),\n",
       " (u'appalling', 0.6766446232795715),\n",
       " (u'crappy', 0.6405069828033447),\n",
       " (u'lousy', 0.638817548751831)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"awful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems we have a reasonably good model for semantic meaning - at least as good as Bag of Words. But how can we use these fancy distributed word vectors for supervised learning? The next section takes a stab at that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: More Fun With Word Vectors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numeric Representations of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a trained model with some semantic understanding of words, how should we use it? If you look beneath the hood, the Word2Vec model trained in Part 2 consists of a feature vector for each word in the vocabulary, stored in a numpy array called \"syn0\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the model that we created in Part 2\n",
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec.load(\"300features_40minwords_10context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.syn0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16490, 300)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.syn0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of rows in syn0 is the number of words in the model's vocabulary, and the number of columns corresponds to the size of the feature vector, which we set in Part 2.  Setting the minimum word count to 40 gave us a total vocabulary of 16,492 words with 300 features apiece. Individual word vectors can be accessed in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -3.55882496e-02,   2.47471277e-02,  -1.04208276e-01,\n",
       "         3.29137072e-02,   2.55899355e-02,   1.74981821e-02,\n",
       "         7.12182969e-02,  -1.42839095e-02,   1.58416592e-02,\n",
       "         9.37454402e-02,  -5.58592677e-02,  -9.29856598e-02,\n",
       "         3.26889344e-02,   1.06930472e-01,   1.85630401e-03,\n",
       "         1.11467671e-02,  -6.41966760e-02,  -2.04013456e-02,\n",
       "        -4.45806980e-02,  -6.75038025e-02,  -1.59813195e-01,\n",
       "        -2.08285563e-02,   1.11681387e-01,   7.89937824e-02,\n",
       "        -6.63784519e-02,  -1.86357126e-02,  -6.04835339e-02,\n",
       "        -7.14961141e-02,  -4.50195335e-02,  -2.05224138e-02,\n",
       "         3.61643173e-02,   9.60387886e-02,  -5.84295951e-02,\n",
       "         6.81338832e-02,  -9.61724818e-02,  -6.60632912e-04,\n",
       "        -8.50417186e-03,  -1.10230200e-01,   7.37866983e-02,\n",
       "         5.62555194e-02,  -2.51879990e-02,  -3.53787579e-02,\n",
       "        -1.61538199e-02,  -1.98000092e-02,   2.87626851e-02,\n",
       "        -6.33075312e-02,  -8.02566037e-02,  -3.68730538e-02,\n",
       "         4.61276323e-02,   1.12826891e-01,  -1.10806301e-01,\n",
       "         3.16583477e-02,   9.68787745e-02,  -4.78281304e-02,\n",
       "        -4.02895249e-02,  -3.52558605e-02,   1.55202113e-04,\n",
       "        -3.63130048e-02,  -1.43808022e-01,   4.42711962e-03,\n",
       "        -4.91630882e-02,  -1.77957595e-03,   5.67717180e-02,\n",
       "        -3.83522324e-02,  -9.60825905e-02,   6.81047961e-02,\n",
       "         3.63117419e-02,   5.61665557e-02,   3.71133909e-02,\n",
       "        -1.26478430e-02,  -6.53350949e-02,   8.99698865e-03,\n",
       "         3.25958407e-03,   1.46788033e-02,   3.01092640e-02,\n",
       "        -3.41891125e-02,  -5.50497361e-02,   3.73913646e-02,\n",
       "        -1.00466115e-02,   8.90686810e-02,   6.13426929e-03,\n",
       "         9.22860131e-02,   8.41703918e-03,  -1.25936776e-01,\n",
       "        -7.89619342e-04,  -3.82772870e-02,   5.67331575e-02,\n",
       "        -6.38181418e-02,   9.06023849e-03,   6.16012923e-02,\n",
       "        -6.06720746e-02,  -8.06147326e-03,  -3.72956885e-04,\n",
       "         5.19216955e-02,  -5.44601083e-02,  -3.51979248e-02,\n",
       "         7.26705790e-02,   2.23731669e-03,   4.48953360e-02,\n",
       "        -7.71032125e-02,  -1.06344307e-02,  -6.93584830e-02,\n",
       "         2.52024252e-02,  -9.72983018e-02,   2.93030590e-02,\n",
       "        -1.56248882e-01,  -3.70237827e-02,   6.73727319e-02,\n",
       "        -5.12270890e-02,  -1.60797134e-01,   3.43241543e-02,\n",
       "         5.93282981e-03,   1.59055933e-01,   2.00582650e-02,\n",
       "         5.54605983e-02,   2.42288113e-02,   7.22672716e-02,\n",
       "        -2.96430220e-03,   6.96482360e-02,   1.04704835e-01,\n",
       "         3.02894805e-02,   6.70118406e-02,  -2.81544216e-02,\n",
       "         7.29399323e-02,   3.37951556e-02,   7.13070156e-03,\n",
       "        -9.92850140e-02,   9.61361546e-03,   5.11280149e-02,\n",
       "         4.22588177e-02,   8.10209755e-03,  -1.09061738e-03,\n",
       "        -7.76890293e-02,  -3.46188061e-02,   1.34196421e-02,\n",
       "        -6.40526563e-02,  -8.23103786e-02,   2.44062040e-02,\n",
       "         1.25887990e-02,   9.38936695e-03,  -5.03795817e-02,\n",
       "         3.32552032e-03,  -3.43791284e-02,  -1.42201800e-02,\n",
       "         1.38962477e-01,  -1.03612412e-02,  -2.51625571e-02,\n",
       "         3.30625959e-02,  -4.99621741e-02,  -1.99146885e-02,\n",
       "         2.27263626e-02,  -1.37947993e-02,   5.35124466e-02,\n",
       "        -2.13138368e-02,   3.81628126e-02,   6.00395165e-02,\n",
       "        -9.40183997e-02,   4.64383997e-02,   6.40595704e-02,\n",
       "        -1.88648887e-02,  -5.72695062e-02,   8.58328715e-02,\n",
       "         2.68947389e-02,  -4.49149460e-02,  -4.95724566e-02,\n",
       "        -3.81453410e-02,  -5.25868274e-02,   4.20970023e-02,\n",
       "         4.30612825e-03,  -3.16251558e-03,  -7.42969811e-02,\n",
       "        -7.17648119e-02,  -2.11895574e-02,  -3.29929553e-02,\n",
       "         7.43309706e-02,   2.93748267e-02,  -7.64147267e-02,\n",
       "        -1.39336120e-02,   4.30943780e-02,  -4.05436642e-02,\n",
       "        -5.21518961e-02,  -4.67929468e-02,  -9.57569852e-02,\n",
       "        -3.45414095e-02,   4.56543751e-02,  -4.96648885e-02,\n",
       "         6.47902712e-02,  -1.09537117e-01,  -3.01021263e-02,\n",
       "        -5.76988794e-02,  -2.06429083e-02,  -5.73864058e-02,\n",
       "         1.38882454e-02,   8.62225331e-03,   7.58093819e-02,\n",
       "        -3.66315022e-02,  -2.12668721e-02,   2.15990487e-02,\n",
       "        -3.21666859e-02,   4.98779342e-02,   5.44862039e-02,\n",
       "        -2.67323270e-03,   2.70017143e-02,   1.29934018e-02,\n",
       "         7.21630380e-02,  -7.41390511e-02,  -8.98320079e-02,\n",
       "        -5.95589355e-02,   4.37078401e-02,   3.35343517e-02,\n",
       "        -4.02515046e-02,   3.59163433e-02,   5.97494794e-03,\n",
       "         4.70575094e-02,   3.90465595e-02,   2.56752651e-02,\n",
       "         1.86664872e-02,   2.13174466e-02,   7.76682347e-02,\n",
       "         3.57806496e-02,   8.86230394e-02,   3.34956795e-02,\n",
       "         3.75167541e-02,  -3.40588503e-02,   4.05320227e-02,\n",
       "        -5.96539229e-02,  -1.16136409e-02,  -4.03795727e-02,\n",
       "         2.83653308e-02,  -9.74851698e-02,   4.23166715e-03,\n",
       "        -2.19235495e-02,   4.66139913e-02,  -5.44767082e-02,\n",
       "        -1.74504835e-02,  -2.72377990e-02,   7.87099451e-03,\n",
       "        -5.81324883e-02,   3.79459560e-02,  -4.54776101e-02,\n",
       "         5.31399213e-02,   3.65951434e-02,  -2.69994903e-02,\n",
       "        -4.20414954e-02,   5.81425056e-03,  -2.17873976e-03,\n",
       "         5.61670475e-02,   1.80523936e-02,   5.16059995e-02,\n",
       "        -1.89411398e-02,   4.99554574e-02,  -1.73452199e-01,\n",
       "        -8.11168365e-03,   8.00325051e-02,   3.09167169e-02,\n",
       "         7.05138445e-02,   2.81192157e-02,  -4.04772460e-02,\n",
       "         4.82485071e-02,  -3.03900316e-02,   2.77718287e-02,\n",
       "        -2.99347639e-02,  -4.83625010e-02,   3.24691869e-02,\n",
       "        -1.30199073e-02,   4.38352562e-02,   1.05329327e-01,\n",
       "        -4.57907468e-02,  -1.88184604e-02,  -4.01927624e-03,\n",
       "        -4.49867286e-02,   7.14428127e-02,  -1.49682146e-02,\n",
       "         9.17007476e-02,   8.07429384e-03,  -8.74338076e-02,\n",
       "         4.05235700e-02,  -8.38367939e-02,  -8.38455185e-03,\n",
       "         2.78369524e-02,  -8.83844867e-02,   9.73052252e-03,\n",
       "         6.64622858e-02,  -2.72305161e-02,  -2.83894986e-02,\n",
       "         3.59206758e-02,  -1.57311093e-02,  -1.40985548e-01,\n",
       "        -1.39436973e-02,  -4.19071354e-02,  -2.50990260e-02,\n",
       "         3.58055793e-02,  -3.15005630e-02,   7.17863366e-02,\n",
       "        -8.48470554e-02,   1.39727769e-02,  -1.43942624e-01,\n",
       "         1.87910888e-02,   1.37729958e-01,   1.03993960e-01], dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[\"flower\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Words To Paragraphs, Attempt 1: Vector Averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One challenge with the IMDB dataset is the variable-length reviews. We need to find a way to take individual word vectors and transform them into a feature set that is the same length for every review.\n",
    "\n",
    "Since each word is a vector in 300-dimensional space, we can use vector operations to combine the words in each review. One method we tried was to simply average the word vectors in a given review (for this purpose, we removed stop words, which would just add noise).\n",
    "\n",
    "The following code averages the feature vectors, building on our code from Part 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np  # Make sure that numpy is imported\n",
    "\n",
    "def makeFeatureVec(words, model, num_features):\n",
    "    # Function to average all of the word vectors in a given\n",
    "    # paragraph\n",
    "    #\n",
    "    # Pre-initialize an empty numpy array (for speed)\n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    #\n",
    "    nwords = 0.\n",
    "    # \n",
    "    # Index2word is a list that contains the names of the words in \n",
    "    # the model's vocabulary. Convert it to a set, for speed \n",
    "    index2word_set = set(model.index2word)\n",
    "    #\n",
    "    # Loop over each word in the review and, if it is in the model's\n",
    "    # vocaublary, add its feature vector to the total\n",
    "    for word in words:\n",
    "        if word in index2word_set: \n",
    "            nwords = nwords + 1.\n",
    "            featureVec = np.add(featureVec,model[word])\n",
    "    # \n",
    "    # Divide the result by the number of words to get the average\n",
    "    featureVec = np.divide(featureVec,nwords)\n",
    "    return featureVec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getAvgFeatureVecs(reviews, model, num_features):\n",
    "    # Given a set of reviews (each one a list of words), calculate \n",
    "    # the average feature vector for each one and return a 2D numpy array \n",
    "    # \n",
    "    # Initialize a counter\n",
    "    counter = 0.\n",
    "    # \n",
    "    # Preallocate a 2D numpy array, for speed\n",
    "    reviewFeatureVecs = np.zeros((len(reviews),num_features),dtype=\"float32\")\n",
    "    # \n",
    "    # Loop through the reviews\n",
    "    for review in reviews:\n",
    "       #\n",
    "       # Print a status message every 1000th review\n",
    "       if counter%1000. == 0.:\n",
    "           print \"Review %d of %d\" % (counter, len(reviews))\n",
    "       # \n",
    "       # Call the function (defined above) that makes average feature vectors\n",
    "       reviewFeatureVecs[counter] = makeFeatureVec(review, model, \\\n",
    "           num_features)\n",
    "       #\n",
    "       # Increment the counter\n",
    "       counter = counter + 1.\n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can call these functions to create average vectors for each paragraph. The following operations will take a few minutes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ****************************************************************\n",
    "# Calculate average feature vectors for training and testing sets,\n",
    "# using the functions we defined above. Notice that we now use stop word\n",
    "# removal.\n",
    "\n",
    "clean_train_reviews = []\n",
    "for review in train[\"review\"]:\n",
    "    clean_train_reviews.append( review_to_wordlist( review, \\\n",
    "        remove_stopwords=True ))\n",
    "\n",
    "trainDataVecs = getAvgFeatureVecs( clean_train_reviews, model, num_features )\n",
    "\n",
    "print \"Creating average feature vecs for test reviews\"\n",
    "clean_test_reviews = []\n",
    "for review in test[\"review\"]:\n",
    "    clean_test_reviews.append( review_to_wordlist( review, \\\n",
    "        remove_stopwords=True ))\n",
    "\n",
    "testDataVecs = getAvgFeatureVecs( clean_test_reviews, model, num_features )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, use the average paragraph vectors to train a random forest. Note that, as in Part 1, we can only use the labeled training reviews to train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit a random forest to the training data, using 100 trees\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier( n_estimators = 100 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"Fitting a random forest to labeled training data...\"\n",
    "forest = forest.fit( trainDataVecs, train[\"sentiment\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test & extract results \n",
    "result = forest.predict( testDataVecs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write the test results \n",
    "output = pd.DataFrame( data={\"id\":test[\"id\"], \"sentiment\":result} )\n",
    "output.to_csv( \"Word2Vec_AverageVectors.csv\", index=False, quoting=3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that this produced results much better than chance, but underperformed Bag of Words by a few percentage points.\n",
    "\n",
    "Since the element-wise average of the vectors didn't produce spectacular results, perhaps we could do it in a more intelligent way? A standard way of weighting word vectors is to apply \"tf-idf\" weights, which measure how important a given word is within a given set of documents. One way to extract tf-idf weights in Python is by using scikit-learn's TfidfVectorizer, which has an interface similar to the CountVectorizer that we used in Part 1. However, when we tried weighting our word vectors in this way, we found no substantial improvement in performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Words to Paragraphs, Attempt 2: Clustering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec creates clusters of semantically related words, so another possible approach is to exploit the similarity of words within a cluster. Grouping vectors in this way is known as \"vector quantization.\" To accomplish this, we first need to find the centers of the word clusters, which we can do by using a clustering algorithm such as K-Means.\n",
    "\n",
    "In K-Means, the one parameter we need to set is \"K,\" or the number of clusters. How should we decide how many clusters to create? Trial and error suggested that small clusters, with an average of only 5 words or so per cluster, gave better results than large clusters with many words. Clustering code is given below. We use scikit-learn to perform our K-Means.\n",
    "\n",
    "K-Means clustering with large K can be very slow; the following code took more than 40 minutes on my computer. Below, we set a timer around the K-Means function to see how long it takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import time\n",
    "\n",
    "start = time.time() # Start time\n",
    "\n",
    "# Set \"k\" (num_clusters) to be 1/5th of the vocabulary size, or an\n",
    "# average of 5 words per cluster\n",
    "word_vectors = model.syn0\n",
    "num_clusters = word_vectors.shape[0] / 5\n",
    "\n",
    "# Initalize a k-means object and use it to extract centroids\n",
    "kmeans_clustering = KMeans( n_clusters = num_clusters )\n",
    "idx = kmeans_clustering.fit_predict( word_vectors )\n",
    "\n",
    "# Get the end time and print how long the process took\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print \"Time taken for K Means clustering: \", elapsed, \"seconds.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cluster assignment for each word is now stored in idx, and the vocabulary from our original Word2Vec model is still stored in model.index2word. For convenience, we zip these into one dictionary as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a Word / Index dictionary, mapping each vocabulary word to\n",
    "# a cluster number                                                                                            \n",
    "word_centroid_map = dict(zip( model.index2word, idx ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a little abstract, so let's take a closer look at what our clusters contain. Your clusters may differ, as Word2Vec relies on a random number seed. Here is a loop that prints out the words for clusters 0 through 9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For the first 10 clusters\n",
    "for cluster in xrange(0,10):\n",
    "    #\n",
    "    # Print the cluster number  \n",
    "    print \"\\nCluster %d\" % cluster\n",
    "    #\n",
    "    # Find all of the words for that cluster number, and print them out\n",
    "    words = []\n",
    "    for i in xrange(0,len(word_centroid_map.values())):\n",
    "        if( word_centroid_map.values()[i] == cluster ):\n",
    "            words.append(word_centroid_map.keys()[i])\n",
    "    print words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are very interesting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-101-ddaca8b2cd9f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-101-ddaca8b2cd9f>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Cluster 0\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Cluster 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cluster 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cluster 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cluster 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cluster 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cluster 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cluster 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cluster 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cluster 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cluster 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the clusters are of varying quality. Some make sense - Cluster 3 mostly contains names, and Clusters 6-8 contain related adjectives (Cluster 6 is my favorite). On the other hand, Cluster 5 is a little mystifying: What do a lobster and a deer have in common (besides being two animals)? Cluster 0 is even worse: Penthouses and suites seem to belong together, but they don't seem to belong with apples and passports. Cluster 2 contains ... maybe war-related words? Perhaps our algorithm works best on adjectives.\n",
    "\n",
    "At any rate, now we have a cluster (or \"centroid\") assignment for each word, and we can define a function to convert reviews into bags-of-centroids. This works just like Bag of Words but uses semantically related clusters instead of individual words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_bag_of_centroids( wordlist, word_centroid_map ):\n",
    "    #\n",
    "    # The number of clusters is equal to the highest cluster index\n",
    "    # in the word / centroid map\n",
    "    num_centroids = max( word_centroid_map.values() ) + 1\n",
    "    #\n",
    "    # Pre-allocate the bag of centroids vector (for speed)\n",
    "    bag_of_centroids = np.zeros( num_centroids, dtype=\"float32\" )\n",
    "    #\n",
    "    # Loop over the words in the review. If the word is in the vocabulary,\n",
    "    # find which cluster it belongs to, and increment that cluster count \n",
    "    # by one\n",
    "    for word in wordlist:\n",
    "        if word in word_centroid_map:\n",
    "            index = word_centroid_map[word]\n",
    "            bag_of_centroids[index] += 1\n",
    "    #\n",
    "    # Return the \"bag of centroids\"\n",
    "    return bag_of_centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function above will give us a numpy array for each review, each with a number of features equal to the number of clusters. Finally, we create bags of centroids for our training and test set, then train a random forest and extract results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pre-allocate an array for the training set bags of centroids (for speed)\n",
    "train_centroids = np.zeros( (train[\"review\"].size, num_clusters), \\\n",
    "    dtype=\"float32\" )\n",
    "\n",
    "# Transform the training set reviews into bags of centroids\n",
    "counter = 0\n",
    "for review in clean_train_reviews:\n",
    "    train_centroids[counter] = create_bag_of_centroids( review, \\\n",
    "        word_centroid_map )\n",
    "    counter += 1\n",
    "\n",
    "# Repeat for test reviews \n",
    "test_centroids = np.zeros(( test[\"review\"].size, num_clusters), \\\n",
    "    dtype=\"float32\" )\n",
    "\n",
    "counter = 0\n",
    "for review in clean_test_reviews:\n",
    "    test_centroids[counter] = create_bag_of_centroids( review, \\\n",
    "        word_centroid_map )\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit a random forest and extract predictions \n",
    "forest = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "# Fitting the forest may take a few minutes\n",
    "print \"Fitting a random forest to labeled training data...\"\n",
    "forest = forest.fit(train_centroids,train[\"sentiment\"])\n",
    "result = forest.predict(test_centroids)\n",
    "\n",
    "# Write the test results \n",
    "output = pd.DataFrame(data={\"id\":test[\"id\"], \"sentiment\":result})\n",
    "output.to_csv( \"BagOfCentroids.csv\", index=False, quoting=3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that the code above gives about the same (or slightly worse) results compared to the Bag of Words in Part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
