{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/.local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/rodrigo/.local/lib/python2.7/site-packages/sklearn/learning_curve.py:23: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import numpy as np\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.learning_curve import learning_curve\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The necessary files can be downloaded from the Data page. The first file that you'll need is unlabeledTrainData.tsv, which contains 25,000 IMDB movie reviews, each with a positive or negative sentiment label.\n",
    "\n",
    "Next, read the tab-delimited file into Python. To do this, we can use the pandas package, introduced in the Titanic tutorial, which provides the read_csv function for easily reading and writing data files. If you haven't used pandas before, you may need to install it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the pandas package, then use the \"read_csv\" function to read\n",
    "# the labeled training data\n",
    "import pandas as pd       \n",
    "data = pd.read_csv(\"data.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, \"header=0\" indicates that the first line of the file contains column names, \"delimiter=\\t\" indicates that the fields are separated by tabs, and quoting=3 tells Python to ignore doubled quotes, otherwise you may encounter errors trying to read the file.\n",
    "\n",
    "We can make sure that we read 25,000 rows and 3 columns as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52108, 2)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['text', 'class'], dtype=object)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reenviar indisponivel novamente registro sac</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aproximado mil nobill suspensão corporativo au...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>conte benéficos devidos expirada franquia intr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>exibe conjunta reinscidente venda combinacao m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nba recebemos oct correção informações solicit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  class\n",
       "0       reenviar indisponivel novamente registro sac      1\n",
       "1  aproximado mil nobill suspensão corporativo au...      1\n",
       "2  conte benéficos devidos expirada franquia intr...      1\n",
       "3  exibe conjunta reinscidente venda combinacao m...      1\n",
       "4  nba recebemos oct correção informações solicit...      1"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The three columns are called \"id\", \"sentiment\", and \"array.\"  Now that you've read the training set, take a look at a few reviews:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a reminder, this will show you the first movie review in the column named \"review.\" You should see a review that starts like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reenviar indisponivel novamente registro sac\n"
     ]
    }
   ],
   "source": [
    "print data[\"text\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing HTML Markup: The BeautifulSoup Package\n",
    "\n",
    "First, we'll remove the HTML tags. For this purpose, we'll use the Beautiful Soup library. If you don't have Beautiful soup installed, do:\n",
    "Then, from within Python, load the package and use it to extract the text from a review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reenviar indisponivel novamente registro sac\n",
      "reenviar indisponivel novamente registro sac\n"
     ]
    }
   ],
   "source": [
    "# Import BeautifulSoup into your workspace\n",
    "from bs4 import BeautifulSoup             \n",
    "\n",
    "# Initialize the BeautifulSoup object on a single movie review     \n",
    "example1 = BeautifulSoup(data[\"text\"][0])  \n",
    "\n",
    "# Print the raw review and then the output of get_text(), for \n",
    "# comparison\n",
    "print data[\"text\"][0]\n",
    "print example1.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling get_text() gives you the text of the review, without tags or markup. If you browse the BeautifulSoup documentation, you'll see that it's a very powerful library - more powerful than we need for this dataset. However, it is not considered a reliable practice to remove markup using regular expressions, so even for an application as simple as this, it's usually best to use a package like BeautifulSoup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with Punctuation, Numbers and Stopwords: NLTK and regular expressions\n",
    "\n",
    "When considering how to clean the text, we should think about the data problem we are trying to solve. For many problems, it makes sense to remove punctuation. On the other hand, in this case, we are tackling a sentiment analysis problem, and it is possible that \"!!!\" or \":-(\" could carry sentiment, and should be treated as words. In this tutorial, for simplicity, we remove the punctuation altogether, but it is something you can play with on your own.\n",
    "\n",
    "Similarly, in this tutorial we will remove numbers, but there are other ways of dealing with them that make just as much sense. For example, we could treat them as words, or replace them all with a placeholder string such as \"NUM\".\n",
    "\n",
    "To remove punctuation and numbers, we will use a package for dealing with regular expressions, called re. The package comes built-in with Python; no need to install anything. For a detailed description of how regular expressions work, see the package documentation. Now, try the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reenviar indisponivel novamente registro sac\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# Use regular expressions to do a find-and-replace\n",
    "letters_only = re.sub(\"[^a-zA-Z]\",           # The pattern to search for\n",
    "                      \" \",                   # The pattern to replace it with\n",
    "                      example1.get_text() )  # The text to search\n",
    "print letters_only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A full overview of regular expressions is beyond the scope of this tutorial, but for now it is sufficient to know that [] indicates group membership and ^ means \"not\". In other words, the re.sub() statement above says, \"Find anything that is NOT a lowercase letter (a-z) or an upper case letter (A-Z), and replace it with a space.\"\n",
    "\n",
    "We'll also convert our reviews to lower case and split them into individual words (called \"tokenization\" in NLP lingo):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lower_case = letters_only.lower()        # Convert to lower case\n",
    "words = lower_case.split()               # Split into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'reenviar', u'indisponivel', u'novamente', u'registro', u'sac']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to decide how to deal with frequently occurring words that don't carry much meaning. Such words are called \"stop words\"; in English they include words such as \"a\", \"and\", \"is\", and \"the\". Conveniently, there are Python packages that come with stop word lists built in. Let's import a stop word list from the Python Natural Language Toolkit (NLTK). You'll need to install the library if you don't already have it on your computer; you'll also need to install the data packages that come with it, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'de', u'a', u'o', u'que', u'e', u'do', u'da', u'em', u'um', u'para', u'com', u'n\\xe3o', u'uma', u'os', u'no', u'se', u'na', u'por', u'mais', u'as', u'dos', u'como', u'mas', u'ao', u'ele', u'das', u'\\xe0', u'seu', u'sua', u'ou', u'quando', u'muito', u'nos', u'j\\xe1', u'eu', u'tamb\\xe9m', u's\\xf3', u'pelo', u'pela', u'at\\xe9', u'isso', u'ela', u'entre', u'depois', u'sem', u'mesmo', u'aos', u'seus', u'quem', u'nas', u'me', u'esse', u'eles', u'voc\\xea', u'essa', u'num', u'nem', u'suas', u'meu', u'\\xe0s', u'minha', u'numa', u'pelos', u'elas', u'qual', u'n\\xf3s', u'lhe', u'deles', u'essas', u'esses', u'pelas', u'este', u'dele', u'tu', u'te', u'voc\\xeas', u'vos', u'lhes', u'meus', u'minhas', u'teu', u'tua', u'teus', u'tuas', u'nosso', u'nossa', u'nossos', u'nossas', u'dela', u'delas', u'esta', u'estes', u'estas', u'aquele', u'aquela', u'aqueles', u'aquelas', u'isto', u'aquilo', u'estou', u'est\\xe1', u'estamos', u'est\\xe3o', u'estive', u'esteve', u'estivemos', u'estiveram', u'estava', u'est\\xe1vamos', u'estavam', u'estivera', u'estiv\\xe9ramos', u'esteja', u'estejamos', u'estejam', u'estivesse', u'estiv\\xe9ssemos', u'estivessem', u'estiver', u'estivermos', u'estiverem', u'hei', u'h\\xe1', u'havemos', u'h\\xe3o', u'houve', u'houvemos', u'houveram', u'houvera', u'houv\\xe9ramos', u'haja', u'hajamos', u'hajam', u'houvesse', u'houv\\xe9ssemos', u'houvessem', u'houver', u'houvermos', u'houverem', u'houverei', u'houver\\xe1', u'houveremos', u'houver\\xe3o', u'houveria', u'houver\\xedamos', u'houveriam', u'sou', u'somos', u's\\xe3o', u'era', u'\\xe9ramos', u'eram', u'fui', u'foi', u'fomos', u'foram', u'fora', u'f\\xf4ramos', u'seja', u'sejamos', u'sejam', u'fosse', u'f\\xf4ssemos', u'fossem', u'for', u'formos', u'forem', u'serei', u'ser\\xe1', u'seremos', u'ser\\xe3o', u'seria', u'ser\\xedamos', u'seriam', u'tenho', u'tem', u'temos', u't\\xe9m', u'tinha', u't\\xednhamos', u'tinham', u'tive', u'teve', u'tivemos', u'tiveram', u'tivera', u'tiv\\xe9ramos', u'tenha', u'tenhamos', u'tenham', u'tivesse', u'tiv\\xe9ssemos', u'tivessem', u'tiver', u'tivermos', u'tiverem', u'terei', u'ter\\xe1', u'teremos', u'ter\\xe3o', u'teria', u'ter\\xedamos', u'teriam']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "print stopwords.words(\"portuguese\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will allow you to view the list of English-language stop words. To remove stop words from our movie review, do:\n",
    "This looks at each word in our \"words\" list, and discards anything that is found in the list of stop words. After all of these steps, your review should now begin something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'reenviar', u'indisponivel', u'novamente', u'registro', u'sac']\n"
     ]
    }
   ],
   "source": [
    "# Remove stop words from \"words\"\n",
    "words = [w for w in words if not w in stopwords.words(\"portuguese\")]\n",
    "print words[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't worry about the \"u\" before each word; it just indicates that Python is internally representing each word as a unicode string.\n",
    "\n",
    "There are many other things we could do to the data - For example, Porter Stemming and Lemmatizing (both available in NLTK) would allow us to treat \"messages\", \"message\", and \"messaging\" as the same word, which could certainly be useful. However, for simplicity, the tutorial will stop here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together\n",
    "Now we have code to clean one review - but we need to clean 25,000 training reviews! To make our code reusable, let's create a function that can be called many times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_to_words( raw_review ):\n",
    "    # Function to convert a raw review to a string of words\n",
    "    # The input is a single string (a raw movie review), and \n",
    "    # the output is a single string (a preprocessed movie review)\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(raw_review).get_text() \n",
    "    #\n",
    "    # 2. Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text) \n",
    "    #\n",
    "    # 3. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()                             \n",
    "    #\n",
    "    # 4. In Python, searching a set is much faster than searching\n",
    "    #   a list, so convert the stop words to a set\n",
    "    stops = set(stopwords.words(\"portuguese\"))                  \n",
    "    # \n",
    "    # 5. Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]   \n",
    "    #\n",
    "    # 6. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return( \" \".join( meaningful_words ))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two elements here are new: First, we converted the stop word list to a different data type, a set. This is for speed; since we'll be calling this function tens of thousands of times, it needs to be fast, and searching sets in Python is much faster than searching lists.\n",
    "\n",
    "Second, we joined the words back into one paragraph. This is to make the output easier to use in our Bag of Words, below. After defining the above function, if you call the function for a single review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reenviar indisponivel novamente registro sac\n"
     ]
    }
   ],
   "source": [
    "clean_data = text_to_words( data[\"text\"][0] )\n",
    "print clean_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it should give you exactly the same output as all of the individual steps we did in preceding tutorial sections. Now let's loop through and clean all of the training set at once (this might take a few minutes depending on your computer):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the number of reviews based on the dataframe column size\n",
    "num_text = data[\"text\"].size\n",
    "\n",
    "# Initialize an empty list to hold the clean reviews\n",
    "clean_data_text = []\n",
    "\n",
    "# Loop over each review; create an index i that goes from 0 to the length\n",
    "# of the movie review list \n",
    "for i in xrange( 0, num_text ):\n",
    "    # Call our function for each one, and add the result to the list of\n",
    "    # clean reviews\n",
    "    clean_data_text.append( text_to_words( data[\"text\"][i] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it can be annoying to wait for a lengthy piece of code to run. It can be helpful to write code so that it gives status updates. To have Python print a status update after every 1000 reviews that it processes, try adding a line or two to the code above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the training set movie reviews...\n",
      "\n",
      "Review 10000 of 52108\n",
      "\n",
      "Review 20000 of 52108\n",
      "\n",
      "Review 30000 of 52108\n",
      "\n",
      "Review 40000 of 52108\n",
      "\n",
      "Review 50000 of 52108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"Cleaning and parsing the training set movie reviews...\\n\"\n",
    "clean_data_text = []\n",
    "for i in xrange( 0, num_text):\n",
    "    # If the index is evenly divisible by 1000, print a message\n",
    "    if( (i+1)%10000 == 0 ):\n",
    "        print \"Review %d of %d\\n\" % ( i+1, num_text )                                                                    \n",
    "    clean_data_text.append( text_to_words( data[\"text\"][i] ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Features from a Bag of Words (Using scikit-learn)\n",
    "Now that we have our training reviews tidied up, how do we convert them to some kind of numeric representation for machine learning? One common approach is called a Bag of Words. The Bag of Words model learns a vocabulary from all of the documents, then models each document by counting the number of times each word appears. For example, consider the following two sentences:\n",
    "\n",
    "Sentence 1: \"The cat sat on the hat\"\n",
    "\n",
    "Sentence 2: \"The dog ate the cat and the hat\"\n",
    "\n",
    "From these two sentences, our vocabulary is as follows:\n",
    "\n",
    "{ the, cat, sat, on, hat, dog, ate, and }\n",
    "\n",
    "To get our bags of words, we count the number of times each word occurs in each sentence. In Sentence 1, \"the\" appears twice, and \"cat\", \"sat\", \"on\", and \"hat\" each appear once, so the feature vector for Sentence 1 is:\n",
    "\n",
    "{ the, cat, sat, on, hat, dog, ate, and }\n",
    "\n",
    "Sentence 1: { 2, 1, 1, 1, 1, 0, 0, 0 }\n",
    "\n",
    "Similarly, the features for Sentence 2 are: { 3, 1, 0, 0, 1, 1, 1, 1}\n",
    "\n",
    "In the IMDB data, we have a very large number of reviews, which will give us a large vocabulary. To limit the size of the feature vectors, we should choose some maximum vocabulary size. Below, we use the 5000 most frequent words (remembering that stop words have already been removed).\n",
    "\n",
    "We'll be using the feature_extraction module from scikit-learn to create bag-of-words features. If you did the Random Forest tutorial in the Titanic competition, you should already have scikit-learn installed; otherwise you will need to install it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the bag of words...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"Creating the bag of words...\\n\"\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "# bag of words tool.  \n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 5000) \n",
    "\n",
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocabulary; second, it transforms our training data\n",
    "# into feature vectors. The input to fit_transform should be a list of \n",
    "# strings.\n",
    "data_features = vectorizer.fit_transform(clean_data_text)\n",
    "\n",
    "# Numpy arrays are easy to work with, so convert the result to an \n",
    "# array\n",
    "data_features = data_features.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see what the training data array now looks like, do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52108, 5000)\n"
     ]
    }
   ],
   "source": [
    "print data_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has 25,000 rows and 5,000 features (one for each vocabulary word).\n",
    "\n",
    "Note that CountVectorizer comes with its own options to automatically do preprocessing, tokenization, and stop word removal -- for each of these, instead of specifying \"None\", we could have used a built-in method or specified our own function to use.  See the function documentation for more details. However, we wanted to write our own function for data cleaning in this tutorial to show you how it's done step by step.\n",
    "\n",
    "Now that the Bag of Words model is trained, let's look at the vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'aa', u'aaaammdd', u'aba', u'abaixo', u'abas', u'abend', u'aberta', u'abertas', u'aberto', u'abertos', u'abertura', u'abo', u'abonador', u'abr', u'abra', u'abre', u'abreu', u'abri', u'abril', u'abrimos', u'abrindo', u'abrir', u'abriu', u'abrtelecom', u'ac', u'acaa', u'acabou', u'acao', u'acarretando', u'acb']\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the words in the vocabulary\n",
    "vocab = vectorizer.get_feature_names()\n",
    "print vocab[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're interested, you can also print the counts of each word in\n",
    "the vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348 aa\n",
      "13 aaaammdd\n",
      "91 aba\n",
      "251 abaixo\n",
      "9 abas\n",
      "27 abend\n",
      "873 aberta\n",
      "210 abertas\n",
      "753 aberto\n",
      "161 abertos\n",
      "519 abertura\n",
      "12 abo\n",
      "31 abonador\n",
      "179 abr\n",
      "16 abra\n",
      "60 abre\n",
      "34 abreu\n",
      "16 abri\n",
      "96 abril\n",
      "27 abrimos\n",
      "30 abrindo\n",
      "283 abrir\n",
      "71 abriu\n",
      "16 abrtelecom\n",
      "129 ac\n",
      "29 acaa\n",
      "12 acabou\n",
      "20 acao\n",
      "39 acarretando\n",
      "25 acb\n",
      "31 acc\n",
      "10 accnt\n",
      "30 account\n",
      "24 acct\n",
      "9 acd\n",
      "51 aceita\n",
      "10 aceitando\n",
      "37 aceito\n",
      "15 aceitou\n",
      "75 acertar\n",
      "119 acerto\n",
      "13 acess\n",
      "53 acessa\n",
      "145 acessado\n",
      "348 acessar\n",
      "756 acesso\n",
      "9 acessorios\n",
      "350 acessos\n",
      "97 ach\n",
      "250 acima\n",
      "43 acionar\n",
      "488 acl\n",
      "13 acm\n",
      "212 acn\n",
      "8 acoa\n",
      "25 acoes\n",
      "30 acompanhamento\n",
      "15 acompanhamos\n",
      "35 acompanhar\n",
      "57 acontece\n",
      "32 acontecendo\n",
      "24 aconteceu\n",
      "16 acordado\n",
      "180 acordo\n",
      "22 acpa\n",
      "12 acredito\n",
      "21 acrescenta\n",
      "9 acrescentar\n",
      "10 actc\n",
      "9 active\n",
      "59 acumulo\n",
      "70 acusa\n",
      "8 acusando\n",
      "8 acusou\n",
      "86 ad\n",
      "44 ada\n",
      "10 adalberto\n",
      "11 adao\n",
      "13 adcional\n",
      "9 adcionar\n",
      "29 add\n",
      "10 ademar\n",
      "10 ademir\n",
      "24 aderir\n",
      "28 aderiu\n",
      "71 ades\n",
      "10 adesao\n",
      "12 adi\n",
      "178 adicionado\n",
      "150 adicionais\n",
      "209 adicional\n",
      "136 adicionar\n",
      "26 adilson\n",
      "11 adimplente\n",
      "11 adm\n",
      "19 administracao\n",
      "54 administrador\n",
      "17 administradora\n",
      "12 adnc\n",
      "140 ado\n",
      "18 ados\n",
      "78 adriana\n",
      "57 adriano\n",
      "251 adsl\n",
      "11 advogados\n",
      "21 ae\n",
      "21 aef\n",
      "16 aei\n",
      "10 aelac\n",
      "32 aelba\n",
      "29 aelbe\n",
      "10 aenxo\n",
      "23 aesc\n",
      "10 aesd\n",
      "16 aeta\n",
      "17 aez\n",
      "81 afeta\n",
      "26 afetada\n",
      "31 afetadas\n",
      "285 afetado\n",
      "83 afetados\n",
      "1529 afetando\n",
      "9 afim\n",
      "86 afirma\n",
      "11 afirmou\n",
      "22 afonso\n",
      "94 ag\n",
      "50 agencia\n",
      "10 agenda\n",
      "26 agendada\n",
      "20 agendado\n",
      "376 agendamento\n",
      "13 agendamentos\n",
      "11 agendamos\n",
      "99 agendar\n",
      "45 agente\n",
      "24 agentes\n",
      "15 agilizar\n",
      "51 agilize\n",
      "33 aglutina\n",
      "24 aglutinado\n",
      "19 aglutinador\n",
      "19 ago\n",
      "84 agosto\n",
      "153 agr\n",
      "291 agrade\n",
      "51 agradecemos\n",
      "10 agrgy\n",
      "10 agrhk\n",
      "21 agrif\n",
      "39 agrig\n",
      "80 agrih\n",
      "12 agrii\n",
      "19 agrupada\n",
      "10 agrupadas\n",
      "26 agrupado\n",
      "201 agrupador\n",
      "62 agrupamento\n",
      "30 agrx\n",
      "16 agry\n",
      "129 aguard\n",
      "40 aguarda\n",
      "458 aguardando\n",
      "33 aguardar\n",
      "12 aguarde\n",
      "63 aguardo\n",
      "47 aguiar\n",
      "16 ai\n",
      "33 aice\n",
      "10 ailton\n",
      "10 aires\n",
      "11 aja\n",
      "28 aju\n",
      "53 ajuda\n",
      "157 ajudar\n",
      "19 ajustada\n",
      "22 ajustado\n",
      "260 ajustar\n",
      "98 ajuste\n",
      "13 ajustes\n",
      "106 al\n",
      "63 alarme\n",
      "71 alberto\n",
      "35 albuquerque\n",
      "16 alcantara\n",
      "10 aldo\n",
      "84 alega\n",
      "17 alegando\n",
      "10 alegre\n",
      "12 alem\n",
      "25 alencar\n",
      "473 alerta\n",
      "29 alessandra\n",
      "9 alessandro\n",
      "39 alex\n",
      "9 alexander\n",
      "9 alexandra\n",
      "88 alexandre\n",
      "14 alexia\n",
      "15 alfredo\n",
      "8 alho\n",
      "56 alice\n",
      "21 alimentos\n",
      "79 aline\n",
      "37 alinhado\n",
      "16 alinhamento\n",
      "9 all\n",
      "8 allan\n",
      "16 allitems\n",
      "18 allnet\n",
      "187 almeida\n",
      "9 almir\n",
      "64 alone\n",
      "14 alt\n",
      "18 alta\n",
      "9 altcpfx\n",
      "103 altctec\n",
      "17 altenda\n",
      "12 altendb\n",
      "517 altera\n",
      "38 alteracao\n",
      "24 alterada\n",
      "78 alteradas\n",
      "386 alterado\n",
      "62 alterados\n",
      "21 alterando\n",
      "345 alterar\n",
      "31 altere\n",
      "39 alterou\n",
      "20 altmeio\n",
      "88 alto\n",
      "67 altpdem\n",
      "20 altperc\n",
      "44 alttcir\n",
      "16 aluguel\n",
      "16 alvaro\n",
      "256 alves\n",
      "57 am\n",
      "17 amanda\n",
      "56 amaral\n",
      "13 amaro\n",
      "45 amb\n",
      "31 ambas\n",
      "95 ambiente\n",
      "10 ambientes\n",
      "527 ambos\n",
      "13 amea\n",
      "14 amelia\n",
      "13 amento\n",
      "49 amorim\n",
      "27 amos\n",
      "20 amostra\n",
      "8 ams\n",
      "229 an\n",
      "187 ana\n",
      "21 analisa\n",
      "22 analisado\n",
      "12 analisados\n",
      "13 analisando\n",
      "272 analisar\n",
      "323 analise\n",
      "25 analises\n",
      "21 analista\n",
      "436 anatel\n",
      "8 anc\n",
      "9 and\n",
      "83 andamento\n",
      "13 andamentos\n",
      "10 andar\n",
      "60 anderson\n",
      "11 andr\n",
      "153 andrade\n",
      "93 andre\n",
      "30 andrea\n",
      "35 andreia\n",
      "14 andressa\n",
      "12 andreza\n",
      "89 anexa\n",
      "45 anexada\n",
      "34 anexadas\n",
      "92 anexado\n",
      "78 anexados\n",
      "130 anexar\n",
      "18 anexas\n",
      "1751 anexo\n",
      "123 anexos\n",
      "42 angela\n",
      "16 angelica\n",
      "11 angelita\n",
      "27 angelo\n",
      "27 anjos\n",
      "11 anna\n",
      "34 ano\n",
      "13 anos\n",
      "19 anote\n",
      "17 ans\n",
      "15 ant\n",
      "121 anterior\n",
      "24 anteriores\n",
      "33 anteriormente\n",
      "45 antiga\n",
      "14 antigas\n",
      "178 antigo\n",
      "13 antigos\n",
      "9 antiv\n",
      "22 antivirus\n",
      "34 antonia\n",
      "212 antonio\n",
      "31 antunes\n",
      "24 aonde\n",
      "63 ap\n",
      "11 apaa\n",
      "30 apaga\n",
      "77 apagada\n",
      "33 apagado\n",
      "384 apagar\n",
      "13 apagou\n",
      "11 aparace\n",
      "12 apare\n",
      "537 aparece\n",
      "90 aparecem\n",
      "181 aparecendo\n",
      "51 aparecer\n",
      "37 apareceu\n",
      "177 aparecida\n",
      "59 aparecido\n",
      "25 aparelho\n",
      "18 aparelhos\n",
      "25 aparente\n",
      "12 apartamento\n",
      "185 apenas\n",
      "56 apesar\n",
      "114 aplic\n",
      "350 aplica\n",
      "31 aplicacao\n",
      "18 aplicacoes\n",
      "31 aplicada\n",
      "59 aplicado\n",
      "15 aplicados\n",
      "217 aplicar\n",
      "37 aplicativo\n",
      "77 apn\n",
      "73 apoio\n",
      "10 aponta\n",
      "123 apos\n",
      "25 app\n",
      "1252 application\n",
      "62 aprazada\n",
      "12 aprece\n",
      "34 aprensenta\n",
      "739 apresenta\n",
      "217 apresentada\n",
      "205 apresentado\n",
      "9 apresentados\n",
      "92 apresentam\n",
      "719 apresentando\n",
      "26 apresentar\n",
      "113 apresentaram\n",
      "14 apresente\n",
      "164 apresentou\n",
      "14 apresta\n",
      "32 aprisionamento\n",
      "52 aprov\n",
      "56 aprova\n",
      "33 aprovada\n",
      "69 aprovado\n",
      "10 aprovisionado\n",
      "250 aprovisionamento\n",
      "9 aproximadamente\n",
      "13 aproximado\n",
      "130 apura\n",
      "100 apurado\n",
      "64 apurar\n",
      "16 aq\n",
      "9 aqui\n",
      "28 aquino\n",
      "10 aquisi\n",
      "53 ar\n",
      "10 ara\n",
      "12 aragao\n",
      "11 arantes\n",
      "9 arapongas\n",
      "191 araujo\n",
      "279 arb\n",
      "11 arbo\n",
      "780 arbor\n",
      "175 arbpc\n",
      "83 arbpd\n",
      "40 arbpe\n",
      "21 arbrc\n",
      "9 arbre\n",
      "9 arbsourcetargetprodpcs\n",
      "10 arbtd\n",
      "19 arbtm\n",
      "88 area\n",
      "8 ari\n",
      "10 ariane\n",
      "71 arm\n",
      "14 armando\n",
      "50 armario\n",
      "11 arnaldo\n",
      "32 arq\n",
      "260 arquivo\n",
      "133 arquivos\n",
      "14 arrecadacao\n",
      "20 arruda\n",
      "751 ars\n",
      "20 arthur\n",
      "19 asap\n",
      "98 asg\n",
      "16 aspx\n",
      "24 ass\n",
      "14 assessoria\n",
      "10 asset\n",
      "160 assim\n",
      "120 assinante\n",
      "9 assinantes\n",
      "216 assinatura\n",
      "41 assinaturas\n",
      "52 assis\n",
      "9 assist\n",
      "10 assistencia\n",
      "59 associa\n",
      "44 associacao\n",
      "72 associada\n",
      "33 associadas\n",
      "282 associado\n",
      "50 associados\n",
      "19 associando\n",
      "83 associar\n",
      "50 assumir\n",
      "33 assumiu\n",
      "16 assuncao\n",
      "20 assunto\n",
      "152 at\n",
      "9 ataide\n",
      "86 ate\n",
      "66 atem\n",
      "35 atemb\n",
      "63 aten\n",
      "30 atenciosamente\n",
      "134 atende\n",
      "284 atendente\n",
      "65 atender\n",
      "18 atendida\n",
      "22 atendido\n",
      "152 atendimento\n",
      "10 atf\n",
      "44 ativ\n",
      "885 ativa\n",
      "49 ativacao\n",
      "71 ativada\n",
      "74 ativado\n",
      "19 ativados\n",
      "23 ativando\n",
      "209 ativar\n",
      "92 ativas\n",
      "432 atividade\n",
      "193 atividades\n",
      "487 ativo\n",
      "177 ativos\n",
      "38 ativou\n",
      "59 ato\n",
      "121 atraso\n",
      "48 atraves\n",
      "29 atrelada\n",
      "55 atrelado\n",
      "9 atrelados\n",
      "8 atrelar\n",
      "52 atribu\n",
      "27 atribui\n",
      "16 atribuido\n",
      "9 atribuir\n",
      "20 atributo\n",
      "95 att\n",
      "26 atu\n",
      "15 atua\n",
      "13 atuais\n",
      "197 atual\n",
      "268 atualiza\n",
      "154 atualizacao\n",
      "36 atualizada\n",
      "10 atualizadas\n",
      "119 atualizado\n",
      "33 atualizados\n",
      "22 atualizando\n",
      "738 atualizar\n",
      "152 atualizou\n",
      "23 atualizr\n",
      "40 atualmente\n",
      "23 atuar\n",
      "8 atuarbterc\n",
      "33 atv\n",
      "34 auditoria\n",
      "79 augusto\n",
      "66 aumento\n",
      "23 aurelio\n",
      "12 aurora\n",
      "9 aus\n",
      "40 autd\n",
      "271 autentica\n",
      "410 autenticar\n",
      "35 auto\n",
      "442 autom\n",
      "8 automa\n",
      "51 automatica\n",
      "95 automaticamente\n",
      "9 automaticas\n",
      "96 automatico\n",
      "152 autor\n",
      "62 autora\n",
      "17 autoridade\n",
      "114 autoriza\n",
      "12 autorizada\n",
      "50 autorizado\n",
      "24 autorizador\n",
      "13 autorizados\n",
      "25 autorizar\n",
      "21 aux\n",
      "11 auxiliadora\n",
      "9 auxiliamos\n",
      "55 auxiliar\n",
      "21 auxilio\n",
      "35 av\n",
      "29 ava\n",
      "42 avaliar\n",
      "122 avan\n",
      "14 avancado\n",
      "51 avaya\n",
      "8 averigua\n",
      "18 averiguar\n",
      "28 avila\n",
      "14 avisar\n",
      "16 avise\n",
      "13 aviso\n",
      "16 avulsa\n",
      "117 avulso\n",
      "47 avulsos\n",
      "9 axa\n",
      "73 azevedo\n",
      "2474 ba\n",
      "47 back\n",
      "256 backlog\n",
      "132 backoffice\n",
      "24 backup\n",
      "50 bahia\n",
      "28 bairro\n",
      "465 baixa\n",
      "59 baixada\n",
      "85 baixadas\n",
      "19 baixado\n",
      "56 baixar\n",
      "10 baixas\n",
      "35 baixo\n",
      "11 baixou\n",
      "16 banc\n",
      "142 banco\n",
      "310 banda\n",
      "14 bandeira\n",
      "14 baptista\n",
      "10 bar\n",
      "19 barbara\n",
      "145 barbosa\n",
      "12 barboza\n",
      "12 barcelos\n",
      "32 barra\n",
      "67 barramento\n",
      "27 barras\n",
      "35 barreto\n",
      "88 barros\n",
      "14 barroso\n",
      "26 bartoline\n",
      "156 bas\n",
      "387 base\n",
      "68 basico\n",
      "10 bastante\n",
      "33 bastos\n",
      "19 bat\n",
      "16 batana\n",
      "21 batch\n",
      "41 bate\n",
      "145 batimento\n",
      "104 batista\n",
      "52 bauer\n",
      "74 bb\n",
      "29 bbiprd\n",
      "116 bc\n",
      "68 bcb\n",
      "9 bcu\n",
      "299 bd\n",
      "17 bdea\n",
      "11 bded\n",
      "91 bdo\n",
      "19 bds\n",
      "9 be\n",
      "34 beatriz\n",
      "45 belo\n",
      "40 bem\n",
      "15 ben\n",
      "10 benedita\n",
      "26 benedito\n",
      "326 benef\n",
      "101 beneficio\n",
      "20 beneficios\n",
      "9 benites\n",
      "25 bento\n",
      "15 bernadete\n",
      "33 bernardo\n",
      "14 bet\n",
      "65 bezerra\n",
      "9 bh\n",
      "120 bhe\n",
      "11 bhya\n",
      "12 bhyd\n",
      "13 bianca\n",
      "19 bib\n",
      "52 biblioteca\n",
      "191 bif\n",
      "144 bilhete\n",
      "34 bilhetes\n",
      "341 bill\n",
      "19 billing\n",
      "103 bin\n",
      "18 binado\n",
      "21 bip\n",
      "17 bispo\n",
      "12 bitencourt\n",
      "232 bito\n",
      "179 bitos\n",
      "19 bko\n",
      "821 bl\n",
      "21 bla\n",
      "13 black\n",
      "10 blackberry\n",
      "19 blico\n",
      "20 blindado\n",
      "37 blindagem\n",
      "24 bll\n",
      "26 blm\n",
      "9 blo\n",
      "15 bloco\n",
      "19 bloddc\n",
      "9 blomov\n",
      "11 bloq\n",
      "124 bloqueada\n",
      "13 bloqueadas\n",
      "216 bloqueado\n",
      "36 bloqueados\n",
      "9 bloqueando\n",
      "53 bloquear\n",
      "621 bloqueio\n",
      "34 bloqueios\n",
      "10 bloquieo\n",
      "12 bma\n",
      "184 bmc\n",
      "197 bo\n",
      "323 boa\n",
      "12 boas\n",
      "23 bol\n",
      "34 boleto\n",
      "8 bolso\n",
      "337 bom\n",
      "20 bonifica\n",
      "84 bonus\n",
      "15 borba\n",
      "88 borges\n",
      "129 bot\n",
      "14 botao\n",
      "11 botelho\n",
      "45 bov\n",
      "612 bp\n",
      "36 bpr\n",
      "39 bps\n",
      "10 bqe\n",
      "155 br\n",
      "21 bradesco\n",
      "48 braga\n",
      "16 braile\n",
      "213 branco\n",
      "26 brandao\n",
      "137 brasil\n",
      "11 brasileira\n",
      "15 braz\n",
      "9 breno\n",
      "12 brf\n",
      "8 bri\n",
      "9 brica\n",
      "73 brito\n",
      "262 brt\n",
      "60 bruna\n",
      "68 bruno\n",
      "21 bs\n",
      "282 bsa\n",
      "19 bsim\n",
      "15 bt\n",
      "9 btacp\n",
      "9 btcc\n",
      "30 btdf\n",
      "25 bueno\n",
      "569 bundle\n",
      "27 bundles\n",
      "146 busca\n",
      "10 buscar\n",
      "11 business\n",
      "25 bva\n",
      "14 by\n",
      "129 ca\n",
      "62 cabo\n",
      "32 cabral\n",
      "23 cache\n",
      "24 cad\n",
      "44 cadastra\n",
      "223 cadastrada\n",
      "53 cadastradas\n",
      "284 cadastrado\n",
      "109 cadastrados\n",
      "77 cadastrais\n",
      "74 cadastral\n",
      "51 cadastramento\n",
      "262 cadastrar\n",
      "14 cadastre\n",
      "612 cadastro\n",
      "9 cadastrocliente\n",
      "20 cadastrou\n",
      "17 cadeia\n",
      "9 cadop\n",
      "23 caetano\n",
      "23 cai\n",
      "75 caindo\n",
      "11 caio\n",
      "9 cair\n",
      "66 caiu\n",
      "154 caixa\n",
      "13 calcados\n",
      "12 caldas\n",
      "61 call\n",
      "18 camapanha\n",
      "16 camara\n",
      "46 camargo\n",
      "41 camila\n",
      "17 camile\n",
      "9 camilo\n",
      "39 caminho\n",
      "13 camp\n",
      "471 campanha\n",
      "104 campanhas\n",
      "343 campo\n",
      "166 campos\n",
      "14 can\n",
      "22 canais\n",
      "151 canal\n",
      "33 canc\n",
      "42 cancel\n",
      "77 cancela\n",
      "525 cancelada\n",
      "79 canceladas\n",
      "534 cancelado\n",
      "85 cancelados\n",
      "1880 cancelamento\n",
      "64 cancelamentos\n",
      "33 cancelando\n",
      "692 cancelar\n",
      "12 cancele\n",
      "43 cancelou\n",
      "11 candida\n",
      "29 candido\n",
      "122 caracter\n",
      "9 caracteres\n",
      "56 caracteristicas\n",
      "36 card\n",
      "103 cardoso\n",
      "9 cardozo\n",
      "96 carga\n",
      "9 cargas\n",
      "23 cargo\n",
      "15 carina\n",
      "9 carine\n",
      "60 carla\n",
      "208 carlos\n",
      "79 carmo\n",
      "44 carneiro\n",
      "51 carolina\n",
      "41 caroline\n",
      "262 caros\n",
      "50 carrega\n",
      "12 carregado\n",
      "24 carregados\n",
      "19 carregando\n",
      "15 carregar\n",
      "119 cart\n",
      "11 cartao\n",
      "96 carte\n",
      "178 carvalho\n",
      "69 casa\n",
      "9 casada\n",
      "29 cascavel\n",
      "43 case\n",
      "84 casella\n",
      "189 caso\n",
      "294 casos\n",
      "26 cassia\n",
      "10 cassio\n",
      "9 castelo\n",
      "99 castro\n",
      "192 cat\n",
      "58 catarina\n",
      "12 categ\n",
      "676 categoria\n",
      "41 categoriza\n",
      "9 catia\n",
      "13 catonx\n",
      "206 causa\n",
      "43 causando\n",
      "23 cavalcante\n",
      "10 cavalcanti\n",
      "23 cb\n",
      "143 cba\n",
      "36 cbb\n",
      "65 cbc\n",
      "217 cc\n",
      "12 cca\n",
      "1605 cco\n",
      "43 ccto\n",
      "78 cd\n",
      "140 cdi\n",
      "9 cdigatprdd\n",
      "12 cdipw\n",
      "88 cdr\n",
      "9 cdrinst\n",
      "148 cdrs\n",
      "137 ce\n",
      "12 ceara\n",
      "9 ceasing\n",
      "22 cecilia\n",
      "95 cel\n",
      "35 celia\n",
      "10 celio\n",
      "25 celso\n",
      "126 celular\n",
      "27 celulares\n",
      "96 cen\n",
      "16 cenario\n",
      "10 cennario\n",
      "57 center\n",
      "24 centrais\n",
      "129 central\n",
      "57 centro\n",
      "67 cep\n",
      "17 cerca\n",
      "13 cerqueira\n",
      "32 certo\n",
      "102 cesar\n",
      "22 cesta\n",
      "22 cezar\n",
      "106 cf\n",
      "104 cfg\n",
      "16 cg\n",
      "62 cga\n",
      "24 cgb\n",
      "213 cgc\n",
      "13 cgd\n",
      "13 cgds\n",
      "51 cge\n",
      "24 cgf\n",
      "20 cgo\n",
      "26 cgocs\n",
      "134 cgs\n",
      "96 ch\n",
      "30 cha\n",
      "65 chagas\n",
      "128 cham\n",
      "26 chama\n",
      "66 chamada\n",
      "120 chamadas\n",
      "497 chamado\n",
      "213 chamador\n",
      "29 chamados\n",
      "16 charlene\n",
      "29 charles\n",
      "126 chave\n",
      "40 chaves\n",
      "41 chega\n",
      "21 chegando\n",
      "61 chegar\n",
      "22 chegaram\n",
      "66 chegou\n",
      "18 chido\n",
      "89 chip\n",
      "26 chips\n",
      "11 chmd\n",
      "8 chn\n",
      "8 christiane\n",
      "70 chrome\n",
      "80 cia\n",
      "17 cicero\n",
      "287 ciclo\n",
      "41 ciclos\n",
      "46 cidade\n",
      "34 cielo\n",
      "124 ciente\n",
      "11 cim\n",
      "16 cima\n",
      "11 cinco\n",
      "27 cinema\n",
      "12 cintia\n",
      "312 cio\n",
      "182 cios\n",
      "9 cir\n",
      "8 circ\n",
      "935 circuito\n",
      "225 circuitos\n",
      "10 circula\n",
      "10 citada\n",
      "9 citadas\n",
      "19 citado\n",
      "18 citados\n",
      "31 citrix\n",
      "23 city\n",
      "10 civil\n",
      "43 cj\n",
      "22 cka\n",
      "9 ckz\n",
      "15 cl\n",
      "11 clara\n",
      "8 clarifay\n",
      "758 clarify\n",
      "98 claro\n",
      "157 classe\n",
      "8 classifica\n",
      "11 classificados\n",
      "9 claudete\n",
      "67 claudia\n",
      "9 claudinei\n",
      "13 claudino\n",
      "75 claudio\n",
      "10 clck\n",
      "59 cld\n",
      "30 clean\n",
      "10 cleanup\n",
      "28 cleber\n",
      "17 cleide\n",
      "31 cleinte\n",
      "13 cleonice\n",
      "123 cli\n",
      "66 clica\n",
      "17 clicado\n",
      "15 clicamos\n",
      "9 clicando\n",
      "165 clicar\n",
      "1404 click\n",
      "71 clie\n",
      "28 client\n",
      "1300 cliente\n",
      "12 clienteoperacao\n",
      "820 clientes\n",
      "9 cliete\n",
      "15 clietne\n",
      "9 clinete\n",
      "20 clinica\n",
      "14 clinte\n",
      "19 clka\n",
      "58 clkb\n",
      "124 clke\n",
      "10 clkp\n",
      "10 cloud\n",
      "155 clt\n",
      "31 cly\n",
      "25 cm\n",
      "68 cmd\n",
      "14 cmf\n",
      "283 cmr\n",
      "130 cms\n",
      "38 cn\n",
      "11 cnf\n",
      "67 cnica\n",
      "155 cnico\n",
      "34 cnicos\n",
      "22 cnl\n",
      "687 cnpj\n",
      "9 cns\n",
      "176 co\n",
      "33 cob\n",
      "17 cober\n",
      "11 cobertura\n",
      "16 cobilling\n",
      "205 cobprd\n",
      "14 cobra\n",
      "60 cobrada\n",
      "32 cobradas\n",
      "317 cobrado\n",
      "27 cobrados\n",
      "435 cobran\n",
      "203 cobranca\n",
      "89 cobrando\n",
      "24 cobrar\n",
      "49 cobre\n",
      "203 cod\n",
      "12 code\n",
      "176 codigo\n",
      "9 codigos\n",
      "17 coelba\n",
      "80 coelho\n",
      "12 coimbra\n",
      "111 colaborador\n",
      "69 colaboradora\n",
      "46 colaboradores\n",
      "9 coleta\n",
      "63 coloca\n",
      "48 colocada\n",
      "24 colocado\n",
      "22 colocamos\n",
      "34 colocando\n",
      "167 colocar\n",
      "9 coloco\n",
      "13 colocou\n",
      "9 colombo\n",
      "39 coluna\n",
      "471 comando\n",
      "39 comandos\n",
      "18 combate\n",
      "9 combina\n",
      "39 combinado\n",
      "112 combo\n",
      "70 combos\n",
      "31 comcampoferta\n",
      "29 come\n",
      "46 coment\n",
      "120 comercial\n",
      "144 comercio\n",
      "20 comfra\n",
      "20 comissionadas\n",
      "58 comp\n",
      "18 companhia\n",
      "10 compartilhada\n",
      "12 compartilhado\n",
      "28 compartilhamento\n",
      "21 compat\n",
      "16 complementar\n",
      "35 complemento\n",
      "9 complementos\n",
      "120 completa\n",
      "21 completada\n",
      "13 completado\n",
      "18 completar\n",
      "162 completo\n",
      "11 complexa\n",
      "40 component\n",
      "74 componente\n",
      "140 componentes\n",
      "10 comportamento\n",
      "36 composi\n",
      "10 compra\n",
      "35 comprobat\n",
      "27 comprova\n",
      "20 comprovando\n",
      "21 comprovante\n",
      "9 computador\n",
      "18 comtemplados\n",
      "15 comum\n",
      "110 comunica\n",
      "20 comunicacao\n",
      "19 comunique\n",
      "16 comuta\n",
      "18 comverse\n",
      "31 con\n",
      "31 concede\n",
      "11 conceder\n",
      "17 concedida\n",
      "70 concedido\n",
      "24 concei\n",
      "82 conceicao\n",
      "9 concentrador\n",
      "32 concess\n",
      "653 conclu\n",
      "26 concluam\n",
      "93 conclui\n",
      "83 concluida\n",
      "20 concluidas\n",
      "247 concluido\n",
      "19 concluidos\n",
      "16 concluindo\n",
      "668 concluir\n",
      "23 concluiu\n",
      "404 conclus\n",
      "27 conclusao\n",
      "13 cond\n",
      "134 condi\n",
      "86 condicao\n",
      "9 condicionada\n",
      "30 condominio\n",
      "15 cone\n",
      "41 conec\n",
      "11 conect\n",
      "479 conectado\n",
      "11 conector\n",
      "12 conex\n",
      "36 conf\n",
      "26 confeccoes\n",
      "10 confederacao\n",
      "41 confer\n",
      "10 conferem\n",
      "101 confian\n",
      "15 config\n",
      "231 configura\n",
      "16 configurada\n",
      "62 configurado\n",
      "168 configurador\n",
      "36 configurados\n",
      "269 configurar\n",
      "95 confira\n",
      "122 confirma\n",
      "30 confirmado\n",
      "16 confirmados\n",
      "43 confirmamos\n",
      "18 confirmando\n",
      "102 confirmar\n",
      "10 confirmou\n",
      "126 conflito\n",
      "654 conforme\n",
      "143 conjunta\n",
      "13 conjunto\n",
      "101 connect\n",
      "33 conosco\n",
      "621 consegue\n",
      "137 conseguem\n",
      "79 consegui\n",
      "12 conseguia\n",
      "12 conseguido\n",
      "220 conseguimos\n",
      "405 conseguindo\n",
      "76 conseguir\n",
      "13 conseguiram\n",
      "19 conseguirmos\n",
      "61 conseguiu\n",
      "61 conseq\n",
      "44 consequ\n",
      "42 consequentemente\n",
      "25 consiga\n",
      "90 consigo\n",
      "18 consolidado\n",
      "609 consta\n",
      "177 constam\n",
      "73 constando\n",
      "9 constantes\n",
      "27 constar\n",
      "21 constatado\n",
      "15 constatamos\n",
      "18 construcao\n",
      "12 construcoes\n",
      "20 construtora\n",
      "385 consulta\n",
      "23 consultado\n",
      "30 consultamos\n",
      "73 consultando\n",
      "239 consultar\n",
      "15 consultas\n",
      "68 consultor\n",
      "11 consultora\n",
      "23 consultoria\n",
      "18 consumida\n",
      "14 consumido\n",
      "64 consumidor\n",
      "16 consumidora\n",
      "135 consumo\n",
      "261 cont\n",
      "863 conta\n",
      "40 contabilidade\n",
      "9 contabilizado\n",
      "21 contactar\n",
      "426 contas\n",
      "31 contatar\n",
      "1495 contato\n",
      "95 contatos\n",
      "27 contax\n",
      "12 conte\n",
      "10 contem\n",
      "15 contempla\n",
      "25 contemplado\n",
      "34 contendo\n",
      "16 contest\n",
      "273 contesta\n",
      "10 contestacoes\n",
      "63 contestada\n",
      "13 contestadas\n",
      "23 contestado\n",
      "14 contestar\n",
      "16 contidas\n",
      "68 conting\n",
      "16 contingencia\n",
      "19 contingencial\n",
      "471 continua\n",
      "78 continuam\n",
      "70 continuar\n",
      "10 continuarmos\n",
      "113 continuidade\n",
      "25 continuou\n",
      "35 contr\n",
      "40 contrata\n",
      "20 contratada\n",
      "20 contratado\n",
      "24 contratar\n",
      "856 contrato\n",
      "107 contratos\n",
      "73 contratou\n",
      "11 contratual\n",
      "19 contro\n",
      "47 control\n",
      "24 controlado\n",
      "633 controle\n",
      "992 controlm\n",
      "16 controlr\n",
      "13 conv\n",
      "123 convergente\n",
      "75 convergentes\n",
      "13 convers\n",
      "27 cooperativa\n",
      "14 cooperativas\n",
      "9 coordenador\n",
      "10 coordenadora\n",
      "10 cor\n",
      "39 cordeiro\n",
      "12 core\n",
      "22 corp\n",
      "43 corpo\n",
      "15 corporativa\n",
      "83 corporativo\n",
      "8 corrde\n",
      "416 corre\n",
      "71 correa\n",
      "15 correcao\n",
      "58 correia\n",
      "26 correios\n",
      "45 corrente\n",
      "17 correspond\n",
      "16 corresponde\n",
      "8 correspondencia\n",
      "25 correspondente\n",
      "77 correspondentes\n",
      "111 correta\n",
      "177 corretamente\n",
      "19 corretas\n",
      "201 correto\n",
      "27 corretora\n",
      "120 corretos\n",
      "20 corridos\n",
      "19 corrigi\n",
      "13 corrigida\n",
      "45 corrigido\n",
      "367 corrigir\n",
      "8 corrijam\n",
      "71 corte\n",
      "8 cortes\n",
      "19 cortip\n",
      "222 costa\n",
      "30 coutinho\n",
      "18 couto\n",
      "17 cp\n",
      "25 cpa\n",
      "12 cpct\n",
      "254 cpe\n",
      "9 cpecom\n",
      "649 cpf\n",
      "50 cpfcnpj\n",
      "15 cpfs\n",
      "14 cps\n",
      "1063 cr\n",
      "12 cracp\n",
      "8 creation\n",
      "11 creditado\n",
      "94 credito\n",
      "36 creditos\n",
      "37 crescente\n",
      "421 cria\n",
      "24 criacao\n",
      "37 criada\n",
      "10 criadas\n",
      "63 criado\n",
      "17 criados\n",
      "97 criar\n",
      "28 criem\n",
      "17 criou\n",
      "57 cristiane\n",
      "27 cristiano\n",
      "142 cristina\n",
      "9 cristine\n",
      "14 crit\n",
      "1110 critica\n",
      "57 criticada\n",
      "11 criticadas\n",
      "19 criticado\n",
      "32 criticados\n",
      "20 criticando\n",
      "16 criticas\n",
      "10 crjd\n",
      "1062 crm\n",
      "23 crmbat\n",
      "10 crmcriatabela\n",
      "30 crmextrator\n",
      "8 crmjob\n",
      "13 crmmktgtwd\n",
      "73 crmoibatd\n",
      "26 crmoiftp\n",
      "8 crmpub\n",
      "29 crmpubsp\n",
      "24 crmshl\n",
      "8 crmshlinadeim\n",
      "99 crmshlsp\n",
      "9 crmshpsp\n",
      "25 crmsp\n",
      "37 cronol\n",
      "35 crtd\n",
      "82 cruz\n",
      "67 crv\n",
      "8 cs\n",
      "24 csp\n",
      "10 css\n",
      "14 ct\n",
      "195 cta\n",
      "1976 ctm\n",
      "367 cto\n",
      "18 ctr\n",
      "105 ctrl\n",
      "158 ctt\n",
      "22 ctxsalpb\n",
      "9 cuidados\n",
      "9 cuja\n",
      "45 cujo\n",
      "30 cula\n",
      "41 culas\n",
      "12 cumprimento\n",
      "86 cunha\n",
      "26 curitiba\n",
      "14 cust\n",
      "27 customer\n",
      "11 cvp\n",
      "23 cx\n",
      "96 dacc\n",
      "43 dad\n",
      "25 dada\n",
      "69 dado\n",
      "614 dados\n",
      "22 daiane\n",
      "168 daily\n",
      "10 dal\n",
      "13 dalva\n",
      "17 damasceno\n",
      "131 dando\n",
      "32 dani\n",
      "75 daniel\n",
      "178 daniela\n",
      "34 daniele\n",
      "12 danielle\n",
      "29 danilo\n",
      "25 dantas\n",
      "15 danubia\n",
      "216 dar\n",
      "32 darmos\n",
      "346 data\n",
      "29 dataquality\n",
      "31 datas\n",
      "16 date\n",
      "65 david\n",
      "13 dayane\n",
      "11 dc\n",
      "26 dd\n",
      "242 ddd\n",
      "9 ddi\n",
      "10 ddmmaaaa\n",
      "103 ddr\n",
      "158 debito\n",
      "71 debitos\n",
      "34 debora\n",
      "16 dec\n",
      "28 decurso\n",
      "47 dedicado\n",
      "16 defeito\n",
      "20 defini\n",
      "11 definido\n",
      "36 definitiva\n",
      "11 definitivamente\n",
      "12 definitivo\n",
      "9 degrada\n",
      "15 deise\n",
      "133 deixa\n",
      "43 deixam\n",
      "125 deixando\n",
      "66 deixar\n",
      "13 deixou\n",
      "10 delgado\n",
      "193 demais\n",
      "90 demanda\n",
      "15 demandante\n",
      "32 demandas\n",
      "15 demilson\n",
      "9 demonstra\n",
      "16 demonstrado\n",
      "27 demora\n",
      "15 demorando\n",
      "11 denilson\n",
      "33 denise\n",
      "217 dentro\n",
      "11 dep\n",
      "9 departamento\n",
      "248 dependente\n",
      "49 dependentes\n",
      "16 deposito\n",
      "38 der\n",
      "20 deriva\n",
      "13 des\n",
      "88 desab\n",
      "16 desabilita\n",
      "15 desabilitada\n",
      "92 desabilitado\n",
      "8 desaparece\n",
      "20 desassocia\n",
      "23 desassociado\n",
      "80 desassociar\n",
      "129 desativa\n",
      "11 desativaacesso\n",
      "60 desativada\n",
      "127 desativado\n",
      "129 desativar\n",
      "31 desatualizado\n",
      "9 desatualizados\n",
      "9 desbloqueada\n",
      "20 desbloqueado\n",
      "34 desbloqueados\n",
      "77 desbloquear\n",
      "14 desbloqueiem\n",
      "352 desbloqueio\n",
      "18 desbloqueou\n",
      "146 desc\n",
      "16 desconectada\n",
      "8 desconectado\n",
      "110 desconex\n",
      "25 desconfigurar\n",
      "26 desconhece\n",
      "214 desconto\n",
      "39 descontos\n",
      "13 descreve\n",
      "291 descrever\n",
      "234 descri\n",
      "15 descric\n",
      "41 descricao\n",
      "11 descrita\n",
      "33 descrito\n",
      "9 descritos\n",
      "710 desde\n",
      "341 deseja\n",
      "102 desejada\n",
      "21 desejado\n",
      "10 desejo\n",
      "22 desenvolvimento\n",
      "19 desfazer\n",
      "103 designa\n",
      "10 designacao\n",
      "31 designada\n",
      "52 designado\n",
      "227 designar\n",
      "18 desinstalar\n",
      "9 desist\n",
      "92 desistente\n",
      "55 desistiu\n",
      "69 desk\n",
      "16 desmembrada\n",
      "26 desmembrado\n",
      "223 desmembramento\n",
      "167 desmembrar\n",
      "23 desmembrou\n",
      "12 desmenbrar\n",
      "15 desmigra\n",
      "74 desmigrar\n",
      "52 desnecess\n",
      "9 despachar\n",
      "18 despacho\n",
      "14 destaque\n",
      "11 destinat\n",
      "26 destino\n",
      "15 desvincula\n",
      "12 desvinculada\n",
      "38 desvinculado\n",
      "68 desvincular\n",
      "21 det\n",
      "25 detalha\n",
      "162 detalhada\n",
      "334 detalhadamente\n",
      "15 detalhadas\n",
      "19 detalhado\n",
      "135 detalhamento\n",
      "55 detalhar\n",
      "79 detalhe\n",
      "63 detalhes\n",
      "107 detectados\n",
      "33 determina\n",
      "20 determinado\n",
      "94 deu\n",
      "9 deus\n",
      "24 deve\n",
      "15 dever\n",
      "36 devida\n",
      "78 devidamente\n",
      "38 devidas\n",
      "337 devido\n",
      "9 devidos\n",
      "21 devolu\n",
      "65 devolvida\n",
      "13 devolvido\n",
      "19 dez\n",
      "59 dezembro\n",
      "387 df\n",
      "44 dg\n",
      "136 di\n",
      "706 dia\n",
      "10 diana\n",
      "64 diante\n",
      "178 diaria\n",
      "21 diariamente\n",
      "57 diario\n",
      "332 dias\n",
      "24 diasnatarefa\n",
      "9 dica\n",
      "15 dico\n",
      "52 diego\n",
      "15 diferen\n",
      "158 diferente\n",
      "66 diferentes\n",
      "324 dificuldade\n",
      "79 dificuldades\n",
      "13 dig\n",
      "38 digita\n",
      "31 digitado\n",
      "24 digitais\n",
      "334 digital\n",
      "92 digitar\n",
      "27 digito\n",
      "10 digitos\n",
      "29 digitronco\n",
      "273 digo\n",
      "37 digos\n",
      "25 diniz\n",
      "13 dio\n",
      "19 diogo\n",
      "33 dir\n",
      "31 direcionada\n",
      "55 direcionado\n",
      "12 direcionamento\n",
      "16 direcionar\n",
      "48 direito\n",
      "18 diret\n",
      "29 diretamente\n",
      "47 direto\n",
      "13 diretoria\n",
      "13 diretorio\n",
      "229 dispon\n",
      "118 disponibilidade\n",
      "133 disponibiliza\n",
      "31 disponibilizada\n",
      "35 disponibilizadas\n",
      "72 disponibilizado\n",
      "31 disponibilizados\n",
      "19 disponibilizando\n",
      "53 disponibilizar\n",
      "25 disponiveis\n",
      "138 disponivel\n",
      "26 disputa\n",
      "46 dissocia\n",
      "12 dissociar\n",
      "15 dist\n",
      "16 distancia\n",
      "15 distribuicao\n",
      "36 distribuidora\n",
      "9 distrito\n",
      "117 dito\n",
      "32 ditos\n",
      "206 diverg\n",
      "111 divergencia\n",
      "10 divergencias\n",
      "97 divergente\n",
      "40 divergentes\n",
      "28 diversas\n",
      "92 diversos\n",
      "13 divina\n",
      "10 divis\n",
      "37 dizendo\n",
      "264 dk\n",
      "31 dm\n",
      "180 dn\n",
      "112 dnc\n",
      "26 doa\n",
      "39 doado\n",
      "380 doadora\n",
      "12 dobro\n",
      "288 doc\n",
      "53 documento\n",
      "13 documentoassociado\n",
      "11 docx\n",
      "162 dois\n",
      "72 dom\n",
      "34 domingos\n",
      "20 domingues\n",
      "36 dominio\n",
      "16 dores\n",
      "33 douglas\n",
      "10 dourado\n",
      "90 downgrade\n",
      "127 dp\n",
      "22 dqx\n",
      "8 ds\n",
      "71 dsa\n",
      "9 dslam\n",
      "77 dsnames\n",
      "129 dt\n",
      "18 dta\n",
      "135 dth\n",
      "55 duarte\n",
      "156 duas\n",
      "10 due\n",
      "9 dulce\n",
      "13 dulo\n",
      "25 dup\n",
      "28 dupl\n",
      "22 duplicada\n",
      "11 duplicadas\n",
      "39 duplicado\n",
      "78 duplicados\n",
      "156 duplicidade\n",
      "104 durante\n",
      "23 dutra\n",
      "48 duvidas\n",
      "39 dvr\n",
      "37 dw\n",
      "29 ea\n",
      "716 eai\n",
      "23 ebilling\n",
      "11 economica\n",
      "14 ed\n",
      "20 eder\n",
      "9 edgar\n",
      "26 edificio\n",
      "12 edilson\n",
      "9 editar\n",
      "11 edmilson\n",
      "21 edna\n",
      "27 edson\n",
      "9 eduarda\n",
      "117 eduardo\n",
      "23 educa\n",
      "13 educacao\n",
      "17 efetiva\n",
      "15 efetivar\n",
      "35 efetivo\n",
      "25 efetua\n",
      "64 efetuada\n",
      "12 efetuadas\n",
      "65 efetuado\n",
      "23 efetuamos\n",
      "58 efetuando\n",
      "384 efetuar\n",
      "40 efetuem\n",
      "141 efetuou\n",
      "15 eh\n",
      "21 eild\n",
      "38 eireli\n",
      "24 el\n",
      "27 elaine\n",
      "75 eleg\n",
      "9 elegibilidade\n",
      "104 elemento\n",
      "141 elementos\n",
      "9 eletronica\n",
      "13 eliana\n",
      "35 eliane\n",
      "37 elias\n",
      "10 elisangela\n",
      "15 elizabete\n",
      "24 elizabeth\n",
      "9 ellen\n",
      "9 elton\n",
      "9 elvira\n",
      "17 elza\n",
      "12 ema\n",
      "362 email\n",
      "10 embalagens\n",
      "19 embora\n",
      "100 embratel\n",
      "18 emerson\n",
      "8 emilia\n",
      "61 emiss\n",
      "40 emissao\n",
      "17 emitida\n",
      "10 emitido\n",
      "58 emitir\n",
      "31 emp\n",
      "13 empacotamento\n",
      "9 empr\n",
      "16 empreendimentos\n",
      "230 empresa\n",
      "8 empresariais\n",
      "91 empresarial\n",
      "15 empresas\n",
      "11 en\n",
      "20 enc\n",
      "8 encaminha\n",
      "21 encaminhada\n",
      "11 encaminhadas\n",
      "49 encaminhado\n",
      "17 encaminhados\n",
      "24 encaminhamento\n",
      "9 encaminhando\n",
      "64 encaminhar\n",
      "11 encaminhou\n",
      "54 encerra\n",
      "387 encerrada\n",
      "60 encerradas\n",
      "584 encerrado\n",
      "95 encerrados\n",
      "60 encerram\n",
      "614 encerramento\n",
      "12 encerrando\n",
      "765 encerrar\n",
      "19 encerre\n",
      "26 encerrou\n",
      "710 encontra\n",
      "104 encontrada\n",
      "10 encontradas\n",
      "248 encontrado\n",
      "24 encontrados\n",
      "354 encontram\n",
      "48 encontramos\n",
      "32 encontrar\n",
      "11 encontrasse\n",
      "12 encontravam\n",
      "110 end\n",
      "599 endere\n",
      "14 endereco\n",
      "11 energia\n",
      "8 eng\n",
      "50 engenharia\n",
      "17 engenheiros\n",
      "28 enriquecendo\n",
      "54 enriquecer\n",
      "8 enriquecidas\n",
      "17 enriquecido\n",
      "64 enriquecidos\n",
      "18 enriquecimento\n",
      "51 ent\n",
      "112 entanto\n",
      "49 entemente\n",
      "47 entender\n",
      "149 enter\n",
      "114 entra\n",
      "117 entrada\n",
      "8 entramos\n",
      "11 entrando\n",
      "273 entrar\n",
      "12 entraram\n",
      "18 entrega\n",
      "607 entregue\n",
      "152 entretanto\n",
      "9 entro\n",
      "543 entrou\n",
      "25 entry\n",
      "11 env\n",
      "43 envia\n",
      "405 enviada\n",
      "26 enviadas\n",
      "112 enviado\n",
      "35 enviados\n",
      "62 enviamos\n",
      "49 enviando\n",
      "262 enviar\n",
      "249 envio\n",
      "22 enviou\n",
      "13 envolvido\n",
      "23 envolvidos\n",
      "8 eo\n",
      "84 eot\n",
      "8 ep\n",
      "122 epp\n",
      "9 eq\n",
      "148 eqn\n",
      "8 equip\n",
      "19 equipamento\n",
      "41 equipamentos\n",
      "111 equipe\n",
      "11 er\n",
      "14 erica\n",
      "12 erika\n",
      "12 ero\n",
      "112 err\n",
      "44 errada\n",
      "76 errado\n",
      "14 errados\n",
      "1050 erro\n",
      "11 errocriandoosoms\n",
      "21 erroneamente\n",
      "25 error\n",
      "184 erros\n",
      "1629 es\n",
      "11 esb\n",
      "50 escolha\n",
      "20 escolher\n",
      "12 escopo\n",
      "12 escrito\n",
      "32 esp\n",
      "13 espa\n",
      "34 espec\n",
      "37 especiais\n",
      "96 especial\n",
      "11 especialista\n",
      "15 especificada\n",
      "21 especificado\n",
      "25 especifico\n",
      "10 espelhado\n",
      "11 espelhamento\n",
      "17 espelhar\n",
      "396 espelho\n",
      "47 espera\n",
      "20 esperado\n",
      "14 espirito\n",
      "36 esqueceu\n",
      "10 esqueci\n",
      "49 est\n",
      "85 estacao\n",
      "9 estacoes\n",
      "193 estado\n",
      "9 estados\n",
      "50 estadual\n",
      "1519 estah\n",
      "91 estando\n",
      "113 estao\n",
      "210 estar\n",
      "28 estarem\n",
      "9 esteves\n",
      "34 estimado\n",
      "11 estoque\n",
      "14 estornado\n",
      "54 estorno\n",
      "28 estourado\n",
      "21 estudo\n",
      "47 etapa\n",
      "12 etapas\n",
      "70 etc\n",
      "10 eth\n",
      "10 etiquetas\n",
      "9 etx\n",
      "9 eugenio\n",
      "16 eunice\n",
      "13 eustaquio\n",
      "17 ev\n",
      "19 eva\n",
      "14 evandro\n",
      "19 evangelista\n",
      "199 evento\n",
      "227 eventos\n",
      "16 eventual\n",
      "10 everton\n",
      "1559 evid\n",
      "505 evidencia\n",
      "21 evidenciada\n",
      "267 evidenciado\n",
      "592 evidencias\n",
      "77 evitar\n",
      "12 evolu\n",
      "54 ex\n",
      "17 exce\n",
      "12 excedente\n",
      "26 excedentes\n",
      "11 excedido\n",
      "16 excel\n",
      "32 exceto\n",
      "65 exclu\n",
      "19 excluido\n",
      "94 excluir\n",
      "59 exclus\n",
      "23 exclusao\n",
      "252 exclusiva\n",
      "10 exclusivo\n",
      "65 exec\n",
      "281 execu\n",
      "256 execucao\n",
      "37 executa\n",
      "174 executada\n",
      "26 executadas\n",
      "119 executado\n",
      "13 executados\n",
      "269 executando\n",
      "316 executar\n",
      "128 exemplo\n",
      "110 exemplos\n",
      "35 exibe\n",
      "18 exibida\n",
      "35 exibido\n",
      "11 exibir\n",
      "9 exige\n",
      "11 exigida\n",
      "38 exist\n",
      "422 existe\n",
      "159 existem\n",
      "94 existente\n",
      "19 existentes\n",
      "9 existia\n",
      "281 expediter\n",
      "125 expert\n",
      "10 expira\n",
      "16 expirada\n",
      "39 expirado\n",
      "11 expirados\n",
      "20 expirou\n",
      "22 explica\n",
      "14 explicar\n",
      "78 explorer\n",
      "40 exposta\n",
      "45 exposto\n",
      "152 ext\n",
      "28 externa\n",
      "43 external\n",
      "32 externo\n",
      "69 extra\n",
      "47 extracao\n",
      "24 extrai\n",
      "10 extrair\n",
      "46 extrator\n",
      "9 extratos\n",
      "34 fa\n",
      "42 fabiana\n",
      "11 fabiane\n",
      "29 fabiano\n",
      "88 fabio\n",
      "19 fabrica\n",
      "25 fabricio\n",
      "26 fac\n",
      "40 fachada\n",
      "282 facilidade\n",
      "140 facilidades\n",
      "18 fagundes\n",
      "87 faixa\n",
      "15 fala\n",
      "11 falamos\n",
      "30 falar\n",
      "52 fale\n",
      "526 falha\n",
      "33 falhas\n",
      "94 falta\n",
      "32 faltando\n",
      "11 faltantes\n",
      "225 fam\n",
      "223 familia\n",
      "49 faria\n",
      "46 farias\n",
      "9 fase\n",
      "51 fast\n",
      "16 fastfu\n",
      "12 fastvb\n",
      "56 fastve\n",
      "114 fat\n",
      "92 fatima\n",
      "40 fato\n",
      "548 fatura\n",
      "13 faturadas\n",
      "72 faturado\n",
      "22 faturados\n",
      "400 faturamento\n",
      "15 faturamentos\n",
      "100 faturando\n",
      "32 faturar\n",
      "443 faturas\n",
      "14 faturou\n",
      "19 favo\n",
      "1581 favor\n",
      "103 faz\n",
      "23 fazem\n",
      "47 fazemos\n",
      "11 fbb\n",
      "26 fbltv\n",
      "54 fd\n",
      "16 feb\n",
      "20 febraban\n",
      "30 fecha\n",
      "250 fechada\n",
      "83 fechadas\n",
      "713 fechado\n",
      "173 fechados\n",
      "936 fechamento\n",
      "14 fechamos\n",
      "11 fechando\n",
      "343 fechar\n",
      "26 fechou\n",
      "10 federacao\n",
      "74 federal\n",
      "49 fego\n",
      "9 feijo\n",
      "15 feira\n",
      "13 feitosa\n",
      "9 felicio\n",
      "92 felipe\n",
      "21 felix\n",
      "36 fen\n",
      "82 fernanda\n",
      "127 fernandes\n",
      "138 fernando\n",
      "271 ferramenta\n",
      "14 ferramentas\n",
      "10 ferrari\n",
      "13 ferraz\n",
      "257 ferreira\n",
      "18 fev\n",
      "122 fevereiro\n",
      "160 fez\n",
      "16 ff\n",
      "13 fhynbeen\n",
      "12 fi\n",
      "8 fialho\n",
      "1596 fibra\n",
      "235 fica\n",
      "9 ficado\n",
      "30 ficam\n",
      "106 ficando\n",
      "53 ficar\n",
      "24 ficaram\n",
      "86 ficha\n",
      "78 fico\n",
      "15 ficos\n",
      "282 ficou\n",
      "107 fict\n",
      "56 ficticio\n",
      "543 fid\n",
      "14 fidel\n",
      "15 fidelidade\n",
      "19 fideliza\n",
      "11 figueira\n",
      "58 figueiredo\n",
      "434 fila\n",
      "27 filas\n",
      "36 file\n",
      "113 filho\n",
      "34 filiais\n",
      "175 filial\n",
      "92 fim\n",
      "21 finais\n",
      "164 final\n",
      "171 finaliza\n",
      "59 finalizada\n",
      "17 finalizadas\n",
      "186 finalizado\n",
      "10 finalizando\n",
      "211 finalizar\n",
      "49 financeira\n",
      "142 financeiro\n",
      "62 fique\n",
      "23 fiquem\n",
      "16 firefox\n",
      "14 fiscais\n",
      "54 fiscal\n",
      "24 fisica\n",
      "9 fisicamente\n",
      "90 fisico\n",
      "35 fix\n",
      "354 fixa\n",
      "15 fixas\n",
      "2946 fixo\n",
      "22 fixos\n",
      "23 fiz\n",
      "30 fizemos\n",
      "14 fizeram\n",
      "9 fj\n",
      "63 fla\n",
      "205 flag\n",
      "75 flat\n",
      "36 flavia\n",
      "43 flavio\n",
      "13 fleg\n",
      "12 flegue\n",
      "22 flex\n",
      "23 flg\n",
      "32 flores\n",
      "90 fluxo\n",
      "20 fm\n",
      "18 fnb\n",
      "211 fns\n",
      "11 focal\n",
      "162 fone\n",
      "69 fonseca\n",
      "11 fonte\n",
      "18 fontes\n",
      "260 forma\n",
      "16 forms\n",
      "24 fortaleza\n",
      "11 fortuna\n",
      "18 found\n",
      "85 fr\n",
      "32 fraga\n",
      "18 frame\n",
      "24 franca\n",
      "9 franciele\n",
      "57 francisca\n",
      "128 francisco\n",
      "36 franco\n",
      "468 franquia\n",
      "28 franquias\n",
      "133 fraude\n",
      "15 frederico\n",
      "25 freire\n",
      "117 freitas\n",
      "10 from\n",
      "50 frqvc\n",
      "9 fs\n",
      "47 ft\n",
      "26 ftp\n",
      "26 ftv\n",
      "23 full\n",
      "25 fun\n",
      "28 funciona\n",
      "47 funcional\n",
      "47 funcionalidade\n",
      "9 funcionalidades\n",
      "20 funcionamento\n",
      "65 funcionando\n",
      "24 funcionar\n",
      "16 funcionou\n",
      "15 fundacao\n",
      "14 fundo\n",
      "16 furtado\n",
      "13 futuras\n",
      "11 futuro\n",
      "20 fv\n",
      "44 fvr\n",
      "10 fx\n",
      "49 ga\n",
      "986 gaap\n",
      "36 gabriel\n",
      "27 gabriela\n",
      "9 gabrielle\n",
      "10 galdino\n",
      "11 galera\n",
      "14 galvao\n",
      "14 gama\n",
      "106 garantir\n",
      "50 garcia\n",
      "12 garimpo\n",
      "13 gas\n",
      "397 gb\n",
      "81 gcob\n",
      "9 gd\n",
      "430 gde\n",
      "40 gdes\n",
      "16 ge\n",
      "52 geco\n",
      "22 ged\n",
      "32 gen\n",
      "11 generico\n",
      "29 geneva\n",
      "387 gentileza\n",
      "56 ger\n",
      "443 gera\n",
      "25 geracao\n",
      "227 gerada\n",
      "81 geradas\n",
      "318 gerado\n",
      "50 gerados\n",
      "26 gerais\n",
      "35 geral\n",
      "43 geraldo\n",
      "11 geralmente\n",
      "10 geramos\n",
      "318 gerando\n",
      "555 gerar\n",
      "27 geraram\n",
      "11 gere\n",
      "39 gerei\n",
      "21 gerencia\n",
      "18 gerenciamento\n",
      "38 gerenciar\n",
      "35 gerente\n",
      "11 gero\n",
      "503 gerou\n",
      "13 gerson\n",
      "24 gest\n",
      "103 gestor\n",
      "10 gestores\n",
      "15 getnet\n",
      "11 gf\n",
      "165 gfr\n",
      "14 gi\n",
      "39 gica\n",
      "9 gid\n",
      "31 gilberto\n",
      "18 gilmar\n",
      "23 gilson\n",
      "48 gina\n",
      "16 gisele\n",
      "24 gl\n",
      "18 global\n",
      "18 globalweb\n",
      "14 globo\n",
      "18 gloria\n",
      "199 gmail\n",
      "21 gmud\n",
      "264 gna\n",
      "466 go\n",
      "15 goes\n",
      "9 goi\n",
      "13 goias\n",
      "181 gomes\n",
      "35 gon\n",
      "161 goncalves\n",
      "9 gontijo\n",
      "10 gonzaga\n",
      "37 google\n",
      "57 gostaria\n",
      "14 goulart\n",
      "9 gouveia\n",
      "10 gov\n",
      "10 governo\n",
      "126 gpon\n",
      "10 gpp\n",
      "40 gprs\n",
      "44 gr\n",
      "76 gra\n",
      "33 gracas\n",
      "24 grade\n",
      "14 grafico\n",
      "63 granite\n",
      "221 grata\n",
      "204 grato\n",
      "18 gratuito\n",
      "20 grava\n",
      "19 graziela\n",
      "33 grosso\n",
      "1003 group\n",
      "9 grta\n",
      "56 grupo\n",
      "24 gse\n",
      "43 gsm\n",
      "26 gt\n",
      "10 gtf\n",
      "12 gua\n",
      "18 guedes\n",
      "12 guerra\n",
      "45 guia\n",
      "55 guilherme\n",
      "72 guimaraes\n",
      "58 gustavo\n",
      "51 gvt\n",
      "1556 ha\n",
      "168 habilita\n",
      "28 habilitada\n",
      "86 habilitado\n",
      "87 habilitar\n",
      "24 havendo\n",
      "58 haver\n",
      "30 havia\n",
      "27 hb\n",
      "97 hd\n",
      "104 hdca\n",
      "16 hdcbj\n",
      "15 hdck\n",
      "85 helena\n",
      "15 helio\n",
      "39 help\n",
      "134 henrique\n",
      "17 hibrido\n",
      "22 hierarquia\n",
      "221 hist\n",
      "22 histo\n",
      "60 historico\n",
      "10 hl\n",
      "89 hlr\n",
      "18 hlrbsi\n",
      "12 hoa\n",
      "25 hob\n",
      "79 hoje\n",
      "10 holanda\n",
      "16 home\n",
      "58 hor\n",
      "199 hora\n",
      "15 horario\n",
      "482 horas\n",
      "23 horasnatarefa\n",
      "48 horizonte\n",
      "37 hot\n",
      "119 hotline\n",
      "162 hotmail\n",
      "60 hrs\n",
      "129 hs\n",
      "91 htcd\n",
      "13 htce\n",
      "564 http\n",
      "13 hugo\n",
      "13 humberto\n",
      "114 ia\n",
      "33 ib\n",
      "268 ic\n",
      "27 iccid\n",
      "10 icms\n",
      "591 ics\n",
      "13 icsldrparc\n",
      "482 id\n",
      "9 ida\n",
      "66 iddaordem\n",
      "55 ident\n",
      "22 identifica\n",
      "21 identificada\n",
      "209 identificado\n",
      "77 identificador\n",
      "17 identificados\n",
      "93 identificamos\n",
      "14 identificando\n",
      "181 identificar\n",
      "13 identificou\n",
      "11 identifiquei\n",
      "16 idpositivo\n",
      "15 ids\n",
      "87 ie\n",
      "9 ieda\n",
      "15 if\n",
      "12 iffd\n",
      "13 ig\n",
      "8 ignorando\n",
      "16 igor\n",
      "100 igual\n",
      "9 ih\n",
      "11 ii\n",
      "8 iig\n",
      "9 ijal\n",
      "35 ijb\n",
      "20 il\n",
      "19 ilha\n",
      "15 ilim\n",
      "16 ilimitada\n",
      "15 ilimitadas\n",
      "73 ilimitado\n",
      "21 ilimitados\n",
      "20 imagem\n",
      "60 imagens\n",
      "44 imediatamente\n",
      "16 imediato\n",
      "10 imei\n",
      "9 imeis\n",
      "9 imobiliaria\n",
      "9 imobiliarios\n",
      "10 imoveis\n",
      "67 imp\n",
      "25 impacta\n",
      "19 impactada\n",
      "11 impactadas\n",
      "14 impactado\n",
      "26 impactados\n",
      "146 impactando\n",
      "53 impacto\n",
      "14 impe\n",
      "137 impede\n",
      "13 impedi\n",
      "81 impedida\n",
      "11 impedidas\n",
      "39 impedido\n",
      "107 impedimento\n",
      "356 impedindo\n",
      "9 impedir\n",
      "27 impeditivo\n",
      "13 impendindo\n",
      "17 implanta\n",
      "85 implantar\n",
      "9 importa\n",
      "11 importacao\n",
      "9 importante\n",
      "21 impossibilidade\n",
      "62 impossibilita\n",
      "34 impossibilitado\n",
      "323 impossibilitando\n",
      "8 impossibilitanto\n",
      "14 imposto\n",
      "15 impress\n",
      "32 imprimir\n",
      "13 improcedente\n",
      "21 imput\n",
      "10 imputar\n",
      "68 imsi\n",
      "132 in\n",
      "17 inacio\n",
      "148 inadimpl\n",
      "46 inadimplencia\n",
      "33 inadimplente\n",
      "9 inadimplentes\n",
      "20 inadiplencia\n",
      "168 inativa\n",
      "15 inativacao\n",
      "32 inativado\n",
      "22 inativados\n",
      "9 inativando\n",
      "109 inativar\n",
      "41 inativas\n",
      "246 inativo\n",
      "69 inativos\n",
      "39 inativou\n",
      "212 incentiva\n",
      "114 incidente\n",
      "9 incidentes\n",
      "69 inclu\n",
      "12 inclua\n",
      "20 inclui\n",
      "10 incluido\n",
      "17 incluindo\n",
      "252 incluir\n",
      "201 inclus\n",
      "23 inclusa\n",
      "18 inclusao\n",
      "15 inclusas\n",
      "24 inclusive\n",
      "44 incluso\n",
      "35 inclusos\n",
      "98 incompat\n",
      "35 incompatibilidade\n",
      "71 incompativel\n",
      "10 incompleto\n",
      "99 inconsist\n",
      "13 inconsistencia\n",
      "38 inconsistente\n",
      "26 inconsistentes\n",
      "48 incorreta\n",
      "23 incorretamente\n",
      "101 incorreto\n",
      "130 incorretos\n",
      "49 ind\n",
      "16 independente\n",
      "17 indeterminado\n",
      "161 indevida\n",
      "259 indevidamente\n",
      "61 indevidas\n",
      "160 indevido\n",
      "23 indevidos\n",
      "35 indica\n",
      "24 indicador\n",
      "14 indicadores\n",
      "162 indispon\n",
      "34 indisponibilidade\n",
      "103 indisponivel\n",
      "15 individual\n",
      "29 indo\n",
      "71 industria\n",
      "19 ines\n",
      "10 inesistente\n",
      "30 inesperado\n",
      "285 inexistente\n",
      "41 inexistentes\n",
      "22 inf\n",
      "34 inferior\n",
      "23 infnc\n",
      "19 info\n",
      "9 inform\n",
      "2690 informa\n",
      "47 informacoes\n",
      "113 informada\n",
      "16 informadas\n",
      "511 informado\n",
      "55 informados\n",
      "10 informam\n",
      "9 informamos\n",
      "552 informando\n",
      "218 informar\n",
      "18 informaram\n",
      "67 informatica\n",
      "125 informe\n",
      "15 informo\n",
      "316 informou\n",
      "10 ingl\n",
      "13 ingrid\n",
      "18 inibi\n",
      "80 inibidos\n",
      "15 inibir\n",
      "30 iniciada\n",
      "13 iniciais\n",
      "155 inicial\n",
      "28 iniciar\n",
      "51 inicio\n",
      "23 iniciodatarefa\n",
      "9 iniciou\n",
      "19 input\n",
      "103 ins\n",
      "199 insadsl\n",
      "10 insagrrw\n",
      "20 insantvir\n",
      "11 insapoio\n",
      "12 insatisfeito\n",
      "9 insblo\n",
      "11 inscirc\n",
      "24 inscomod\n",
      "12 inscorins\n",
      "37 inscpe\n",
      "44 inser\n",
      "17 insere\n",
      "24 inserida\n",
      "9 inseridas\n",
      "125 inserido\n",
      "23 inseridos\n",
      "9 inserindo\n",
      "214 inserir\n",
      "24 insfastfu\n",
      "406 insfastve\n",
      "13 insinet\n",
      "22 insmodcli\n",
      "23 insnfilim\n",
      "23 insnfm\n",
      "89 insoitot\n",
      "24 inspcte\n",
      "98 insplano\n",
      "20 inspor\n",
      "514 inst\n",
      "20 insta\n",
      "20 instal\n",
      "700 instala\n",
      "263 instalacao\n",
      "136 instalada\n",
      "20 instaladas\n",
      "366 instalado\n",
      "70 instalados\n",
      "357 instalar\n",
      "9 instalou\n",
      "34 instance\n",
      "76 instancia\n",
      "159 instancias\n",
      "17 instituto\n",
      "105 int\n",
      "54 intcel\n",
      "697 integra\n",
      "9 integradas\n",
      "15 integrado\n",
      "12 integral\n",
      "26 intelig\n",
      "9 intenret\n",
      "53 inter\n",
      "17 intera\n",
      "21 intercepta\n",
      "14 interesse\n",
      "699 interface\n",
      "32 interfaces\n",
      "20 interfacesbcv\n",
      "16 interm\n",
      "53 intermedi\n",
      "65 intermediario\n",
      "12 intermitente\n",
      "41 interna\n",
      "38 internacionais\n",
      "35 internacional\n",
      "12 internaliza\n",
      "13 internalizados\n",
      "314 internet\n",
      "52 interno\n",
      "27 interopera\n",
      "10 interoperacao\n",
      "16 interrompida\n",
      "31 interven\n",
      "9 intra\n",
      "23 intragrupo\n",
      "10 intranet\n",
      "27 intrarrede\n",
      "360 inv\n",
      "26 inva\n",
      "11 inval\n",
      "107 invalida\n",
      "233 invalido\n",
      "80 invalidos\n",
      "107 investiga\n",
      "47 investigado\n",
      "232 investigar\n",
      "167 investigativa\n",
      "10 investigue\n",
      "24 inviabilidade\n",
      "9 iolanda\n",
      "10 ione\n",
      "134 ip\n",
      "17 ipc\n",
      "121 iptv\n",
      "93 ir\n",
      "16 ira\n",
      "15 iracema\n",
      "9 iremos\n",
      "11 irene\n",
      "11 iria\n",
      "12 irla\n",
      "9 irmaos\n",
      "47 is\n",
      "27 isabel\n",
      "9 isabela\n",
      "54 isen\n",
      "25 isentar\n",
      "21 isento\n",
      "17 israel\n",
      "32 it\n",
      "12 ita\n",
      "21 itau\n",
      "66 item\n",
      "60 itens\n",
      "22 ivan\n",
      "10 ivo\n",
      "17 ivone\n",
      "9 ivonete\n",
      "21 izabel\n",
      "387 ja\n",
      "16 jacarepagua\n",
      "9 jackson\n",
      "14 jair\n",
      "10 jairo\n",
      "9 jamc\n",
      "19 jan\n",
      "19 janaina\n",
      "13 jane\n",
      "122 janeiro\n",
      "173 janela\n",
      "10 janete\n",
      "42 jaqueline\n",
      "24 jardim\n",
      "9 jb\n",
      "28 jean\n",
      "19 jec\n",
      "21 jeferson\n",
      "22 jefferson\n",
      "48 jessica\n",
      "132 jesus\n",
      "31 jfa\n",
      "9 jffd\n",
      "44 jo\n",
      "23 joana\n",
      "138 joao\n",
      "23 joaquim\n",
      "1106 job\n",
      "669 jobid\n",
      "10 jobs\n",
      "22 joel\n",
      "10 jogar\n",
      "19 joice\n",
      "9 jonas\n",
      "54 jorge\n",
      "39 jos\n",
      "211 jose\n",
      "12 josefa\n",
      "12 josiane\n",
      "11 joyce\n",
      "20 jpa\n",
      "10 jti\n",
      "214 judicial\n",
      "16 jul\n",
      "101 julho\n",
      "16 julia\n",
      "60 juliana\n",
      "17 juliano\n",
      "40 julio\n",
      "57 jumper\n",
      "58 jumpers\n",
      "9 jun\n",
      "80 junho\n",
      "20 junio\n",
      "162 junior\n",
      "45 juntamente\n",
      "98 junto\n",
      "24 jur\n",
      "39 juros\n",
      "50 justica\n",
      "18 jve\n",
      "16 karina\n",
      "15 karine\n",
      "21 karla\n",
      "51 katia\n",
      "12 kb\n",
      "25 kbps\n",
      "49 keller\n",
      "45 kelly\n",
      "18 ken\n",
      "245 kenpx\n",
      "9 key\n",
      "155 kit\n",
      "10 kleber\n",
      "81 la\n",
      "21 lacerda\n",
      "198 lado\n",
      "9 lago\n",
      "76 lais\n",
      "113 lan\n",
      "18 lara\n",
      "176 larga\n",
      "21 larissa\n",
      "23 las\n",
      "25 laura\n",
      "12 layout\n",
      "9 lazaro\n",
      "10 lcg\n",
      "8 lch\n",
      "10 lculo\n",
      "445 ld\n",
      "24 ldi\n",
      "16 lditotal\n",
      "72 ldn\n",
      "12 ldntotal\n",
      "9 le\n",
      "35 leal\n",
      "80 leandro\n",
      "9 legada\n",
      "141 legado\n",
      "133 legados\n",
      "16 leitao\n",
      "64 leite\n",
      "16 leitura\n",
      "19 lembra\n",
      "77 lembramos\n",
      "22 lembrando\n",
      "10 lemes\n",
      "17 lemos\n",
      "31 lentid\n",
      "74 leonardo\n",
      "21 leticia\n",
      "70 levantamento\n",
      "20 levantamentos\n",
      "32 levantar\n",
      "13 lfe\n",
      "27 lg\n",
      "96 li\n",
      "238 lia\n",
      "35 lib\n",
      "478 libera\n",
      "20 liberacao\n",
      "289 liberada\n",
      "60 liberadas\n",
      "83 liberado\n",
      "18 liberados\n",
      "17 liberamos\n",
      "17 liberando\n",
      "381 liberar\n",
      "8 liberem\n",
      "9 liberou\n",
      "238 lico\n",
      "72 lida\n",
      "18 lidas\n",
      "9 lider\n",
      "8 lidia\n",
      "10 lidiane\n",
      "154 lido\n",
      "153 lidos\n",
      "11 liente\n",
      "297 liga\n",
      "10 ligado\n",
      "8 ligados\n",
      "25 ligar\n",
      "246 light\n",
      "8 ligmix\n",
      "9 ligou\n",
      "15 lilian\n",
      "11 liliane\n",
      "240 lima\n",
      "94 limbo\n",
      "13 limitada\n",
      "47 limite\n",
      "16 limites\n",
      "71 limpar\n",
      "44 limpeza\n",
      "35 line\n",
      "45 linh\n",
      "915 linha\n",
      "9 linhares\n",
      "514 linhas\n",
      "50 link\n",
      "9 lino\n",
      "13 lins\n",
      "64 lio\n",
      "10 lira\n",
      "18 lisboa\n",
      "175 lise\n",
      "30 lises\n",
      "11 list\n",
      "98 lista\n",
      "13 listada\n",
      "14 listadas\n",
      "113 listados\n",
      "40 listagem\n",
      "13 listando\n",
      "25 listar\n",
      "9 literal\n",
      "14 live\n",
      "19 livia\n",
      "17 livre\n",
      "13 lobo\n",
      "79 loc\n",
      "34 locais\n",
      "266 local\n",
      "395 localidade\n",
      "29 localidades\n",
      "29 localiza\n",
      "39 localizada\n",
      "77 localizado\n",
      "10 localizamos\n",
      "43 localizar\n",
      "12 loctotal\n",
      "87 log\n",
      "9 loga\n",
      "10 logadas\n",
      "55 logar\n",
      "68 logi\n",
      "463 login\n",
      "58 logins\n",
      "14 logistica\n",
      "75 logo\n",
      "72 logradouro\n",
      "21 logradouros\n",
      "42 logs\n",
      "9 loguin\n",
      "143 loja\n",
      "19 lojas\n",
      "143 lojista\n",
      "28 longa\n",
      "153 lopes\n",
      "11 lorena\n",
      "56 los\n",
      "33 lote\n",
      "11 louise\n",
      "51 lourdes\n",
      "20 lourenco\n",
      "16 lpa\n",
      "26 lt\n",
      "11 ltd\n",
      "197 ltda\n",
      "20 ltiplo\n",
      "14 luan\n",
      "34 luana\n",
      "70 lucas\n",
      "124 lucia\n",
      "51 luciana\n",
      "13 luciane\n",
      "34 luciano\n",
      "14 luciene\n",
      "9 lucimar\n",
      "24 lucio\n",
      "16 lugar\n",
      "91 luis\n",
      "194 luiz\n",
      "38 luiza\n",
      "29 lula\n",
      "12 lurdes\n",
      "44 luz\n",
      "21 luzia\n",
      "10 lw\n",
      "13 lyra\n",
      "59 ma\n",
      "41 macedo\n",
      "118 machado\n",
      "34 maciel\n",
      "149 macro\n",
      "23 macros\n",
      "20 madalena\n",
      "81 mae\n",
      "42 magalhaes\n",
      "11 magno\n",
      "26 mahi\n",
      "42 maia\n",
      "168 mail\n",
      "58 mailing\n",
      "12 mails\n",
      "90 maio\n",
      "49 maior\n",
      "95 maiores\n",
      "10 maioria\n",
      "12 maira\n",
      "10 manda\n",
      "12 mandar\n",
      "18 maneira\n",
      "12 manh\n",
      "15 manobra\n",
      "59 manoel\n",
      "13 mantendo\n",
      "30 manter\n",
      "14 manteve\n",
      "162 manual\n",
      "323 manualmente\n",
      "12 manuel\n",
      "20 manuten\n",
      "9 manutencao\n",
      "15 maquina\n",
      "14 maquinas\n",
      "335 mar\n",
      "34 mara\n",
      "59 marca\n",
      "54 marcado\n",
      "10 marcados\n",
      "72 marcar\n",
      "9 marcel\n",
      "17 marcelino\n",
      "124 marcelo\n",
      "103 marcia\n",
      "68 marcio\n",
      "80 marco\n",
      "124 marcos\n",
      "19 marcus\n",
      "9 margarete\n",
      "12 margarida\n",
      "245 maria\n",
      "39 mariana\n",
      "20 mariane\n",
      "25 mariano\n",
      "16 marilene\n",
      "13 marilia\n",
      "10 marina\n",
      "26 marinho\n",
      "10 marint\n",
      "29 mario\n",
      "11 marisa\n",
      "10 mariza\n",
      "33 marketing\n",
      "35 marlene\n",
      "21 marli\n",
      "130 marques\n",
      "9 mart\n",
      "27 marta\n",
      "10 martha\n",
      "10 martinez\n",
      "182 martins\n",
      "9 mary\n",
      "22 masc\n",
      "9 mascara\n",
      "69 massa\n",
      "68 massivo\n",
      "28 master\n",
      "14 mat\n",
      "54 materiais\n",
      "25 mateus\n",
      "28 matheus\n",
      "12 matias\n",
      "36 mato\n",
      "43 matos\n",
      "71 matr\n",
      "60 matricula\n",
      "78 matriculas\n",
      "9 matriz\n",
      "22 mattos\n",
      "40 mauricio\n",
      "20 mauro\n",
      "14 max\n",
      "11 maxima\n",
      "13 maximo\n",
      "9 mayara\n",
      "340 mb\n",
      "25 mbps\n",
      "8 mc\n",
      "11 mce\n",
      "9 mcl\n",
      "31 mco\n",
      "17 md\n",
      "9 mecanica\n",
      "61 medeiros\n",
      "35 media\n",
      "13 mediante\n",
      "9 medica\n",
      "11 medicamentos\n",
      "8 medicos\n",
      "13 medina\n",
      "114 medio\n",
      "67 mega\n",
      "73 megas\n",
      "364 meio\n",
      "93 meios\n",
      "11 meira\n",
      "35 melhor\n",
      "46 mello\n",
      "101 melo\n",
      "10 memso\n",
      "19 mencionado\n",
      "104 mendes\n",
      "31 mendonca\n",
      "48 menezes\n",
      "64 menor\n",
      "47 menos\n",
      "486 mensagem\n",
      "34 mensagens\n",
      "15 mensais\n",
      "54 mensal\n",
      "10 mensalmente\n",
      "132 menu\n",
      "29 mercado\n",
      "25 merge\n",
      "913 mero\n",
      "115 meros\n",
      "52 mes\n",
      "79 meses\n",
      "37 mesquita\n",
      "13 messias\n",
      "245 met\n",
      "10 metalico\n",
      "12 metalurgica\n",
      "16 metro\n",
      "28 metroeth\n",
      "10 metros\n",
      "599 mg\n",
      "9 mge\n",
      "26 mgid\n",
      "101 mi\n",
      "116 mica\n",
      "10 micas\n",
      "10 michael\n",
      "10 michel\n",
      "19 michele\n",
      "18 michelle\n",
      "166 mico\n",
      "133 micro\n",
      "15 micros\n",
      "44 mig\n",
      "687 migra\n",
      "21 migracao\n",
      "43 migrada\n",
      "22 migradas\n",
      "148 migrado\n",
      "23 migrador\n",
      "37 migrados\n",
      "20 migrando\n",
      "297 migrar\n",
      "26 migraram\n",
      "143 migrou\n",
      "39 miguel\n",
      "20 mil\n",
      "15 militar\n",
      "12 milton\n",
      "73 min\n",
      "27 minas\n",
      "15 minhaoi\n",
      "102 mini\n",
      "97 miniciclo\n",
      "14 ministerio\n",
      "168 minutos\n",
      "82 miranda\n",
      "10 miriam\n",
      "22 mirian\n",
      "13 miscelaneous\n",
      "40 mite\n",
      "144 mix\n",
      "39 mkt\n",
      "12 mktrel\n",
      "20 mm\n",
      "36 mms\n",
      "26 mns\n",
      "24 mobile\n",
      "16 mobilidade\n",
      "35 modalidade\n",
      "9 modas\n",
      "35 modelo\n",
      "210 modem\n",
      "9 modens\n",
      "132 modifica\n",
      "13 modificado\n",
      "34 modificar\n",
      "25 modo\n",
      "132 modulo\n",
      "11 moises\n",
      "241 momento\n",
      "172 mon\n",
      "11 monet\n",
      "27 monica\n",
      "12 monit\n",
      "57 monitor\n",
      "13 monitoracao\n",
      "18 monitorar\n",
      "10 monte\n",
      "80 monteiro\n",
      "12 monthly\n",
      "102 moraes\n",
      "62 morais\n",
      "121 moreira\n",
      "11 moreno\n",
      "44 mos\n",
      "195 mostra\n",
      "12 mostrado\n",
      "18 mostrando\n",
      "25 mota\n",
      "308 motivo\n",
      "11 motivos\n",
      "19 motta\n",
      "88 moura\n",
      "15 mov\n",
      "88 moveis\n",
      "496 movel\n",
      "17 mover\n",
      "23 movimento\n",
      "10 mozila\n",
      "76 mozilla\n",
      "14 mpa\n",
      "74 mpn\n",
      "540 ms\n",
      "49 msg\n",
      "364 msisdn\n",
      "52 msisdns\n",
      "23 mssisdn\n",
      "22 msz\n",
      "33 mszc\n",
      "277 mt\n",
      "11 mu\n",
      "11 mua\n",
      "118 mud\n",
      "47 muda\n",
      "516 mudan\n",
      "18 mudanca\n",
      "10 mudando\n",
      "92 mudar\n",
      "12 mudarea\n",
      "87 mudend\n",
      "57 mudext\n",
      "185 mudinho\n",
      "35 mudla\n",
      "9 mudloc\n",
      "43 mudou\n",
      "40 mudporta\n",
      "28 mudqlinha\n",
      "17 muller\n",
      "209 multa\n",
      "37 multas\n",
      "14 multi\n",
      "34 multiplicidade\n",
      "11 multiproduto\n",
      "61 multiprodutos\n",
      "9 mundo\n",
      "19 munic\n",
      "60 municipal\n",
      "60 municipio\n",
      "18 muniz\n",
      "9 murilo\n",
      "47 nacional\n",
      "72 nada\n",
      "17 nadia\n",
      "12 nadir\n",
      "145 name\n",
      "683 nao\n",
      "22 nara\n",
      "188 nasc\n",
      "313 nascimento\n",
      "82 nat\n",
      "11 natal\n",
      "48 natalia\n",
      "21 nathalia\n",
      "44 navegador\n",
      "88 navegadores\n",
      "10 nayara\n",
      "10 nazare\n",
      "25 nba\n",
      "48 nc\n",
      "2559 ncia\n",
      "11 nciado\n",
      "13 ncial\n",
      "1313 ncias\n",
      "10 nculo\n",
      "10 nds\n",
      "12 ne\n",
      "315 necess\n",
      "10 necessarias\n",
      "90 necessario\n",
      "28 necessidade\n",
      "44 necessita\n",
      "51 necessitam\n",
      "19 necessitamos\n",
      "27 necessito\n",
      "28 neg\n",
      "37 negado\n",
      "13 negocia\n",
      "15 negocio\n",
      "14 negocios\n",
      "9 neide\n",
      "35 nelson\n",
      "232 nenhuma\n",
      "9 neogrid\n",
      "11 nery\n",
      "57 nesse\n",
      "14 nesses\n",
      "97 neste\n",
      "117 net\n",
      "9 netb\n",
      "14 netiwn\n",
      "84 neto\n",
      "10 netprd\n",
      "38 netwin\n",
      "26 neuza\n",
      "61 neves\n",
      "41 nextel\n",
      "23 nf\n",
      "9 nffd\n",
      "14 nia\n",
      "154 nica\n",
      "16 nicas\n",
      "29 nico\n",
      "9 nilson\n",
      "9 nilton\n",
      "14 nilza\n",
      "93 nimo\n",
      "75 nio\n",
      "24 niter\n",
      "16 niteroi\n",
      "25 niu\n",
      "208 nivel\n",
      "16 nm\n",
      "26 nnf\n",
      "63 nobill\n",
      "11 nobre\n",
      "104 noc\n",
      "26 node\n",
      "987 nodeid\n",
      "50 nogueira\n",
      "112 noite\n",
      "50 nok\n",
      "876 nome\n",
      "18 nomenclatura\n",
      "11 nomes\n",
      "17 nonato\n",
      "14 noncat\n",
      "127 norm\n",
      "10 norma\n",
      "12 normais\n",
      "198 normal\n",
      "11 normalizado\n",
      "138 normalmente\n",
      "10 norte\n",
      "24 not\n",
      "105 nota\n",
      "37 notas\n",
      "16 notifica\n",
      "12 nov\n",
      "239 nova\n",
      "14 novaes\n",
      "128 novamente\n",
      "38 novas\n",
      "21 novembro\n",
      "423 novo\n",
      "79 novos\n",
      "23 np\n",
      "61 npac\n",
      "55 nr\n",
      "275 nrc\n",
      "25 nrcs\n",
      "43 nres\n",
      "38 nri\n",
      "21 nro\n",
      "14 nrs\n",
      "16 ns\n",
      "11 nsc\n",
      "29 nt\n",
      "78 ntcd\n",
      "26 ntce\n",
      "12 ntcm\n",
      "31 ntl\n",
      "11 nu\n",
      "62 null\n",
      "16 nulo\n",
      "11 number\n",
      "11 numera\n",
      "13 numeracao\n",
      "20 numerador\n",
      "580 numero\n",
      "40 numeros\n",
      "96 nunes\n",
      "341 nus\n",
      "11 oa\n",
      "13 obj\n",
      "39 objectel\n",
      "12 obriga\n",
      "200 obrigada\n",
      "193 obrigado\n",
      "155 obrigat\n",
      "9 obrigatorio\n",
      "493 obs\n",
      "66 observa\n",
      "10 observar\n",
      "10 obter\n",
      "15 obteve\n",
      "14 ocasionando\n",
      "10 occurred\n",
      "14 ocm\n",
      "440 oco\n",
      "83 ocorr\n",
      "40 ocorra\n",
      "320 ocorre\n",
      "14 ocorrencia\n",
      "150 ocorrendo\n",
      "35 ocorrer\n",
      "12 ocorreram\n",
      "419 ocorreu\n",
      "10 ocorrida\n",
      "41 ocorrido\n",
      "40 ocos\n",
      "162 ocs\n",
      "388 oct\n",
      "13 octlight\n",
      "51 ocupado\n",
      "12 od\n",
      "672 odate\n",
      "205 odo\n",
      "59 odos\n",
      "11 oe\n",
      "66 oes\n",
      "15 oeste\n",
      "13 of\n",
      "41 ofc\n",
      "417 oferta\n",
      "16 ofertado\n",
      "61 ofertas\n",
      "32 off\n",
      "18 office\n",
      "28 offline\n",
      "74 ogs\n",
      "5637 oi\n",
      "22 oidigital\n",
      "9 oigalera\n",
      "31 oiofc\n",
      "11 oipontos\n",
      "41 oit\n",
      "36 oitot\n",
      "98 oitotal\n",
      "91 oitv\n",
      "36 oivende\n",
      "270 ok\n",
      "13 old\n",
      "336 oliveira\n",
      "284 om\n",
      "213 omr\n",
      "950 oms\n",
      "13 omvelox\n",
      "42 on\n",
      "256 onde\n",
      "44 online\n",
      "28 ontem\n",
      "473 op\n",
      "61 opcao\n",
      "52 opcional\n",
      "31 open\n",
      "641 opera\n",
      "184 operacao\n",
      "10 operacional\n",
      "45 operador\n",
      "479 operadora\n",
      "40 operadoras\n",
      "52 operadores\n",
      "35 optica\n",
      "11 opvprd\n",
      "19 or\n",
      "10 oracle\n",
      "867 ordem\n",
      "256 ordens\n",
      "78 order\n",
      "1657 orderid\n",
      "13 organiza\n",
      "13 orgao\n",
      "71 orienta\n",
      "44 orientada\n",
      "51 orientado\n",
      "365 origem\n",
      "11 originadas\n",
      "21 originado\n",
      "102 original\n",
      "31 oscrm\n",
      "226 oss\n",
      "20 ossac\n",
      "14 osvaldo\n",
      "22 osvc\n",
      "803 ot\n",
      "9 otavio\n",
      "9 otl\n",
      "33 out\n",
      "15 outlook\n",
      "67 outubro\n",
      "16 ouve\n",
      "127 ouvidoria\n",
      "11 override\n",
      "157 pa\n",
      "15 pablo\n",
      "45 pabx\n",
      "9 pac\n",
      "29 pacheco\n",
      "41 pack\n",
      "20 package\n",
      "429 pacote\n",
      "257 pacotes\n",
      "10 padilha\n",
      "15 padr\n",
      "176 pae\n",
      "17 paes\n",
      "158 paga\n",
      "306 pagamento\n",
      "13 pagando\n",
      "19 pagar\n",
      "330 pagas\n",
      "16 paggo\n",
      "64 pagina\n",
      "712 pago\n",
      "18 pagos\n",
      "61 pagou\n",
      "10 pagseguro\n",
      "187 pai\n",
      "14 painel\n",
      "13 pais\n",
      "39 paiva\n",
      "12 paixao\n",
      "11 palno\n",
      "9 paludo\n",
      "9 pamela\n",
      "25 paola\n",
      "57 pap\n",
      "20 papel\n",
      "59 papo\n",
      "323 par\n",
      "900 parada\n",
      "254 paradas\n",
      "227 parado\n",
      "129 parados\n",
      "24 parametriza\n",
      "28 parametrizada\n",
      "11 parametro\n",
      "8 paran\n",
      "11 parana\n",
      "10 parc\n",
      "152 parceiro\n",
      "9 parcela\n",
      "93 parcelamento\n",
      "8 parcelar\n",
      "71 parcial\n",
      "9 parcialmente\n",
      "23 parece\n",
      "23 parecer\n",
      "13 parm\n",
      "24 parou\n",
      "144 parte\n",
      "64 participante\n",
      "36 partir\n",
      "10 partiu\n",
      "22 pas\n",
      "15 pass\n",
      "39 passa\n",
      "31 passada\n",
      "31 passado\n",
      "8 passados\n",
      "12 passando\n",
      "38 passar\n",
      "11 passaram\n",
      "190 passo\n",
      "29 passos\n",
      "74 passou\n",
      "19 pasta\n",
      "13 patr\n",
      "90 patricia\n",
      "167 paula\n",
      "17 paulino\n",
      "176 paulo\n",
      "16 paz\n",
      "62 pb\n",
      "11 pbat\n",
      "132 pbi\n",
      "211 pc\n",
      "11 pcb\n",
      "23 pcd\n",
      "17 pcdi\n",
      "23 pcen\n",
      "9 pcmais\n",
      "10 pcp\n",
      "44 pcpprd\n",
      "301 pcrm\n",
      "113 pcs\n",
      "9 pcscodigoplano\n",
      "19 pct\n",
      "10 pcte\n",
      "77 pdf\n",
      "1340 pdv\n",
      "10 pdvs\n",
      "559 pe\n",
      "39 pecas\n",
      "111 pede\n",
      "12 pedencia\n",
      "24 pedente\n",
      "2332 pedido\n",
      "154 pedidos\n",
      "15 pedimos\n",
      "37 pedindo\n",
      "12 pedir\n",
      "52 pediu\n",
      "110 pedro\n",
      "9 pef\n",
      "9 pegar\n",
      "25 pegasus\n",
      "37 peixoto\n",
      "12 pelican\n",
      "885 pend\n",
      "10 pendecia\n",
      "549 pendencia\n",
      "44 pendenciada\n",
      "60 pendenciado\n",
      "20 pendenciar\n",
      "76 pendencias\n",
      "695 pendente\n",
      "127 pendentes\n",
      "15 penha\n",
      "262 per\n",
      "65 percentual\n",
      "78 perda\n",
      "22 perdeu\n",
      "11 perdido\n",
      "262 pereira\n",
      "17 peres\n",
      "169 perfil\n",
      "12 perfis\n",
      "24 periodo\n",
      "10 permance\n",
      "349 permanece\n",
      "228 permanecem\n",
      "34 permanecendo\n",
      "98 permanecer\n",
      "40 permaneceram\n",
      "96 permaneceu\n",
      "23 permiss\n",
      "379 permite\n",
      "16 permitem\n",
      "9 permiti\n",
      "128 permitida\n",
      "144 permitido\n",
      "169 permitindo\n",
      "39 permitir\n",
      "57 permitiu\n",
      "12 pernambuco\n",
      "145 persiste\n",
      "120 pertence\n",
      "20 pertencem\n",
      "8 pertencentes\n",
      "110 pesquisa\n",
      "21 pesquisar\n",
      "31 pesquisas\n",
      "65 pessoa\n",
      "16 pessoal\n",
      "83 pessoas\n",
      "121 pf\n",
      "26 pfat\n",
      "13 pfc\n",
      "369 pfx\n",
      "18 pg\n",
      "692 pgm\n",
      "989 php\n",
      "50 pi\n",
      "191 pics\n",
      "37 pida\n",
      "11 pido\n",
      "20 piloto\n",
      "15 pimenta\n",
      "14 pimentel\n",
      "30 pinf\n",
      "59 pinheiro\n",
      "15 pinho\n",
      "73 pinto\n",
      "14 pio\n",
      "47 pip\n",
      "14 pipeline\n",
      "64 pires\n",
      "11 pj\n",
      "72 pke\n",
      "9 pkg\n",
      "30 pl\n",
      "47 plabil\n",
      "14 plaf\n",
      "12 plan\n",
      "18 planas\n",
      "9 planejamento\n",
      "143 planilha\n",
      "802 plano\n",
      "175 planos\n",
      "45 planta\n",
      "10 plat\n",
      "89 plataforma\n",
      "28 plataformas\n",
      "9 playboy\n",
      "13 plsql\n",
      "11 plt\n",
      "44 plus\n",
      "15 pmj\n",
      "28 pmkt\n",
      "156 pms\n",
      "94 pnet\n",
      "10 pneus\n",
      "49 po\n",
      "133 podem\n",
      "42 podemos\n",
      "82 poder\n",
      "55 podera\n",
      "20 podermos\n",
      "14 policia\n",
      "57 ponta\n",
      "24 pontes\n",
      "225 ponto\n",
      "159 pontos\n",
      "13 pontual\n",
      "33 pop\n",
      "20 popular\n",
      "18 porcentagem\n",
      "490 porem\n",
      "12 porqu\n",
      "16 port\n",
      "125 porta\n",
      "14 portab\n",
      "684 portabilidade\n",
      "15 portabilidades\n",
      "43 portada\n",
      "14 portadas\n",
      "332 portado\n",
      "61 portador\n",
      "26 portadora\n",
      "26 portados\n",
      "822 portal\n",
      "77 portanto\n",
      "29 portar\n",
      "35 portas\n",
      "22 portf\n",
      "18 portfolio\n",
      "22 portif\n",
      "18 portifolio\n",
      "26 porto\n",
      "26 portou\n",
      "492 pos\n",
      "22 posconec\n",
      "29 posi\n",
      "15 positiva\n",
      "410 poss\n",
      "141 possa\n",
      "24 possam\n",
      "186 possamos\n",
      "86 possibilidade\n",
      "12 possibilita\n",
      "297 possivel\n",
      "118 possu\n",
      "20 possue\n",
      "95 possuem\n",
      "550 possui\n",
      "33 possuia\n",
      "11 possuimos\n",
      "9 possuindo\n",
      "30 possuir\n",
      "9 possuo\n",
      "60 postal\n",
      "28 posterior\n",
      "24 posteriormente\n",
      "1086 posto\n",
      "28 postos\n",
      "9 poup\n",
      "21 pp\n",
      "14 ppi\n",
      "23 pprt\n",
      "12 pq\n",
      "1361 pr\n",
      "154 pra\n",
      "35 prado\n",
      "10 prates\n",
      "340 prazo\n",
      "20 prazos\n",
      "671 prc\n",
      "11 prd\n",
      "319 pre\n",
      "139 precisa\n",
      "55 precisam\n",
      "342 precisamos\n",
      "211 preciso\n",
      "14 preco\n",
      "12 predio\n",
      "18 preechemos\n",
      "19 preen\n",
      "11 preenche\n",
      "157 preencher\n",
      "20 preenchida\n",
      "9 preenchidas\n",
      "83 preenchido\n",
      "24 preenchidos\n",
      "40 preenchimento\n",
      "74 prefeitura\n",
      "17 prefixo\n",
      "9 prefixos\n",
      "10 premier\n",
      "15 premiere\n",
      "201 prep\n",
      "25 prepago\n",
      "25 preq\n",
      "297 presa\n",
      "40 presas\n",
      "68 presente\n",
      "11 presentes\n",
      "286 preso\n",
      "24 presos\n",
      "18 prestada\n",
      "9 prestes\n",
      "11 preven\n",
      "11 prevista\n",
      "13 previsto\n",
      "9 preza\n",
      "154 prezado\n",
      "439 prezados\n",
      "24 prezadx\n",
      "1977 pri\n",
      "60 prim\n",
      "9 primario\n",
      "45 primeira\n",
      "36 prin\n",
      "57 principal\n",
      "676 print\n",
      "190 prints\n",
      "48 prioridade\n",
      "10 prioriza\n",
      "34 priorizar\n",
      "36 priscila\n",
      "79 prj\n",
      "174 pro\n",
      "358 problema\n",
      "160 problemas\n",
      "52 proc\n",
      "12 procede\n",
      "19 procedente\n",
      "191 proceder\n",
      "271 procedimento\n",
      "32 procedimentos\n",
      "22 procedure\n",
      "13 proceguir\n",
      "14 process\n",
      "13 processa\n",
      "17 processada\n",
      "25 processado\n",
      "160 processamento\n",
      "11 processar\n",
      "310 processo\n",
      "15 processos\n",
      "116 procon\n",
      "11 procsim\n",
      "13 procurar\n",
      "131 prod\n",
      "107 prodtrap\n",
      "30 produ\n",
      "514 produto\n",
      "13 produtor\n",
      "268 produtos\n",
      "74 profissional\n",
      "71 proforma\n",
      "10 prog\n",
      "379 programa\n",
      "9 programada\n",
      "19 progressao\n",
      "9 proje\n",
      "57 projetado\n",
      "58 projeto\n",
      "54 projetos\n",
      "131 promessa\n",
      "82 promo\n",
      "22 promocional\n",
      "28 pronta\n",
      "28 pronto\n",
      "58 propensos\n",
      "16 proporcional\n",
      "42 proposta\n",
      "15 propriedade\n",
      "11 proprio\n",
      "36 prorroga\n",
      "12 prorrogadas\n",
      "42 prorrogar\n",
      "17 proseguindo\n",
      "19 proseguir\n",
      "46 prossegue\n",
      "18 prosseguimento\n",
      "386 prosseguir\n",
      "22 prosseguirmos\n",
      "12 prosseguiu\n",
      "429 protocolo\n",
      "36 protocolos\n",
      "13 provavelmente\n",
      "29 provedor\n",
      "56 prover\n",
      "470 providenciar\n",
      "67 provis\n",
      "16 provisionado\n",
      "370 provisionamento\n",
      "24 provisionar\n",
      "9 provisonamento\n",
      "18 provisorio\n",
      "212 prvnosb\n",
      "32 ps\n",
      "12 psa\n",
      "41 psbl\n",
      "21 psul\n",
      "13 ptica\n",
      "44 pts\n",
      "24 ptvs\n",
      "16 publica\n",
      "48 publico\n",
      "9 puxa\n",
      "9 puxar\n",
      "11 pv\n",
      "80 pvo\n",
      "14 pvw\n",
      "11 pzlv\n",
      "10 qabr\n",
      "9 qago\n",
      "9 qd\n",
      "10 qdez\n",
      "11 qfev\n",
      "9 qjan\n",
      "11 qjun\n",
      "13 qmai\n",
      "9 qmar\n",
      "10 qnov\n",
      "133 qr\n",
      "47 qtd\n",
      "32 qtde\n",
      "13 qu\n",
      "9 quadro\n",
      "25 qualifica\n",
      "18 qualificada\n",
      "139 qualificar\n",
      "15 quality\n",
      "114 qualquer\n",
      "142 quantidade\n",
      "44 quarentena\n",
      "11 quase\n",
      "14 quatro\n",
      "9 queda\n",
      "35 queiroz\n",
      "90 queixa\n",
      "128 quer\n",
      "121 quest\n",
      "16 questionamentos\n",
      "12 questionando\n",
      "40 quina\n",
      "9 quinas\n",
      "117 quitado\n",
      "39 quot\n",
      "15 qy\n",
      "147 ra\n",
      "9 rachel\n",
      "120 rafael\n",
      "24 rafaela\n",
      "17 raimunda\n",
      "38 raimundo\n",
      "238 raiz\n",
      "12 ram\n",
      "81 ramais\n",
      "94 ramal\n",
      "18 ramalho\n",
      "10 ramon\n",
      "92 ramos\n",
      "21 rangel\n",
      "17 raphael\n",
      "37 raquel\n",
      "12 rata\n",
      "175 raz\n",
      "13 raza\n",
      "48 razao\n",
      "143 rb\n",
      "9 rbce\n",
      "35 rbo\n",
      "12 rbt\n",
      "682 rc\n",
      "40 rce\n",
      "26 rcs\n",
      "25 re\n",
      "124 rea\n",
      "28 reagendamento\n",
      "98 reagendar\n",
      "55 reais\n",
      "23 real\n",
      "118 realiza\n",
      "202 realizada\n",
      "40 realizadas\n",
      "259 realizado\n",
      "19 realizados\n",
      "18 realizam\n",
      "54 realizamos\n",
      "45 realizando\n",
      "690 realizar\n",
      "66 realizarmos\n",
      "14 realize\n",
      "10 realizei\n",
      "155 realizou\n",
      "82 realmente\n",
      "15 reas\n",
      "10 reason\n",
      "134 reativa\n",
      "52 reativada\n",
      "60 reativar\n",
      "28 rec\n",
      "30 recado\n",
      "214 recarga\n",
      "42 recargas\n",
      "14 receba\n",
      "101 recebe\n",
      "11 recebem\n",
      "50 recebemos\n",
      "249 recebendo\n",
      "135 receber\n",
      "62 receberam\n",
      "14 receberretornosolicitbilheteportab\n",
      "13 receberretornosolicitportab\n",
      "316 recebeu\n",
      "11 recebida\n",
      "91 recebido\n",
      "88 recebimento\n",
      "83 receita\n",
      "12 recente\n",
      "9 recentemente\n",
      "86 recentes\n",
      "351 recep\n",
      "59 receptiva\n",
      "46 receptivo\n",
      "143 receptor\n",
      "74 receptora\n",
      "15 receptores\n",
      "14 reciclagem\n",
      "14 reciclo\n",
      "12 recife\n",
      "89 recl\n",
      "350 reclama\n",
      "118 reclamada\n",
      "29 reclamadas\n",
      "262 reclamado\n",
      "25 reclamados\n",
      "14 reclamando\n",
      "77 reclamante\n",
      "24 recomandar\n",
      "11 reconhe\n",
      "220 reconhece\n",
      "13 reconhecendo\n",
      "8 reconheceu\n",
      "18 reconhecido\n",
      "13 recorre\n",
      "58 recorrente\n",
      "12 recupera\n",
      "95 recuperar\n",
      "9 recursos\n",
      "14 recusa\n",
      "318 recusada\n",
      "10 recusadas\n",
      "17 recusado\n",
      "119 rede\n",
      "19 redecard\n",
      "12 redes\n",
      "20 redirect\n",
      "37 redu\n",
      "9 reduzir\n",
      "57 reenviar\n",
      "25 reenvio\n",
      "349 ref\n",
      "34 refazer\n",
      "104 refer\n",
      "18 refere\n",
      "62 referencia\n",
      "328 referente\n",
      "123 referentes\n",
      "18 referido\n",
      "8 referidos\n",
      "12 reflete\n",
      "18 refletido\n",
      "10 refletidos\n",
      "13 refletindo\n",
      "10 refletir\n",
      "120 refletiu\n",
      "25 reflita\n",
      "117 reg\n",
      "101 regi\n",
      "11 regiane\n",
      "15 regiao\n",
      "98 regina\n",
      "20 reginaldo\n",
      "19 regionais\n",
      "213 regional\n",
      "9 regis\n",
      "11 registra\n",
      "9 registrada\n",
      "43 registrado\n",
      "39 registrar\n",
      "8 registration\n",
      "250 registro\n",
      "74 registros\n",
      "15 rego\n",
      "80 regra\n",
      "12 regras\n",
      "8 regulariza\n",
      "23 regularizar\n",
      "19 reinaldo\n",
      "11 reincid\n",
      "11 reincidente\n",
      "8 reiniciar\n",
      "16 reiniciou\n",
      "92 reinstala\n",
      "36 reinstalar\n",
      "124 reis\n",
      "15 rej\n",
      "13 rejane\n",
      "65 rejei\n",
      "30 rejeitado\n",
      "31 rejeitados\n",
      "128 rel\n",
      "81 rela\n",
      "12 relacionadas\n",
      "20 relacionado\n",
      "11 relacionados\n",
      "9 relacionamento\n",
      "124 relat\n",
      "59 relata\n",
      "22 relatorio\n",
      "119 relatorios\n",
      "12 relay\n",
      "43 relfat\n",
      "11 remedy\n",
      "19 remessa\n",
      "12 remessas\n",
      "57 remo\n",
      "85 remover\n",
      "23 removeu\n",
      "18 removido\n",
      "15 renan\n",
      "72 renata\n",
      "46 renato\n",
      "12 renova\n",
      "15 rentabiliza\n",
      "11 rep\n",
      "271 reparo\n",
      "47 reparos\n",
      "11 repassado\n",
      "35 repasse\n",
      "18 replica\n",
      "14 replicacao\n",
      "16 reporta\n",
      "9 reportado\n",
      "24 reppx\n",
      "27 representacoes\n",
      "13 reproc\n",
      "9 reprocessado\n",
      "19 reprocessados\n",
      "35 reprocessamento\n",
      "31 reprocessar\n",
      "28 req\n",
      "15 requer\n",
      "24 request\n",
      "60 requisi\n",
      "187 res\n",
      "15 resende\n",
      "118 reserva\n",
      "94 reservada\n",
      "35 reservado\n",
      "9 reservar\n",
      "281 reset\n",
      "66 resetar\n",
      "31 resgatar\n",
      "77 resgate\n",
      "43 resid\n",
      "24 residencia\n",
      "205 residencial\n",
      "21 resolu\n",
      "35 resolver\n",
      "9 resolveu\n",
      "23 resolvida\n",
      "39 resolvido\n",
      "22 resolvo\n",
      "11 resp\n",
      "12 respectiva\n",
      "16 respectivamente\n",
      "17 respectivas\n",
      "83 respectivos\n",
      "19 respeitando\n",
      "16 responda\n",
      "21 responde\n",
      "113 respons\n",
      "10 responsabilidade\n",
      "32 responsavel\n",
      "11 response\n",
      "50 resposta\n",
      "14 ressaltar\n",
      "41 ressalto\n",
      "9 ressubmeter\n",
      "16 ressubmiss\n",
      "24 rest\n",
      "17 restante\n",
      "9 restaurar\n",
      "10 restore\n",
      "34 restri\n",
      "13 resubmeter\n",
      "68 resultado\n",
      "9 resultando\n",
      "11 resumindo\n",
      "137 resumo\n",
      "436 ret\n",
      "27 retadsl\n",
      "29 retblo\n",
      "11 retbusca\n",
      "9 retcirc\n",
      "17 reteild\n",
      "364 reten\n",
      "14 retencao\n",
      "18 retida\n",
      "14 retidas\n",
      "12 retido\n",
      "15 retificada\n",
      "63 retinsmud\n",
      "74 retinsmudnum\n",
      "12 retir\n",
      "68 retira\n",
      "748 retirada\n",
      "15 retiradas\n",
      "206 retirado\n",
      "51 retirados\n",
      "24 retirando\n",
      "391 retirar\n",
      "15 retire\n",
      "10 retirem\n",
      "15 retirou\n",
      "12 retitar\n",
      "9 retmtro\n",
      "26 retoitot\n",
      "203 retorna\n",
      "24 retornada\n",
      "48 retornado\n",
      "10 retornam\n",
      "74 retornando\n",
      "72 retornar\n",
      "12 retornaram\n",
      "15 retorne\n",
      "260 retorno\n",
      "10 retornos\n",
      "388 retornou\n",
      "58 retplano\n",
      "79 retransmitir\n",
      "70 rev\n",
      "86 revenda\n",
      "26 revers\n",
      "12 review\n",
      "10 revis\n",
      "22 rezende\n",
      "32 rf\n",
      "11 rffd\n",
      "11 rffps\n",
      "11 rffpsel\n",
      "332 rg\n",
      "30 ri\n",
      "762 ria\n",
      "163 rias\n",
      "12 ribas\n",
      "200 ribeiro\n",
      "110 ricardo\n",
      "235 rico\n",
      "24 rie\n",
      "18 rii\n",
      "1909 rio\n",
      "323 rios\n",
      "14 risco\n",
      "58 rita\n",
      "528 rj\n",
      "289 rjo\n",
      "46 rmino\n",
      "47 rn\n",
      "205 ro\n",
      "37 roaming\n",
      "25 roberta\n",
      "208 roberto\n",
      "59 robo\n",
      "49 robson\n",
      "121 rocha\n",
      "15 rodando\n",
      "55 rodar\n",
      "11 rodolfo\n",
      "119 rodrigo\n",
      "215 rodrigues\n",
      "94 rogerio\n",
      "20 rogero\n",
      "10 rolagem\n",
      "9 romero\n",
      "37 ronaldo\n",
      "13 rondonia\n",
      "10 roque\n",
      "123 rosa\n",
      "14 rosana\n",
      "24 rosangela\n",
      "15 rosario\n",
      "13 rose\n",
      "10 roseli\n",
      "9 rosilene\n",
      "9 rossi\n",
      "10 rot\n",
      "20 rota\n",
      "9 roteador\n",
      "9 roteamento\n",
      "41 rotina\n",
      "12 rotinas\n",
      "14 roubo\n",
      "78 row\n",
      "47 rp\n",
      "11 rpc\n",
      "27 rr\n",
      "9 rro\n",
      "176 rs\n",
      "150 rt\n",
      "125 rtcd\n",
      "16 rtcm\n",
      "39 rua\n",
      "22 rubens\n",
      "11 rufino\n",
      "32 rural\n",
      "11 rus\n",
      "9 rute\n",
      "28 rv\n",
      "11 rvd\n",
      "115 sa\n",
      "17 sabe\n",
      "13 sabemos\n",
      "46 saber\n",
      "9 sabrina\n",
      "2066 sac\n",
      "108 saf\n",
      "18 sag\n",
      "25 sai\n",
      "18 sair\n",
      "29 saiu\n",
      "108 saldo\n",
      "53 sales\n",
      "12 salete\n",
      "11 salles\n",
      "26 salvador\n",
      "23 salvar\n",
      "56 sampaio\n",
      "89 sample\n",
      "20 samuel\n",
      "11 sanches\n",
      "40 sandra\n",
      "24 sandro\n",
      "10 sant\n",
      "62 santa\n",
      "90 santana\n",
      "51 santander\n",
      "26 santiago\n",
      "29 santo\n",
      "291 santos\n",
      "43 sao\n",
      "101 sap\n",
      "12 saraiva\n",
      "9 satus\n",
      "33 saude\n",
      "16 saulo\n",
      "32 sav\n",
      "94 sbl\n",
      "10 sbloitotal\n",
      "9 sblpx\n",
      "519 sc\n",
      "10 scacp\n",
      "13 scb\n",
      "25 schedule\n",
      "19 scom\n",
      "12 scp\n",
      "15 sd\n",
      "13 sdcorp\n",
      "67 sdr\n",
      "10 sebastiana\n",
      "26 sebastiao\n",
      "61 sec\n",
      "63 secretaria\n",
      "55 secund\n",
      "9 sedex\n",
      "9 seg\n",
      "99 segmenta\n",
      "103 segmento\n",
      "1776 segue\n",
      "197 seguem\n",
      "34 seguida\n",
      "24 seguindo\n",
      "243 seguinte\n",
      "50 seguintes\n",
      "425 seguir\n",
      "10 seguirmos\n",
      "12 seguiu\n",
      "64 segunda\n",
      "59 segundo\n",
      "12 segundos\n",
      "35 seguran\n",
      "25 seguranca\n",
      "28 seguros\n",
      "10 seis\n",
      "9 seixas\n",
      "30 sele\n",
      "9 seleciona\n",
      "17 selecionada\n",
      "78 selecionado\n",
      "65 selecionar\n",
      "10 select\n",
      "10 selma\n",
      "119 semana\n",
      "11 semanas\n",
      "23 sena\n",
      "483 senha\n",
      "11 senhora\n",
      "75 senhores\n",
      "14 separada\n",
      "30 separadamente\n",
      "27 separadas\n",
      "21 separado\n",
      "16 sequ\n",
      "21 sequencia\n",
      "91 sequencial\n",
      "343 ser\n",
      "48 sera\n",
      "25 serede\n",
      "70 serem\n",
      "13 sereno\n",
      "98 sergio\n",
      "10 sergipe\n",
      "9 serie\n",
      "30 serpa\n",
      "41 serra\n",
      "62 serv\n",
      "20 server\n",
      "1074 servi\n",
      "57 service\n",
      "10 services\n",
      "218 servico\n",
      "116 servicos\n",
      "27 servidor\n",
      "11 servidores\n",
      "8 sess\n",
      "24 set\n",
      "78 setembro\n",
      "63 setor\n",
      "9 setores\n",
      "23 sev\n",
      "11 severidade\n",
      "18 severino\n",
      "9 sevi\n",
      "8 sex\n",
      "28 sexy\n",
      "365 sfa\n",
      "527 sge\n",
      "10 sgeb\n",
      "27 sgef\n",
      "8 sgep\n",
      "39 sgft\n",
      "22 sgo\n",
      "16 sh\n",
      "13 sharepoint\n",
      "20 sheila\n",
      "328 siac\n",
      "136 sibel\n",
      "59 sica\n",
      "343 sico\n",
      "8 sicoob\n",
      "15 sicos\n",
      "21 sidara\n",
      "13 sidnei\n",
      "8 sidney\n",
      "2516 siebel\n",
      "11 siebelbatimento\n",
      "14 siebelcdi\n",
      "14 siebeldataguard\n",
      "26 siebelmkt\n",
      "187 siebelreport\n",
      "38 siga\n",
      "199 sigla\n",
      "12 siin\n",
      "365 silva\n",
      "47 silvana\n",
      "94 silveira\n",
      "8 silvestre\n",
      "27 silvia\n",
      "11 silvio\n",
      "364 sim\n",
      "10 simao\n",
      "8 simas\n",
      "17 simcard\n",
      "12 simcards\n",
      "21 simoes\n",
      "59 simone\n",
      "26 simples\n",
      "21 simproc\n",
      "118 simula\n",
      "8 simulada\n",
      "45 simular\n",
      "15 sin\n",
      "190 sinal\n",
      "35 sincronismo\n",
      "9 sindicato\n",
      "384 sinn\n",
      "9 sinndth\n",
      "20 sinnweb\n",
      "58 siqueira\n",
      "17 sirlene\n",
      "111 sis\n",
      "283 sisjur\n",
      "360 sisraf\n",
      "289 sist\n",
      "9 sistem\n",
      "753 sistema\n",
      "250 sistemas\n",
      "25 sistemica\n",
      "98 sistemico\n",
      "30 sit\n",
      "1109 site\n",
      "28 sitema\n",
      "60 sitescope\n",
      "21 sito\n",
      "40 sittel\n",
      "210 situa\n",
      "21 situacao\n",
      "18 sla\n",
      "10 sldd\n",
      "9 sle\n",
      "20 slot\n",
      "29 sls\n",
      "13 smi\n",
      "13 smkprd\n",
      "10 smp\n",
      "9 smpe\n",
      "163 sms\n",
      "10 sno\n",
      "100 so\n",
      "53 soa\n",
      "11 soapenv\n",
      "11 soapx\n",
      "152 soares\n",
      "18 soasync\n",
      "1402 soc\n",
      "215 social\n",
      "14 sociedade\n",
      "21 socorro\n",
      "35 sofreram\n",
      "41 sofreu\n",
      "11 sol\n",
      "24 solange\n",
      "12 solic\n",
      "1679 solicita\n",
      "39 solicitacao\n",
      "100 solicitada\n",
      "233 solicitado\n",
      "117 solicitados\n",
      "104 solicitamos\n",
      "143 solicitando\n",
      "112 solicitante\n",
      "342 solicitar\n",
      "32 solicite\n",
      "452 solicito\n",
      "334 solicitou\n",
      "102 solu\n",
      "32 solucionado\n",
      "32 solucionar\n",
      "11 solucoes\n",
      "11 solutions\n",
      "14 som\n",
      "17 some\n",
      "182 somente\n",
      "36 sompxa\n",
      "57 sonia\n",
      "57 sons\n",
      "11 soo\n",
      "15 soube\n",
      "154 sousa\n",
      "10 souto\n",
      "274 souza\n",
      "11 sox\n",
      "110 sp\n",
      "20 spm\n",
      "120 spo\n",
      "12 sql\n",
      "176 sr\n",
      "16 sra\n",
      "85 srs\n",
      "15 ss\n",
      "10 sso\n",
      "21 ssp\n",
      "1779 st\n",
      "10 sta\n",
      "59 start\n",
      "987 status\n",
      "11 staus\n",
      "1746 stc\n",
      "12 stcab\n",
      "47 stcd\n",
      "2033 step\n",
      "51 sti\n",
      "39 stica\n",
      "98 sticas\n",
      "57 su\n",
      "55 sub\n",
      "149 subfastve\n",
      "41 subiu\n",
      "79 subnum\n",
      "67 substitui\n",
      "21 substituir\n",
      "26 substituta\n",
      "29 substituto\n",
      "446 sucesso\n",
      "12 sueli\n",
      "70 sul\n",
      "17 sumiu\n",
      "9 sup\n",
      "21 super\n",
      "13 superior\n",
      "14 supermercado\n",
      "28 supersav\n",
      "67 supervisor\n",
      "20 supervisora\n",
      "93 suporte\n",
      "176 surge\n",
      "140 surgiu\n",
      "9 susini\n",
      "15 suspen\n",
      "87 suspens\n",
      "29 suspensa\n",
      "67 suspenso\n",
      "26 suspensos\n",
      "11 suzana\n",
      "11 sv\n",
      "74 sva\n",
      "18 svctb\n",
      "110 svoi\n",
      "33 sylvia\n",
      "978 sysout\n",
      "32 ta\n",
      "39 tab\n",
      "103 tabela\n",
      "12 tabelas\n",
      "15 tadeu\n",
      "41 tais\n",
      "9 taise\n",
      "68 tal\n",
      "23 tamanho\n",
      "50 tambem\n",
      "25 tania\n",
      "68 tanto\n",
      "412 tarde\n",
      "677 tarefa\n",
      "33 tarefas\n",
      "62 tarif\n",
      "52 tarifa\n",
      "21 tarifacao\n",
      "21 tarifada\n",
      "9 tarifadas\n",
      "240 tarifado\n",
      "49 tarifados\n",
      "15 tarifario\n",
      "26 task\n",
      "16 tatiana\n",
      "25 tatiane\n",
      "66 tavares\n",
      "29 taxa\n",
      "16 tb\n",
      "124 tc\n",
      "13 tced\n",
      "10 tceprbu\n",
      "40 tcs\n",
      "33 tdm\n",
      "19 tec\n",
      "9 tecla\n",
      "138 tecle\n",
      "43 tecnica\n",
      "24 tecnico\n",
      "54 tecnicos\n",
      "56 tecnologia\n",
      "16 teis\n",
      "111 teixeira\n",
      "346 tel\n",
      "817 tela\n",
      "256 telas\n",
      "19 tele\n",
      "12 telecine\n",
      "86 telecom\n",
      "26 telecomunicacoes\n",
      "23 telef\n",
      "607 telefone\n",
      "84 telefones\n",
      "18 telefonica\n",
      "163 telemar\n",
      "21 teles\n",
      "43 televendas\n",
      "8 telma\n",
      "11 telr\n",
      "9 teminal\n",
      "19 template\n",
      "96 tempo\n",
      "25 tempor\n",
      "22 temporariamente\n",
      "320 tenta\n",
      "30 tentado\n",
      "136 tentamos\n",
      "442 tentando\n",
      "625 tentar\n",
      "46 tentarmos\n",
      "280 tentativa\n",
      "69 tentativas\n",
      "22 tentato\n",
      "99 tente\n",
      "29 tentei\n",
      "37 tento\n",
      "120 tentou\n",
      "16 teodoro\n",
      "15 ter\n",
      "16 terceiro\n",
      "18 terceiros\n",
      "27 terem\n",
      "12 teresa\n",
      "27 teresinha\n",
      "16 tereza\n",
      "62 terezinha\n",
      "108 term\n",
      "29 termina\n",
      "549 terminais\n",
      "1491 terminal\n",
      "9 termino\n",
      "24 termo\n",
      "11 termos\n",
      "17 terra\n",
      "130 testar\n",
      "59 teste\n",
      "21 testes\n",
      "8 textil\n",
      "10 tffd\n",
      "38 thais\n",
      "12 the\n",
      "89 thiago\n",
      "21 tht\n",
      "305 tiago\n",
      "743 tica\n",
      "40 ticas\n",
      "228 tico\n",
      "19 tijuca\n",
      "79 tim\n",
      "18 time\n",
      "21 timeout\n",
      "8 tipifica\n",
      "218 tipo\n",
      "25 tipodaos\n",
      "11 tirado\n",
      "30 tirar\n",
      "848 titular\n",
      "8 titulares\n",
      "116 titularidade\n",
      "10 tlm\n",
      "1976 tlmoi\n",
      "16 tlmpackageoriginalid\n",
      "23 tlv\n",
      "15 tm\n",
      "1699 tmapw\n",
      "11 tmarq\n",
      "664 tn\n",
      "11 tns\n",
      "101 to\n",
      "11 tocantins\n",
      "9 todo\n",
      "16 todvrgratis\n",
      "52 token\n",
      "20 toolkit\n",
      "76 top\n",
      "9 topologia\n",
      "29 tor\n",
      "44 torpedo\n",
      "25 torpedos\n",
      "12 torre\n",
      "36 torres\n",
      "17 tot\n",
      "5335 total\n",
      "18 totalmente\n",
      "10 tp\n",
      "11 tpa\n",
      "424 tr\n",
      "80 tra\n",
      "12 traas\n",
      "93 trabalho\n",
      "22 tradu\n",
      "172 traducao\n",
      "10 trafegar\n",
      "27 trafego\n",
      "22 tramit\n",
      "261 tramita\n",
      "18 tramitacao\n",
      "55 tramitada\n",
      "15 tramitadas\n",
      "24 tramitado\n",
      "111 tramitando\n",
      "341 tramitar\n",
      "39 tramitaram\n",
      "325 tramite\n",
      "450 tramitou\n",
      "14 trans\n",
      "23 transa\n",
      "20 transact\n",
      "74 transfer\n",
      "11 transfere\n",
      "47 transferencia\n",
      "18 transferidor\n",
      "11 transferir\n",
      "31 transmiss\n",
      "18 transporte\n",
      "28 transportes\n",
      "41 trat\n",
      "312 trata\n",
      "50 tratada\n",
      "66 tratadas\n",
      "68 tratado\n",
      "23 tratados\n",
      "12 tratam\n",
      "582 tratamento\n",
      "11 tratamentos\n",
      "12 tratamos\n",
      "17 tratando\n",
      "698 tratar\n",
      "345 tratativa\n",
      "24 tratativas\n",
      "161 tratconv\n",
      "47 trava\n",
      "173 travada\n",
      "18 travadas\n",
      "452 travado\n",
      "15 travando\n",
      "11 traz\n",
      "12 trazendo\n",
      "16 tres\n",
      "46 tria\n",
      "48 tribunal\n",
      "17 tridigito\n",
      "10 trigados\n",
      "40 trigger\n",
      "20 trindade\n",
      "10 trl\n",
      "316 troca\n",
      "64 trocar\n",
      "20 trocou\n",
      "45 tronco\n",
      "9 trunc\n",
      "22 tsa\n",
      "568 tt\n",
      "58 tts\n",
      "23 tulo\n",
      "23 turbo\n",
      "20 turismo\n",
      "2959 tv\n",
      "63 tvas\n",
      "24 tvspdcrc\n",
      "21 tx\n",
      "83 txt\n",
      "13 type\n",
      "12 udr\n",
      "387 uf\n",
      "47 ufacp\n",
      "12 uffd\n",
      "20 uffps\n",
      "20 uffpsel\n",
      "9 ufftp\n",
      "14 ufs\n",
      "53 ug\n",
      "40 ultima\n",
      "17 ultimapendencia\n",
      "12 ultimas\n",
      "21 ultimo\n",
      "11 un\n",
      "89 unica\n",
      "11 unico\n",
      "177 unid\n",
      "151 unidade\n",
      "21 unifica\n",
      "11 unificada\n",
      "18 unificado\n",
      "11 universidade\n",
      "18 unix\n",
      "87 up\n",
      "10 update\n",
      "62 upgrade\n",
      "48 ur\n",
      "52 ura\n",
      "143 urg\n",
      "215 urgencia\n",
      "78 urgente\n",
      "20 url\n",
      "11 usa\n",
      "49 usado\n",
      "49 usados\n",
      "28 usando\n",
      "36 usar\n",
      "10 user\n",
      "99 uso\n",
      "125 usos\n",
      "1387 usu\n",
      "81 usuaria\n",
      "183 usuario\n",
      "9 usuarios\n",
      "201 utcd\n",
      "10 utcdc\n",
      "27 utce\n",
      "21 uteis\n",
      "92 utiliza\n",
      "21 utilizada\n",
      "99 utilizado\n",
      "20 utilizados\n",
      "33 utilizando\n",
      "84 utilizar\n",
      "21 utilize\n",
      "12 utilizo\n",
      "21 utilizou\n",
      "135 uv\n",
      "86 vaga\n",
      "13 vagner\n",
      "164 vago\n",
      "18 vagos\n",
      "175 vai\n",
      "26 val\n",
      "18 valdir\n",
      "49 vale\n",
      "30 valeria\n",
      "16 valerio\n",
      "10 valid\n",
      "214 valida\n",
      "9 validade\n",
      "12 validado\n",
      "9 validamos\n",
      "54 validar\n",
      "43 valido\n",
      "430 valor\n",
      "125 valores\n",
      "16 valter\n",
      "12 value\n",
      "31 vamos\n",
      "9 vanda\n",
      "11 vanderlei\n",
      "54 vanessa\n",
      "22 vania\n",
      "163 varejo\n",
      "32 vargas\n",
      "40 varias\n",
      "33 varios\n",
      "12 vasconcellos\n",
      "45 vasconcelos\n",
      "34 vaz\n",
      "12 vazio\n",
      "9 vazios\n",
      "141 vc\n",
      "14 vca\n",
      "59 vcoinr\n",
      "56 vctotal\n",
      "11 vdsl\n",
      "16 ve\n",
      "30 veiculos\n",
      "16 veiga\n",
      "47 veio\n",
      "203 veis\n",
      "24 veja\n",
      "1664 vel\n",
      "366 velocidade\n",
      "20 velocidades\n",
      "13 veloso\n",
      "1022 velox\n",
      "65 vem\n",
      "23 venc\n",
      "40 venceu\n",
      "489 vencida\n",
      "24 vencidas\n",
      "20 vencido\n",
      "181 vencimento\n",
      "11 vencimentos\n",
      "33 vend\n",
      "683 venda\n",
      "10 vendaconjuntar\n",
      "142 vendas\n",
      "241 vende\n",
      "365 vendedor\n",
      "165 vendedora\n",
      "14 vendedores\n",
      "10 vender\n",
      "9 venho\n",
      "48 vera\n",
      "10 verde\n",
      "23 verficar\n",
      "20 vericar\n",
      "17 verif\n",
      "27 verifcar\n",
      "992 verifica\n",
      "15 verificada\n",
      "295 verificado\n",
      "115 verificamos\n",
      "59 verificando\n",
      "1364 verificar\n",
      "31 verificarem\n",
      "27 verificou\n",
      "85 verifique\n",
      "26 verifiquei\n",
      "234 verifiquem\n",
      "27 veriricar\n",
      "19 veronica\n",
      "14 vers\n",
      "75 vetor\n",
      "70 vezes\n",
      "15 vga\n",
      "19 vi\n",
      "368 via\n",
      "393 viabilidade\n",
      "17 viagem\n",
      "14 viagens\n",
      "46 viana\n",
      "23 vicente\n",
      "23 victor\n",
      "58 vida\n",
      "23 vidas\n",
      "241 vide\n",
      "150 vieira\n",
      "12 view\n",
      "52 vig\n",
      "9 vigencia\n",
      "28 vigente\n",
      "24 vila\n",
      "12 vilela\n",
      "24 vilma\n",
      "9 vilmar\n",
      "15 vimos\n",
      "26 vincula\n",
      "146 vinculada\n",
      "23 vinculadas\n",
      "301 vinculado\n",
      "85 vinculados\n",
      "42 vincular\n",
      "33 vinculo\n",
      "10 vinculou\n",
      "66 vinicius\n",
      "72 vip\n",
      "11 vira\n",
      "8 virginia\n",
      "31 virtual\n",
      "27 virtude\n",
      "10 vis\n",
      "24 visita\n",
      "54 vista\n",
      "205 visto\n",
      "123 visualiza\n",
      "19 visualizado\n",
      "19 visualizando\n",
      "244 visualizar\n",
      "11 vite\n",
      "42 vitor\n",
      "12 vitoria\n",
      "197 vitria\n",
      "36 viviane\n",
      "346 vivo\n",
      "14 vizualizar\n",
      "19 vl\n",
      "14 vlox\n",
      "13 vlr\n",
      "27 vm\n",
      "15 vmp\n",
      "52 voc\n",
      "45 voice\n",
      "97 volta\n",
      "19 voltando\n",
      "27 voltar\n",
      "9 voltaram\n",
      "61 volte\n",
      "24 voltem\n",
      "23 voltou\n",
      "46 volume\n",
      "82 volumetria\n",
      "10 vossa\n",
      "19 vou\n",
      "635 voz\n",
      "82 vpn\n",
      "16 vrd\n",
      "9 vs\n",
      "21 vta\n",
      "16 vva\n",
      "21 vw\n",
      "28 wagner\n",
      "62 wainting\n",
      "59 waiting\n",
      "9 wal\n",
      "16 walter\n",
      "10 wanderson\n",
      "63 web\n",
      "20 webservice\n",
      "19 webshare\n",
      "54 wedo\n",
      "25 wellington\n",
      "33 wesley\n",
      "30 wf\n",
      "11 wfl\n",
      "783 wfm\n",
      "12 where\n",
      "23 william\n",
      "24 willian\n",
      "20 wilson\n",
      "66 wll\n",
      "9 wllgatprdd\n",
      "78 wllprd\n",
      "56 wllpx\n",
      "12 woi\n",
      "10 woiprd\n",
      "11 word\n",
      "16 workflow\n",
      "49 xavier\n",
      "11 xfb\n",
      "38 xima\n",
      "14 ximo\n",
      "32 ximos\n",
      "67 xlsx\n",
      "44 xml\n",
      "12 xmlns\n",
      "56 xx\n",
      "14 xxx\n",
      "15 xxxx\n",
      "95 yahoo\n",
      "745 zc\n",
      "15 zelia\n",
      "33 zerada\n",
      "16 zerado\n",
      "16 zero\n",
      "13 zga\n",
      "15 zilda\n",
      "13 zip\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sum up the counts of each vocabulary word\n",
    "dist = np.sum(data_features, axis=0)\n",
    "\n",
    "# For each, print the vocabulary word and the number of times it \n",
    "# appears in the training set\n",
    "for tag, count in zip(vocab, dist):\n",
    "    print count, tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into a training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41686, 2)\n",
      "(10422, 2)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(data, test_size = 0.2)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate further the data into features (X) and target (y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = train.drop(\"class\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = test.drop(\"class\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = train[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = test[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train[:0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Random Forest\n",
    "At this point, we have numeric training features from the Bag of Words and the original sentiment labels for each feature vector, so let's do some supervised learning! Here, we'll use the Random Forest classifier that we introduced in the Titanic tutorial.  The Random Forest algorithm is included in scikit-learn (Random Forest uses many tree-based classifiers to make predictions, hence the \"forest\"). Below, we set the number of trees to 100 as a reasonable default value. More trees may (or may not) perform better, but will certainly take longer to run. Likewise, the more features you include for each review, the longer this will take."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the random forest...\n"
     ]
    }
   ],
   "source": [
    "print \"Training the random forest...\"\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize a Random Forest classifier with 100 trees\n",
    "forest = RandomForestClassifier(n_estimators = 100, njobs = 5) \n",
    "\n",
    "# Fit the forest to the training set, using the bag of words as \n",
    "# features and the sentiment labels as the response variable\n",
    "#\n",
    "# This may take a few minutes to run\n",
    "forest = forest.fit( data_features, data[\"text\"] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Submission\n",
    "All that remains is to run the trained Random Forest on our test set and create a submission file. If you haven't already done so, download testData.tsv from the Data page. This file contains another 25,000 reviews and ids; our task is to predict the sentiment label.\n",
    "\n",
    "Note that when we use the Bag of Words for the test set, we only call \"transform\", not \"fit_transform\" as we did for the training set. In machine learning, you shouldn't use the test set to fit your model, otherwise you run the risk of overfitting. For this reason, we keep the test set off-limits until we are ready to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2)\n",
      "Cleaning and parsing the test set movie reviews...\n",
      "\n",
      "Review 1000 of 25000\n",
      "\n",
      "Review 2000 of 25000\n",
      "\n",
      "Review 3000 of 25000\n",
      "\n",
      "Review 4000 of 25000\n",
      "\n",
      "Review 5000 of 25000\n",
      "\n",
      "Review 6000 of 25000\n",
      "\n",
      "Review 7000 of 25000\n",
      "\n",
      "Review 8000 of 25000\n",
      "\n",
      "Review 9000 of 25000\n",
      "\n",
      "Review 10000 of 25000\n",
      "\n",
      "Review 11000 of 25000\n",
      "\n",
      "Review 12000 of 25000\n",
      "\n",
      "Review 13000 of 25000\n",
      "\n",
      "Review 14000 of 25000\n",
      "\n",
      "Review 15000 of 25000\n",
      "\n",
      "Review 16000 of 25000\n",
      "\n",
      "Review 17000 of 25000\n",
      "\n",
      "Review 18000 of 25000\n",
      "\n",
      "Review 19000 of 25000\n",
      "\n",
      "Review 20000 of 25000\n",
      "\n",
      "Review 21000 of 25000\n",
      "\n",
      "Review 22000 of 25000\n",
      "\n",
      "Review 23000 of 25000\n",
      "\n",
      "Review 24000 of 25000\n",
      "\n",
      "Review 25000 of 25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read the test data\n",
    "test = pd.read_csv(\"testData.tsv\", header=0, delimiter=\"\\t\", \\\n",
    "                   quoting=3 )\n",
    "\n",
    "# Verify that there are 25,000 rows and 2 columns\n",
    "print test.shape\n",
    "\n",
    "# Create an empty list and append the clean reviews one by one\n",
    "num_reviews = len(test[\"review\"])\n",
    "clean_test_reviews = [] \n",
    "\n",
    "print \"Cleaning and parsing the test set movie reviews...\\n\"\n",
    "for i in xrange(0,num_reviews):\n",
    "    if( (i+1) % 1000 == 0 ):\n",
    "        print \"Review %d of %d\\n\" % (i+1, num_reviews)\n",
    "    clean_review = review_to_words( test[\"review\"][i] )\n",
    "    clean_test_reviews.append( clean_review )\n",
    "\n",
    "# Get a bag of words for the test set, and convert to a numpy array\n",
    "test_data_features = vectorizer.transform(clean_test_reviews)\n",
    "test_data_features = test_data_features.toarray()\n",
    "\n",
    "# Use the random forest to make sentiment label predictions\n",
    "result = forest.predict(test_data_features)\n",
    "\n",
    "# Copy the results to a pandas dataframe with an \"id\" column and\n",
    "# a \"sentiment\" column\n",
    "output = pd.DataFrame( data={\"id\":test[\"id\"], \"sentiment\":result} )\n",
    "\n",
    "# Use pandas to write the comma-separated output file\n",
    "output.to_csv( \"Bag_of_Words_model.csv\", index=False, quoting=3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, you are ready to make your first submission! Try different things and see how your results change. You can clean the reviews differently, choose a different number of vocabulary words for the Bag of Words representation, try Porter Stemming, a different classifier, or any number of other things. To try out your NLP chops on a different data set, you can also head over to our Rotten Tomatoes competition. Or, if you're ready for something completely different, move along to the Deep Learning and Word Vector pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing to Train a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now down to the nitty-gritty! First, we read in the data with pandas, as we did in Part 1. Unlike Part 1, we now use unlabeledTrain.tsv, which contains 50,000 additional reviews with no labels. When we built the Bag of Words model in Part 1, extra unlabeled training reviews were not useful. However, since Word2Vec can learn from unlabeled data, these extra 50,000 reviews can now be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read data from files \n",
    "train = pd.read_csv( \"labeledTrainData.tsv\", header=0, \n",
    " delimiter=\"\\t\", quoting=3, encoding=\"utf-8\") \n",
    "test = pd.read_csv( \"testData.tsv\", header=0, delimiter=\"\\t\", quoting=3 , encoding=\"utf-8\")\n",
    "unlabeled_train = pd.read_csv( \"unlabeledTrainData.tsv\", header=0, \n",
    " delimiter=\"\\t\", quoting=3 , encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Verify the number of reviews that were read (100,000 in total)\n",
    "print \"Read %d labeled train reviews, %d labeled test reviews, \" \\\n",
    " \"and %d unlabeled reviews\\n\" % (train[\"review\"].size,  \n",
    " test[\"review\"].size, unlabeled_train[\"review\"].size )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions we write to clean the data are also similar to Part 1, although now there are a couple of differences. First, to train Word2Vec it is better not to remove stop words because the algorithm relies on the broader context of the sentence in order to produce high-quality word vectors. For this reason, we will make stop word removal optional in the functions below. It also might be better not to remove numbers, but we leave that as an exercise for the reader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import various modules for string cleaning\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def review_to_wordlist( review, remove_stopwords=False ):\n",
    "    # Function to convert a document to a sequence of words,\n",
    "    # optionally removing stop words.  Returns a list of words.\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(review).get_text()\n",
    "    #  \n",
    "    # 2. Remove non-letters\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    #\n",
    "    # 3. Convert words to lower case and split them\n",
    "    words = review_text.lower().split()\n",
    "    #\n",
    "    # 4. Optionally remove stop words (false by default)\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    #\n",
    "    # 5. Return a list of words\n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want a specific input format. Word2Vec expects single sentences, each one as a list of words. In other words, the input format is a list of lists.\n",
    "\n",
    "It is not at all straightforward how to split a paragraph into sentences. There are all kinds of gotchas in natural language. English sentences can end with \"?\", \"!\", \"\"\", or \".\", among other things, and spacing and capitalization are not reliable guides either. For this reason, we'll use NLTK's punkt tokenizer for sentence splitting. In order to use this, you will need to install NLTK and use nltk.download() to download the relevant training file for punkt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Download the punkt tokenizer for sentence splitting\n",
    "import nltk.data\n",
    "#nltk.download()   \n",
    "# Load the punkt tokenizer\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a function to split a review into parsed sentences\n",
    "def review_to_sentences( review, tokenizer, remove_stopwords=False ):\n",
    "    # Function to split a review into parsed sentences. Returns a \n",
    "    # list of sentences, where each sentence is a list of words\n",
    "    #\n",
    "    # 1. Use the NLTK tokenizer to split the paragraph into sentences\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "    #\n",
    "    # 2. Loop over each sentence\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        # If a sentence is empty, skip it\n",
    "        if len(raw_sentence) > 0:\n",
    "            # Otherwise, call review_to_wordlist to get a list of words\n",
    "            sentences.append( review_to_wordlist( raw_sentence, \\\n",
    "              remove_stopwords ))\n",
    "    #\n",
    "    # Return the list of sentences (each sentence is a list of words,\n",
    "    # so this returns a list of lists\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can apply this function to prepare our data for input to Word2Vec (this will take a couple minutes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "sentences = []  # Initialize an empty list of sentences\n",
    "\n",
    "print \"Parsing sentences from training set\"\n",
    "for review in train[\"review\"]:\n",
    "    sentences += review_to_sentences(review, tokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Parsing sentences from unlabeled set\"\n",
    "for review in unlabeled_train[\"review\"]:\n",
    "    sentences += review_to_sentences(review, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can apply this function to prepare our data for input to Word2Vec (this will take a couple minutes):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may get a few warnings from BeautifulSoup about URLs in the sentences. These are nothing to worry about (although you may want to consider removing URLs when cleaning the text). \n",
    "\n",
    "We can take a look at the output to see how this differs from Part 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Saving Your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the list of nicely parsed sentences, we're ready to train the model. There are a number of parameter choices that affect the run time and the quality of the final model that is produced. For details on the algorithms below, see the word2vec API documentation as well as the Google documentation. \n",
    "\n",
    "    Architecture: Architecture options are skip-gram (default) or continuous bag of words. We found that skip-gram was very slightly slower but produced better results.\n",
    "    Training algorithm: Hierarchical softmax (default) or negative sampling. For us, the default worked well.\n",
    "    Downsampling of frequent words: The Google documentation recommends values between .00001 and .001. For us, values closer 0.001 seemed to improve the accuracy of the final model.\n",
    "    Word vector dimensionality: More features result in longer runtimes, and often, but not always, result in better models. Reasonable values can be in the tens to hundreds; we used 300.\n",
    "    Context / window size: How many words of context should the training algorithm take into account? 10 seems to work well for hierarchical softmax (more is better, up to a point).\n",
    "    Worker threads: Number of parallel processes to run. This is computer-specific, but between 4 and 6 should work on most systems.\n",
    "    Minimum word count: This helps limit the size of the vocabulary to meaningful words. Any word that does not occur at least this many times across all documents is ignored. Reasonable values could be between 10 and 100. In this case, since each movie occurs 30 times, we set the minimum word count to 40, to avoid attaching too much importance to individual movie titles. This resulted in an overall vocabulary size of around 15,000 words. Higher values also help limit run time.\n",
    "\n",
    "Choosing parameters is not easy, but once we have chosen our parameters, creating a Word2Vec model is straightforward:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the built-in logging module and configure it so that Word2Vec \n",
    "# creates nice output messages\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "    level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set values for various parameters\n",
    "num_features = 300    # Word vector dimensionality                      \n",
    "min_word_count = 40   # Minimum word count                        \n",
    "num_workers = 8       # Number of threads to run in parallel\n",
    "context = 10          # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Initialize and train the model (this will take some time)\n",
    "from gensim.models import word2vec\n",
    "print \"Training model...\"\n",
    "model = word2vec.Word2Vec(sentences, workers=num_workers, \\\n",
    "            size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If you don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# It can be helpful to create a meaningful model name and \n",
    "# save the model for later use. You can load it later using Word2Vec.load()\n",
    "model_name = \"300features_40minwords_10context\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a dual-core Macbook Pro, this took less than 15 minutes to run using 4 worker threads. However, it will vary depending on your computer. Fortunately, the logging functionality prints informative messages.\n",
    "\n",
    "If you are on a Mac or Linux system, you can use the \"top\" command from within Terminal (not from within Python) to see if your system is successfully parallelizing while the model is training. Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the Model Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations on making it successfully through everything so far! Let's take a look at the model we created out of our 75,000 training reviews.\n",
    "\n",
    "The \"doesnt_match\" function will try to deduce which word in a set is most dissimilar from the others:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kitchen'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"man woman child kitchen\".split())\n",
    "'kitchen'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is capable of distinguishing differences in meaning! It knows that men, women and children are more similar to each other than they are to kitchens. More exploration shows that the model is sensitive to more subtle differences in meaning, such as differences between countries and cities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'berlin'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"france england germany berlin\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... although with the relatively small training set we used, it's certainly not perfect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'paris'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"paris berlin london austria\".split())\n",
    "'paris'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the \"most_similar\" function to get insight into the model's word clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'woman', 0.6322274208068848),\n",
       " (u'lady', 0.5871136784553528),\n",
       " (u'lad', 0.5658714175224304),\n",
       " (u'men', 0.5298689603805542),\n",
       " (u'monk', 0.5283631086349487),\n",
       " (u'businessman', 0.5234595537185669),\n",
       " (u'millionaire', 0.5194512605667114),\n",
       " (u'soldier', 0.5185883641242981),\n",
       " (u'guy', 0.5120233297348022),\n",
       " (u'person', 0.5120117664337158)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"man\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'princess', 0.6948347687721252),\n",
       " (u'bride', 0.6394442319869995),\n",
       " (u'goddess', 0.6107475161552429),\n",
       " (u'mistress', 0.6015448570251465),\n",
       " (u'mary', 0.5880306363105774),\n",
       " (u'eva', 0.5803037881851196),\n",
       " (u'angela', 0.5779411792755127),\n",
       " (u'duchess', 0.5745822787284851),\n",
       " (u'dame', 0.5716529488563538),\n",
       " (u'maid', 0.570807695388794)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"queen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given our particular training set, it's not surprising that \"Latifah\" is a top hit for similarity with \"Queen\".\n",
    "\n",
    "Or, more relevant for sentiment analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'terrible', 0.7888780832290649),\n",
       " (u'atrocious', 0.7586556673049927),\n",
       " (u'horrible', 0.7239440679550171),\n",
       " (u'horrendous', 0.7101829648017883),\n",
       " (u'dreadful', 0.7024926543235779),\n",
       " (u'abysmal', 0.6903165578842163),\n",
       " (u'horrid', 0.6864355206489563),\n",
       " (u'appalling', 0.6766446232795715),\n",
       " (u'crappy', 0.6405069828033447),\n",
       " (u'lousy', 0.638817548751831)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"awful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems we have a reasonably good model for semantic meaning - at least as good as Bag of Words. But how can we use these fancy distributed word vectors for supervised learning? The next section takes a stab at that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: More Fun With Word Vectors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numeric Representations of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a trained model with some semantic understanding of words, how should we use it? If you look beneath the hood, the Word2Vec model trained in Part 2 consists of a feature vector for each word in the vocabulary, stored in a numpy array called \"syn0\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the model that we created in Part 2\n",
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec.load(\"300features_40minwords_10context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.syn0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16490, 300)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.syn0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of rows in syn0 is the number of words in the model's vocabulary, and the number of columns corresponds to the size of the feature vector, which we set in Part 2.  Setting the minimum word count to 40 gave us a total vocabulary of 16,492 words with 300 features apiece. Individual word vectors can be accessed in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -3.55882496e-02,   2.47471277e-02,  -1.04208276e-01,\n",
       "         3.29137072e-02,   2.55899355e-02,   1.74981821e-02,\n",
       "         7.12182969e-02,  -1.42839095e-02,   1.58416592e-02,\n",
       "         9.37454402e-02,  -5.58592677e-02,  -9.29856598e-02,\n",
       "         3.26889344e-02,   1.06930472e-01,   1.85630401e-03,\n",
       "         1.11467671e-02,  -6.41966760e-02,  -2.04013456e-02,\n",
       "        -4.45806980e-02,  -6.75038025e-02,  -1.59813195e-01,\n",
       "        -2.08285563e-02,   1.11681387e-01,   7.89937824e-02,\n",
       "        -6.63784519e-02,  -1.86357126e-02,  -6.04835339e-02,\n",
       "        -7.14961141e-02,  -4.50195335e-02,  -2.05224138e-02,\n",
       "         3.61643173e-02,   9.60387886e-02,  -5.84295951e-02,\n",
       "         6.81338832e-02,  -9.61724818e-02,  -6.60632912e-04,\n",
       "        -8.50417186e-03,  -1.10230200e-01,   7.37866983e-02,\n",
       "         5.62555194e-02,  -2.51879990e-02,  -3.53787579e-02,\n",
       "        -1.61538199e-02,  -1.98000092e-02,   2.87626851e-02,\n",
       "        -6.33075312e-02,  -8.02566037e-02,  -3.68730538e-02,\n",
       "         4.61276323e-02,   1.12826891e-01,  -1.10806301e-01,\n",
       "         3.16583477e-02,   9.68787745e-02,  -4.78281304e-02,\n",
       "        -4.02895249e-02,  -3.52558605e-02,   1.55202113e-04,\n",
       "        -3.63130048e-02,  -1.43808022e-01,   4.42711962e-03,\n",
       "        -4.91630882e-02,  -1.77957595e-03,   5.67717180e-02,\n",
       "        -3.83522324e-02,  -9.60825905e-02,   6.81047961e-02,\n",
       "         3.63117419e-02,   5.61665557e-02,   3.71133909e-02,\n",
       "        -1.26478430e-02,  -6.53350949e-02,   8.99698865e-03,\n",
       "         3.25958407e-03,   1.46788033e-02,   3.01092640e-02,\n",
       "        -3.41891125e-02,  -5.50497361e-02,   3.73913646e-02,\n",
       "        -1.00466115e-02,   8.90686810e-02,   6.13426929e-03,\n",
       "         9.22860131e-02,   8.41703918e-03,  -1.25936776e-01,\n",
       "        -7.89619342e-04,  -3.82772870e-02,   5.67331575e-02,\n",
       "        -6.38181418e-02,   9.06023849e-03,   6.16012923e-02,\n",
       "        -6.06720746e-02,  -8.06147326e-03,  -3.72956885e-04,\n",
       "         5.19216955e-02,  -5.44601083e-02,  -3.51979248e-02,\n",
       "         7.26705790e-02,   2.23731669e-03,   4.48953360e-02,\n",
       "        -7.71032125e-02,  -1.06344307e-02,  -6.93584830e-02,\n",
       "         2.52024252e-02,  -9.72983018e-02,   2.93030590e-02,\n",
       "        -1.56248882e-01,  -3.70237827e-02,   6.73727319e-02,\n",
       "        -5.12270890e-02,  -1.60797134e-01,   3.43241543e-02,\n",
       "         5.93282981e-03,   1.59055933e-01,   2.00582650e-02,\n",
       "         5.54605983e-02,   2.42288113e-02,   7.22672716e-02,\n",
       "        -2.96430220e-03,   6.96482360e-02,   1.04704835e-01,\n",
       "         3.02894805e-02,   6.70118406e-02,  -2.81544216e-02,\n",
       "         7.29399323e-02,   3.37951556e-02,   7.13070156e-03,\n",
       "        -9.92850140e-02,   9.61361546e-03,   5.11280149e-02,\n",
       "         4.22588177e-02,   8.10209755e-03,  -1.09061738e-03,\n",
       "        -7.76890293e-02,  -3.46188061e-02,   1.34196421e-02,\n",
       "        -6.40526563e-02,  -8.23103786e-02,   2.44062040e-02,\n",
       "         1.25887990e-02,   9.38936695e-03,  -5.03795817e-02,\n",
       "         3.32552032e-03,  -3.43791284e-02,  -1.42201800e-02,\n",
       "         1.38962477e-01,  -1.03612412e-02,  -2.51625571e-02,\n",
       "         3.30625959e-02,  -4.99621741e-02,  -1.99146885e-02,\n",
       "         2.27263626e-02,  -1.37947993e-02,   5.35124466e-02,\n",
       "        -2.13138368e-02,   3.81628126e-02,   6.00395165e-02,\n",
       "        -9.40183997e-02,   4.64383997e-02,   6.40595704e-02,\n",
       "        -1.88648887e-02,  -5.72695062e-02,   8.58328715e-02,\n",
       "         2.68947389e-02,  -4.49149460e-02,  -4.95724566e-02,\n",
       "        -3.81453410e-02,  -5.25868274e-02,   4.20970023e-02,\n",
       "         4.30612825e-03,  -3.16251558e-03,  -7.42969811e-02,\n",
       "        -7.17648119e-02,  -2.11895574e-02,  -3.29929553e-02,\n",
       "         7.43309706e-02,   2.93748267e-02,  -7.64147267e-02,\n",
       "        -1.39336120e-02,   4.30943780e-02,  -4.05436642e-02,\n",
       "        -5.21518961e-02,  -4.67929468e-02,  -9.57569852e-02,\n",
       "        -3.45414095e-02,   4.56543751e-02,  -4.96648885e-02,\n",
       "         6.47902712e-02,  -1.09537117e-01,  -3.01021263e-02,\n",
       "        -5.76988794e-02,  -2.06429083e-02,  -5.73864058e-02,\n",
       "         1.38882454e-02,   8.62225331e-03,   7.58093819e-02,\n",
       "        -3.66315022e-02,  -2.12668721e-02,   2.15990487e-02,\n",
       "        -3.21666859e-02,   4.98779342e-02,   5.44862039e-02,\n",
       "        -2.67323270e-03,   2.70017143e-02,   1.29934018e-02,\n",
       "         7.21630380e-02,  -7.41390511e-02,  -8.98320079e-02,\n",
       "        -5.95589355e-02,   4.37078401e-02,   3.35343517e-02,\n",
       "        -4.02515046e-02,   3.59163433e-02,   5.97494794e-03,\n",
       "         4.70575094e-02,   3.90465595e-02,   2.56752651e-02,\n",
       "         1.86664872e-02,   2.13174466e-02,   7.76682347e-02,\n",
       "         3.57806496e-02,   8.86230394e-02,   3.34956795e-02,\n",
       "         3.75167541e-02,  -3.40588503e-02,   4.05320227e-02,\n",
       "        -5.96539229e-02,  -1.16136409e-02,  -4.03795727e-02,\n",
       "         2.83653308e-02,  -9.74851698e-02,   4.23166715e-03,\n",
       "        -2.19235495e-02,   4.66139913e-02,  -5.44767082e-02,\n",
       "        -1.74504835e-02,  -2.72377990e-02,   7.87099451e-03,\n",
       "        -5.81324883e-02,   3.79459560e-02,  -4.54776101e-02,\n",
       "         5.31399213e-02,   3.65951434e-02,  -2.69994903e-02,\n",
       "        -4.20414954e-02,   5.81425056e-03,  -2.17873976e-03,\n",
       "         5.61670475e-02,   1.80523936e-02,   5.16059995e-02,\n",
       "        -1.89411398e-02,   4.99554574e-02,  -1.73452199e-01,\n",
       "        -8.11168365e-03,   8.00325051e-02,   3.09167169e-02,\n",
       "         7.05138445e-02,   2.81192157e-02,  -4.04772460e-02,\n",
       "         4.82485071e-02,  -3.03900316e-02,   2.77718287e-02,\n",
       "        -2.99347639e-02,  -4.83625010e-02,   3.24691869e-02,\n",
       "        -1.30199073e-02,   4.38352562e-02,   1.05329327e-01,\n",
       "        -4.57907468e-02,  -1.88184604e-02,  -4.01927624e-03,\n",
       "        -4.49867286e-02,   7.14428127e-02,  -1.49682146e-02,\n",
       "         9.17007476e-02,   8.07429384e-03,  -8.74338076e-02,\n",
       "         4.05235700e-02,  -8.38367939e-02,  -8.38455185e-03,\n",
       "         2.78369524e-02,  -8.83844867e-02,   9.73052252e-03,\n",
       "         6.64622858e-02,  -2.72305161e-02,  -2.83894986e-02,\n",
       "         3.59206758e-02,  -1.57311093e-02,  -1.40985548e-01,\n",
       "        -1.39436973e-02,  -4.19071354e-02,  -2.50990260e-02,\n",
       "         3.58055793e-02,  -3.15005630e-02,   7.17863366e-02,\n",
       "        -8.48470554e-02,   1.39727769e-02,  -1.43942624e-01,\n",
       "         1.87910888e-02,   1.37729958e-01,   1.03993960e-01], dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[\"flower\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Words To Paragraphs, Attempt 1: Vector Averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One challenge with the IMDB dataset is the variable-length reviews. We need to find a way to take individual word vectors and transform them into a feature set that is the same length for every review.\n",
    "\n",
    "Since each word is a vector in 300-dimensional space, we can use vector operations to combine the words in each review. One method we tried was to simply average the word vectors in a given review (for this purpose, we removed stop words, which would just add noise).\n",
    "\n",
    "The following code averages the feature vectors, building on our code from Part 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np  # Make sure that numpy is imported\n",
    "\n",
    "def makeFeatureVec(words, model, num_features):\n",
    "    # Function to average all of the word vectors in a given\n",
    "    # paragraph\n",
    "    #\n",
    "    # Pre-initialize an empty numpy array (for speed)\n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    #\n",
    "    nwords = 0.\n",
    "    # \n",
    "    # Index2word is a list that contains the names of the words in \n",
    "    # the model's vocabulary. Convert it to a set, for speed \n",
    "    index2word_set = set(model.index2word)\n",
    "    #\n",
    "    # Loop over each word in the review and, if it is in the model's\n",
    "    # vocaublary, add its feature vector to the total\n",
    "    for word in words:\n",
    "        if word in index2word_set: \n",
    "            nwords = nwords + 1.\n",
    "            featureVec = np.add(featureVec,model[word])\n",
    "    # \n",
    "    # Divide the result by the number of words to get the average\n",
    "    featureVec = np.divide(featureVec,nwords)\n",
    "    return featureVec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getAvgFeatureVecs(reviews, model, num_features):\n",
    "    # Given a set of reviews (each one a list of words), calculate \n",
    "    # the average feature vector for each one and return a 2D numpy array \n",
    "    # \n",
    "    # Initialize a counter\n",
    "    counter = 0.\n",
    "    # \n",
    "    # Preallocate a 2D numpy array, for speed\n",
    "    reviewFeatureVecs = np.zeros((len(reviews),num_features),dtype=\"float32\")\n",
    "    # \n",
    "    # Loop through the reviews\n",
    "    for review in reviews:\n",
    "       #\n",
    "       # Print a status message every 1000th review\n",
    "       if counter%1000. == 0.:\n",
    "           print \"Review %d of %d\" % (counter, len(reviews))\n",
    "       # \n",
    "       # Call the function (defined above) that makes average feature vectors\n",
    "       reviewFeatureVecs[counter] = makeFeatureVec(review, model, \\\n",
    "           num_features)\n",
    "       #\n",
    "       # Increment the counter\n",
    "       counter = counter + 1.\n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can call these functions to create average vectors for each paragraph. The following operations will take a few minutes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ****************************************************************\n",
    "# Calculate average feature vectors for training and testing sets,\n",
    "# using the functions we defined above. Notice that we now use stop word\n",
    "# removal.\n",
    "\n",
    "clean_train_reviews = []\n",
    "for review in train[\"review\"]:\n",
    "    clean_train_reviews.append( review_to_wordlist( review, \\\n",
    "        remove_stopwords=True ))\n",
    "\n",
    "trainDataVecs = getAvgFeatureVecs( clean_train_reviews, model, num_features )\n",
    "\n",
    "print \"Creating average feature vecs for test reviews\"\n",
    "clean_test_reviews = []\n",
    "for review in test[\"review\"]:\n",
    "    clean_test_reviews.append( review_to_wordlist( review, \\\n",
    "        remove_stopwords=True ))\n",
    "\n",
    "testDataVecs = getAvgFeatureVecs( clean_test_reviews, model, num_features )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, use the average paragraph vectors to train a random forest. Note that, as in Part 1, we can only use the labeled training reviews to train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit a random forest to the training data, using 100 trees\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier( n_estimators = 100 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"Fitting a random forest to labeled training data...\"\n",
    "forest = forest.fit( trainDataVecs, train[\"sentiment\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test & extract results \n",
    "result = forest.predict( testDataVecs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write the test results \n",
    "output = pd.DataFrame( data={\"id\":test[\"id\"], \"sentiment\":result} )\n",
    "output.to_csv( \"Word2Vec_AverageVectors.csv\", index=False, quoting=3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that this produced results much better than chance, but underperformed Bag of Words by a few percentage points.\n",
    "\n",
    "Since the element-wise average of the vectors didn't produce spectacular results, perhaps we could do it in a more intelligent way? A standard way of weighting word vectors is to apply \"tf-idf\" weights, which measure how important a given word is within a given set of documents. One way to extract tf-idf weights in Python is by using scikit-learn's TfidfVectorizer, which has an interface similar to the CountVectorizer that we used in Part 1. However, when we tried weighting our word vectors in this way, we found no substantial improvement in performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Words to Paragraphs, Attempt 2: Clustering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec creates clusters of semantically related words, so another possible approach is to exploit the similarity of words within a cluster. Grouping vectors in this way is known as \"vector quantization.\" To accomplish this, we first need to find the centers of the word clusters, which we can do by using a clustering algorithm such as K-Means.\n",
    "\n",
    "In K-Means, the one parameter we need to set is \"K,\" or the number of clusters. How should we decide how many clusters to create? Trial and error suggested that small clusters, with an average of only 5 words or so per cluster, gave better results than large clusters with many words. Clustering code is given below. We use scikit-learn to perform our K-Means.\n",
    "\n",
    "K-Means clustering with large K can be very slow; the following code took more than 40 minutes on my computer. Below, we set a timer around the K-Means function to see how long it takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import time\n",
    "\n",
    "start = time.time() # Start time\n",
    "\n",
    "# Set \"k\" (num_clusters) to be 1/5th of the vocabulary size, or an\n",
    "# average of 5 words per cluster\n",
    "word_vectors = model.syn0\n",
    "num_clusters = word_vectors.shape[0] / 5\n",
    "\n",
    "# Initalize a k-means object and use it to extract centroids\n",
    "kmeans_clustering = KMeans( n_clusters = num_clusters )\n",
    "idx = kmeans_clustering.fit_predict( word_vectors )\n",
    "\n",
    "# Get the end time and print how long the process took\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print \"Time taken for K Means clustering: \", elapsed, \"seconds.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cluster assignment for each word is now stored in idx, and the vocabulary from our original Word2Vec model is still stored in model.index2word. For convenience, we zip these into one dictionary as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a Word / Index dictionary, mapping each vocabulary word to\n",
    "# a cluster number                                                                                            \n",
    "word_centroid_map = dict(zip( model.index2word, idx ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a little abstract, so let's take a closer look at what our clusters contain. Your clusters may differ, as Word2Vec relies on a random number seed. Here is a loop that prints out the words for clusters 0 through 9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For the first 10 clusters\n",
    "for cluster in xrange(0,10):\n",
    "    #\n",
    "    # Print the cluster number  \n",
    "    print \"\\nCluster %d\" % cluster\n",
    "    #\n",
    "    # Find all of the words for that cluster number, and print them out\n",
    "    words = []\n",
    "    for i in xrange(0,len(word_centroid_map.values())):\n",
    "        if( word_centroid_map.values()[i] == cluster ):\n",
    "            words.append(word_centroid_map.keys()[i])\n",
    "    print words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are very interesting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-101-ddaca8b2cd9f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-101-ddaca8b2cd9f>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Cluster 0\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Cluster 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cluster 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cluster 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cluster 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cluster 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cluster 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cluster 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cluster 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cluster 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cluster 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the clusters are of varying quality. Some make sense - Cluster 3 mostly contains names, and Clusters 6-8 contain related adjectives (Cluster 6 is my favorite). On the other hand, Cluster 5 is a little mystifying: What do a lobster and a deer have in common (besides being two animals)? Cluster 0 is even worse: Penthouses and suites seem to belong together, but they don't seem to belong with apples and passports. Cluster 2 contains ... maybe war-related words? Perhaps our algorithm works best on adjectives.\n",
    "\n",
    "At any rate, now we have a cluster (or \"centroid\") assignment for each word, and we can define a function to convert reviews into bags-of-centroids. This works just like Bag of Words but uses semantically related clusters instead of individual words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_bag_of_centroids( wordlist, word_centroid_map ):\n",
    "    #\n",
    "    # The number of clusters is equal to the highest cluster index\n",
    "    # in the word / centroid map\n",
    "    num_centroids = max( word_centroid_map.values() ) + 1\n",
    "    #\n",
    "    # Pre-allocate the bag of centroids vector (for speed)\n",
    "    bag_of_centroids = np.zeros( num_centroids, dtype=\"float32\" )\n",
    "    #\n",
    "    # Loop over the words in the review. If the word is in the vocabulary,\n",
    "    # find which cluster it belongs to, and increment that cluster count \n",
    "    # by one\n",
    "    for word in wordlist:\n",
    "        if word in word_centroid_map:\n",
    "            index = word_centroid_map[word]\n",
    "            bag_of_centroids[index] += 1\n",
    "    #\n",
    "    # Return the \"bag of centroids\"\n",
    "    return bag_of_centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function above will give us a numpy array for each review, each with a number of features equal to the number of clusters. Finally, we create bags of centroids for our training and test set, then train a random forest and extract results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pre-allocate an array for the training set bags of centroids (for speed)\n",
    "train_centroids = np.zeros( (train[\"review\"].size, num_clusters), \\\n",
    "    dtype=\"float32\" )\n",
    "\n",
    "# Transform the training set reviews into bags of centroids\n",
    "counter = 0\n",
    "for review in clean_train_reviews:\n",
    "    train_centroids[counter] = create_bag_of_centroids( review, \\\n",
    "        word_centroid_map )\n",
    "    counter += 1\n",
    "\n",
    "# Repeat for test reviews \n",
    "test_centroids = np.zeros(( test[\"review\"].size, num_clusters), \\\n",
    "    dtype=\"float32\" )\n",
    "\n",
    "counter = 0\n",
    "for review in clean_test_reviews:\n",
    "    test_centroids[counter] = create_bag_of_centroids( review, \\\n",
    "        word_centroid_map )\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit a random forest and extract predictions \n",
    "forest = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "# Fitting the forest may take a few minutes\n",
    "print \"Fitting a random forest to labeled training data...\"\n",
    "forest = forest.fit(train_centroids,train[\"sentiment\"])\n",
    "result = forest.predict(test_centroids)\n",
    "\n",
    "# Write the test results \n",
    "output = pd.DataFrame(data={\"id\":test[\"id\"], \"sentiment\":result})\n",
    "output.to_csv( \"BagOfCentroids.csv\", index=False, quoting=3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that the code above gives about the same (or slightly worse) results compared to the Bag of Words in Part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
